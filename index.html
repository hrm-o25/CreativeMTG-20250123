<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><meta name="next-head-count" content="2"/><link rel="preload" href="./_next/static/css/d1893b45984f5972.css" as="style"/><link rel="stylesheet" href="./_next/static/css/d1893b45984f5972.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="./_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="./_next/static/chunks/webpack-6f0e0dcf15b6875d.js" defer=""></script><script src="./_next/static/chunks/framework-49c6cecf1f6d5795.js" defer=""></script><script src="./_next/static/chunks/main-723f98eb367cc52a.js" defer=""></script><script src="./_next/static/chunks/pages/_app-4ac3cada10d020c2.js" defer=""></script><script src="./_next/static/chunks/413-9ff854af82ce4d76.js" defer=""></script><script src="./_next/static/chunks/664-d254d21a6fe56bff.js" defer=""></script><script src="./_next/static/chunks/39-45fee9698b3cd58c.js" defer=""></script><script src="./_next/static/chunks/pages/index-4106543ad8e86225.js" defer=""></script><script src="./_next/static/CV6WqzivbkPeR90C6i50t/_buildManifest.js" defer=""></script><script src="./_next/static/CV6WqzivbkPeR90C6i50t/_ssgManifest.js" defer=""></script></head><body><div id="__next"></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"result":{"clusters":[{"cluster":"参加者のポジティブな反応","cluster_id":"3","takeaways":"参加者のコメントからは、Creative MTGの雰囲気が非常に活気に満ちていたことが伺えます。特に、プロジェクトの引き取り手がいることや、ジャンパーの魅力についての反応が好意的で、参加者同士の交流が盛んだったことが強調されています。また、ブレインストーミングの時間を設けることで、全員が意見を出し合う重要性や、プロジェクトの核心を再確認することの大切さが共有され、実践的な学びがあったことが印象的です。","arguments":[{"arg_id":"A0_0","argument":"良い声ww","comment_id":"0","x":4.9333386,"y":14.132209,"p":0.8737562118804985},{"arg_id":"A1_0","argument":"はじまるよ〜！","comment_id":"1","x":4.601118,"y":14.728456,"p":1},{"arg_id":"A2_0","argument":"わー！","comment_id":"2","x":4.420931,"y":14.109039,"p":1},{"arg_id":"A26_0","argument":"すでに引き取り手がいるのよかった‼️","comment_id":"26","x":4.3670187,"y":14.519595,"p":1},{"arg_id":"A36_0","argument":"かわいい！","comment_id":"36","x":4.536664,"y":13.969583,"p":0.8186284207170899},{"arg_id":"A37_0","argument":"ジャンパーほしい！！","comment_id":"37","x":4.634155,"y":14.356778,"p":1},{"arg_id":"A43_0","argument":"引き継ぐPM目線でタメになる話！","comment_id":"43","x":4.872645,"y":15.194779,"p":0},{"arg_id":"A45_0","argument":"リピートすばらしい！！","comment_id":"45","x":4.960383,"y":14.433292,"p":0.9754727677750452},{"arg_id":"A55_0","argument":"わたしも途中でブレストタイムいれて、全員半強制的にチャットに意見書かせたことあります！","comment_id":"55","x":5.3616967,"y":14.9055,"p":0},{"arg_id":"A71_0","argument":"知らなかった...","comment_id":"71","x":3.9523778,"y":14.777444,"p":0},{"arg_id":"A79_0","argument":"ビシッと「何が一番大事か思い出せ!!」笑","comment_id":"79","x":4.4957848,"y":14.754319,"p":1}]},{"cluster":"参加者の熱意と反応","cluster_id":"4","takeaways":"参加者のコメントからは、AkeruEチームへの強い愛情と熱意が伝わってきます。特に、チームの機敏な動きや現場感に感動したという声が多く、アケルエの活動が参加者にとって大きなインスピレーションとなっていることが伺えます。また、アルケミストプログラムの参加者がプロジェクトに対する情熱を持ち続けている点も印象的です。全体として、AkeruEの成功とその影響力に対する期待が高まっている様子が見受けられます。","arguments":[{"arg_id":"A3_0","argument":"今回もコメント分析たのしみ〜","comment_id":"3","x":5.521326,"y":14.986865,"p":0},{"arg_id":"A5_0","argument":"AI分析さんに褒めてもらえるよう頑張るぞい","comment_id":"5","x":5.906033,"y":14.635072,"p":0},{"arg_id":"A7_0","argument":"AkeruEチームの熱量は本当にすごかったです","comment_id":"7","x":6.332323,"y":13.811634,"p":1},{"arg_id":"A16_0","argument":"アケルエ愛されてる！","comment_id":"16","x":6.415863,"y":14.6888075,"p":1},{"arg_id":"A18_0","argument":"現場のアケルエチームの動きが機敏すぎるのがとてもすごいし、現場感の実感できて感動。","comment_id":"18","x":6.5289865,"y":13.937571,"p":1},{"arg_id":"A22_0","argument":"アーカイブは次に繋がりますね。","comment_id":"22","x":5.7861176,"y":15.357857,"p":0},{"arg_id":"A23_0","argument":"アケルエの競合というか、似た施設って存在してるのでしょうか？","comment_id":"23","x":6.538934,"y":15.025101,"p":1},{"arg_id":"A27_0","argument":"どのくらいの広さが必要なの？アルケミストプログラム","comment_id":"27","x":6.8153467,"y":14.386611,"p":1},{"arg_id":"A28_0","argument":"アルケミストプログラムの参加者メンバーは終わった今でも変わらずこれつくった！これに出展します！というような連絡してきてくれてます〜情熱は変わらずつづいております。(わたけん)","comment_id":"28","x":6.450236,"y":14.193749,"p":1},{"arg_id":"A31_0","argument":"アケルエみたいなプロジェクト作りたい","comment_id":"31","x":6.699807,"y":14.698245,"p":1},{"arg_id":"A32_0","argument":"アケルエを締めるね","comment_id":"32","x":6.355016,"y":15.209399,"p":0},{"arg_id":"A42_0","argument":"SDSの活用方法すごくいいですね。個別のプロジェクトで使うのいいなと思います。","comment_id":"42","x":6.9057446,"y":14.264206,"p":0}]},{"cluster":"参加者の具体的な反応","cluster_id":"5","takeaways":"参加者のコメントからは、ガールズバーの盛り上がりやクリスマスの終業式の思い出が強調されており、楽しい雰囲気が伝わってきます。また、「魔貫光殺砲」や「ポテチおでん」などのユニークな話題もあり、参加者同士の軽妙なやり取りが見受けられます。全体として、リラックスした雰囲気の中での交流が印象的です。","arguments":[{"arg_id":"A4_0","argument":"前回はガールズバーがめちゃくちゃ盛り上がってましたね","comment_id":"4","x":3.5498753,"y":15.268645,"p":0},{"arg_id":"A12_0","argument":"たしかにクリスマスらへん終業式してたな〜","comment_id":"12","x":3.2992067,"y":14.907526,"p":0.6607589975739088},{"arg_id":"A14_0","argument":"圧巻ですね","comment_id":"14","x":3.2964206,"y":15.343674,"p":1},{"arg_id":"A34_0","argument":"パナソニック続きですね","comment_id":"34","x":3.0935,"y":15.18904,"p":1},{"arg_id":"A44_0","argument":"魔貫光殺砲はなんだったんだろう","comment_id":"44","x":3.168245,"y":15.662149,"p":0.9281613935520102},{"arg_id":"A46_0","argument":"これすっごい苦労してたよね","comment_id":"46","x":3.5308466,"y":15.760292,"p":0},{"arg_id":"A53_0","argument":"わざですね","comment_id":"53","x":2.6698785,"y":14.638079,"p":0.7637298249832616},{"arg_id":"A66_0","argument":"たしかに笑","comment_id":"66","x":3.141727,"y":14.537296,"p":1},{"arg_id":"A67_0","argument":"ポテチを箸で食べてるな👀","comment_id":"67","x":2.5611708,"y":15.325407,"p":1},{"arg_id":"A68_0","argument":"ポテチおでんの汁につけてる？","comment_id":"68","x":2.635554,"y":15.461565,"p":0},{"arg_id":"A72_0","argument":"マルの中にクセなんですね","comment_id":"72","x":2.6862075,"y":15.007106,"p":1}]},{"cluster":"参加者の具体的な反応","cluster_id":"2","takeaways":"来場者57万人という大規模なイベントに対する称賛が目立ち、特に300人の常連参加者の存在が注目されました。デザインやユニフォーム、スタッフの服装に対する好評も多く、特に背中のロゴやバックプリントが可愛らしいと評価されています。また、オンラインMTGの重要性やチームの雰囲気の良さについても言及され、クリエイティブな取り組みやアートを通じたチームビルディングのアイデアが素晴らしいとされました。全体として、参加者の熱意とイベントの魅力が強調されています。","arguments":[{"arg_id":"A6_0","argument":"来場者57万、立派","comment_id":"6","x":4.842225,"y":12.75003,"p":0},{"arg_id":"A8_0","argument":"Yチームわたけんです。名古屋から応援！","comment_id":"8","x":5.867913,"y":13.008045,"p":1},{"arg_id":"A15_0","argument":"300人の常連ってとっても凄い！！","comment_id":"15","x":5.195941,"y":12.844196,"p":0},{"arg_id":"A21_0","argument":"それぞれのデザインでぶん回しつつ、ボックスに入れてまとまり良く整える、素敵◎◎","comment_id":"21","x":5.3045845,"y":13.343089,"p":1},{"arg_id":"A35_0","argument":"エリアのブロック表示かわいい","comment_id":"35","x":5.502761,"y":13.179381,"p":0.8312594111747644},{"arg_id":"A38_0","argument":"デザインすてき","comment_id":"38","x":5.468476,"y":13.550887,"p":1},{"arg_id":"A39_0","argument":"背中ロゴのユニフォーム、すてき！","comment_id":"39","x":5.0179286,"y":13.259673,"p":1},{"arg_id":"A40_0","argument":"バックプリントなスタッフじゃんぱーかわいい","comment_id":"40","x":4.730774,"y":13.255287,"p":0},{"arg_id":"A41_0","argument":"めっちゃいろんなことやってる、クリエイティブも素敵","comment_id":"41","x":5.9874535,"y":13.559447,"p":0.7869462244490851},{"arg_id":"A51_0","argument":"オンラインMTGはファシリ大事","comment_id":"51","x":5.5346484,"y":13.853875,"p":1},{"arg_id":"A58_0","argument":"CLのチームの雰囲気も良くなってそうで素敵！","comment_id":"58","x":6.249745,"y":13.0206785,"p":0.7885905508761044},{"arg_id":"A60_0","argument":"オンラインでもいい空気になるのすごい","comment_id":"60","x":5.76178,"y":13.858039,"p":0.8286039417360355},{"arg_id":"A70_0","argument":"このロゴすてきです！","comment_id":"70","x":5.03687,"y":13.669512,"p":0},{"arg_id":"A74_0","argument":"チームビルディングのお題目でアートを巡るの、素敵！","comment_id":"74","x":6.104269,"y":13.194865,"p":1},{"arg_id":"A75_0","argument":"CLと美術館いくのいいですね！","comment_id":"75","x":5.9651814,"y":12.723752,"p":0}]},{"cluster":"参加者の感情表現","cluster_id":"0","takeaways":"参加者のコメントからは、感情豊かな反応が多く見られ、特に「泣く」という表現が印象的です。また、「ひといっぱいだ」や「可愛いシロクマ」といった言葉からは、イベントの雰囲気が賑やかで親しみやすいことが伝わります。特に「発言切り込み隊長」や「びっくりさっさんかわいいです」といった具体的な名前の言及は、参加者同士の関係性や楽しさを感じさせる要素となっています。全体として、感謝の気持ちや楽しさが強調されている印象です。","arguments":[{"arg_id":"A9_0","argument":"名前がすでにこわい笑","comment_id":"9","x":3.6360285,"y":14.567654,"p":0.7003434197928847},{"arg_id":"A13_0","argument":"ひといっぱいだ","comment_id":"13","x":2.5166864,"y":14.228303,"p":1},{"arg_id":"A19_0","argument":"読んだら泣くな","comment_id":"19","x":3.376239,"y":14.420805,"p":1},{"arg_id":"A20_0","argument":"読んだら泣く(わたけん)","comment_id":"20","x":3.2541199,"y":14.29638,"p":1},{"arg_id":"A25_0","argument":"乃村工藝社オトコマエ","comment_id":"25","x":4.1501255,"y":13.019125,"p":0},{"arg_id":"A29_0","argument":"大澤くんのやつだ","comment_id":"29","x":3.2608957,"y":13.7423115,"p":0},{"arg_id":"A30_0","argument":"あつすぎる","comment_id":"30","x":2.447597,"y":14.2249565,"p":1},{"arg_id":"A33_0","argument":"わたけん、ありがとう！","comment_id":"33","x":4.0794735,"y":14.058209,"p":0.8926199667308271},{"arg_id":"A52_0","argument":"発言切り込み隊長","comment_id":"52","x":4.387159,"y":13.586059,"p":0},{"arg_id":"A62_0","argument":"さっっっっさん","comment_id":"62","x":3.4675756,"y":13.4627695,"p":1},{"arg_id":"A65_0","argument":"びっくりさっさんかわいいです","comment_id":"65","x":3.7478266,"y":13.9029665,"p":0.7054121425462443},{"arg_id":"A69_0","argument":"見てるで","comment_id":"69","x":2.6759205,"y":13.981031,"p":1},{"arg_id":"A73_0","argument":"しろくまさん","comment_id":"73","x":3.5186422,"y":13.275846,"p":1},{"arg_id":"A78_0","argument":"可愛いシロクマ","comment_id":"78","x":3.8303468,"y":13.417092,"p":0.9508089790845944}]},{"cluster":"参加者の具体的な意見","cluster_id":"1","takeaways":"参加者は、人口減少社会における事業の閉鎖や「締め方のデザイン」に関心を寄せており、特にその理想的な形や固定資産問題についての懸念が示されました。また、ネーミングや商標の表現に関する難しさや、意見を引き出す際のコミュニケーションの工夫についても議論が交わされました。特に、若手の意見を尊重しつつ、偉い人の意見に流されないようにする方法や、視察の意義を明確にすることの重要性が強調されました。","arguments":[{"arg_id":"A10_0","argument":"人口減少社会だから事業を閉じる会社もどんどん多くなるはず。「締め方のデザイン」は社会的に参考になる人多そう。","comment_id":"10","x":4.1613336,"y":16.213236,"p":0.6286910228790943},{"arg_id":"A11_0","argument":"ファンの数もすごく多かったから締め方は本当に難しそう","comment_id":"11","x":3.9043355,"y":16.00661,"p":0},{"arg_id":"A17_0","argument":"その理想の様子をどんな形で見せたんだろう？","comment_id":"17","x":3.5396814,"y":16.935394,"p":0.5768170706405911},{"arg_id":"A24_0","argument":"固定資産問題、どうなるの？","comment_id":"24","x":4.0865474,"y":16.946564,"p":0},{"arg_id":"A47_0","argument":"名前でスケジュール食いつぶされる⁉️","comment_id":"47","x":4.401593,"y":15.522259,"p":1},{"arg_id":"A48_0","argument":"商標とネーミングの表現は両立させるのむずいよね","comment_id":"48","x":4.4940815,"y":16.529984,"p":0.5048353447328134},{"arg_id":"A49_0","argument":"そもそもネーミングのスケジュールの組み方なんて、とっても難しそう…","comment_id":"49","x":4.2084394,"y":15.71706,"p":0},{"arg_id":"A50_0","argument":"名前を呼ぶの大事","comment_id":"50","x":4.763368,"y":15.656555,"p":1},{"arg_id":"A54_0","argument":"確かに声が大きい人の意見を取り入れそうになる...とても大切！","comment_id":"54","x":5.0513873,"y":15.848535,"p":1},{"arg_id":"A56_0","argument":"その方がLWのやりたい方向にもってきやすいこともありますよねー","comment_id":"56","x":3.7707007,"y":16.560917,"p":0.8562025323897753},{"arg_id":"A57_0","argument":"偉い人の声が大きい場合、若手にどうですか？と振っても「前の人と同じです」ってなりがちな場合もあるかなと思います。そう言う時に白けずに意見を聞き出すコツありますか？","comment_id":"57","x":5.0538216,"y":16.185717,"p":1},{"arg_id":"A59_0","argument":"〇〇さんが投票したからその案かな…というような忖度はなかったのか気になる","comment_id":"59","x":3.5639927,"y":16.576801,"p":1},{"arg_id":"A61_0","argument":"おじ層と若手層の相互効果いいですね","comment_id":"61","x":4.6425705,"y":16.262861,"p":0.4954718616767886},{"arg_id":"A63_0","argument":"どうシンプルになったのか気になるなぁ","comment_id":"63","x":3.620397,"y":16.750755,"p":1},{"arg_id":"A64_0","argument":"何事も引き継ぎは引き継ぐ方も引き継がれる方も難しいですよね","comment_id":"64","x":4.0834517,"y":16.52473,"p":0.6456805827384603},{"arg_id":"A76_0","argument":"避けたいほうが気になります","comment_id":"76","x":3.2415693,"y":16.403961,"p":0},{"arg_id":"A77_0","argument":"視察ってやりたいけど、それをやった意義を言語化するの大事ですよね。結構チームビルディングよりもワーク的になるのかなと思いますが、どんな準備しましたか？もしくはしてないですか？","comment_id":"77","x":5.3912244,"y":16.296833,"p":0}]}],"comments":{"0":{"comment":"良い声ww"},"1":{"comment":"はじまるよ〜！"},"2":{"comment":"わー！"},"3":{"comment":"今回もコメント分析たのしみ〜"},"4":{"comment":"前回はガールズバーがめちゃくちゃ盛り上がってましたね"},"5":{"comment":"AI分析さんに褒めてもらえるよう頑張るぞい"},"6":{"comment":"来場者57万、立派"},"7":{"comment":"AkeruEチームの熱量は本当にすごかったです"},"8":{"comment":"Yチームわたけんです。名古屋から応援！"},"9":{"comment":"名前がすでにこわい笑"},"10":{"comment":"人口減少社会だから事業を閉じる会社もどんどん多くなるはず。「締め方のデザイン」は社会的に参考になる人多そう。"},"11":{"comment":"ファンの数もすごく多かったから締め方は本当に難しそう"},"12":{"comment":"たしかにクリスマスらへん終業式してたな〜"},"13":{"comment":"ひといっぱいだ"},"14":{"comment":"圧巻ですね"},"15":{"comment":"300人の常連ってとっても凄い！！"},"16":{"comment":"アケルエ愛されてる！"},"17":{"comment":"その理想の様子をどんな形で見せたんだろう？"},"18":{"comment":"現場のアケルエチームの動きば機敏すぎるのがとてもすごいし､現場感の実感できて感動｡"},"19":{"comment":"読んだら泣くな"},"20":{"comment":"読んだら泣く(わたけん"},"21":{"comment":"それぞれのデザインでぶん回しつつ、ボックスに入れてまとまり良く整える、素敵◎◎"},"22":{"comment":"アーカイブは次に繋がりますね。"},"23":{"comment":"アケルエの競合というか、似た施設って存在してるのでしょうか？"},"24":{"comment":"固定資産問題、どうなるの？"},"25":{"comment":"乃村工藝社オトコマエ"},"26":{"comment":"すでに引き取り手がいるのよかった‼️"},"27":{"comment":"どのくらいの広さが必要なの？アルケミストプログラム"},"28":{"comment":"アルケミストプログラムの参加者メンバーは終わった今でも変わらずこれつくった！これに出展します！というような連絡してきてくれてます〜情熱は変わらずつづいております。(わたけん)"},"29":{"comment":"大澤くんのやつだ"},"30":{"comment":"あつすぎる"},"31":{"comment":"アケルエみたいなプロジェクト作りたい"},"32":{"comment":"アケルエを締めるね"},"33":{"comment":"わたけん、ありがとう！"},"34":{"comment":"パナソニック続きですね"},"35":{"comment":"エリアのブロック表示かわいい"},"36":{"comment":"かわいい！"},"37":{"comment":"ジャンパーほしい！！"},"38":{"comment":"デザインすてき"},"39":{"comment":"背中ロゴのユニフォーム、すてき！"},"40":{"comment":"バックプリントなスタッフじゃんぱーかわいい"},"41":{"comment":"めっちゃいろんなことやってる、クリエイティブも素敵"},"42":{"comment":"SDSの活用方法すごくいいですね。個別のプロジェクトで使うのいいなと思います"},"43":{"comment":"引き継ぐPM目線でタメになる話！"},"44":{"comment":"魔貫光殺砲はなんだったんだろう"},"45":{"comment":"リピートすばらしい！！"},"46":{"comment":"これすっごい苦労してたよね"},"47":{"comment":"名前でスケジュール食いつぶされる⁉️"},"48":{"comment":"商標とネーミングの表現は両立させるのむずいよね"},"49":{"comment":"そもそもネーミングのスケジュールの組み方なんて、とっても難しそう…"},"50":{"comment":"名前を呼ぶの大事"},"51":{"comment":"オンラインMTGはファシリ大事"},"52":{"comment":"発言切り込み隊長"},"53":{"comment":"わざですね"},"54":{"comment":"確かに声が大きい人の意見を取り入れそうになる...とても大切！"},"55":{"comment":"わたしも途中でブレストタイムいれて、全員半強制的にチャットに意見書かせたことあります！"},"56":{"comment":"その方がLWのやりたい方向にもってきやすいこともありますよねー"},"57":{"comment":"偉い人の声が大きい場合、若手にどうですか？と振っても「前の人と同じです」ってなりがちな場合もあるかなと思います。そう言う時に白けずに意見を聞き出すコツありますか？"},"58":{"comment":"CLのチームの雰囲気も良くなってそうで素敵！"},"59":{"comment":"〇〇さんが投票したからその案かな…というような忖度はなかったのか気になる"},"60":{"comment":"オンラインでもいい空気になるのすごい"},"61":{"comment":"おじ層と若手層の相互効果いいですね"},"62":{"comment":"さっっっっさん"},"63":{"comment":"どうシンプルになったのか気になるなぁ"},"64":{"comment":"何事も引き継ぎは引き継ぐ方も引き継がれる方も難しいですよね"},"65":{"comment":"びっくりさっさんかわいいです"},"66":{"comment":"たしかに笑"},"67":{"comment":"ポテチを箸で食べてるな👀"},"68":{"comment":"ポテチおでんの汁につけてる？"},"69":{"comment":"見てるで"},"70":{"comment":"このロゴすてきです！"},"71":{"comment":"知らなかった..."},"72":{"comment":"マルの中にクセなんですね"},"73":{"comment":"しろくまさん"},"74":{"comment":"チームビルディングのお題目でアートを巡るの、素敵！"},"75":{"comment":"CLと美術館いくのいいですね！"},"76":{"comment":"避けたいほうが気になります"},"77":{"comment":"視察ってやりたいけど、それをやった意義を言語化するの大事ですよね。結構チームビルディングよりもワーク的になるのかなと思いますが、どんな準備しましたか？もしくはしてないですか？"},"78":{"comment":"可愛いシロクマ"},"79":{"comment":"ビシッと「何が一番大事か思い出せ!!」笑"}},"overview":"Creative MTGでは、参加者からのポジティブな反応が際立ち、特にAkeruEチームへの熱意やプロジェクトの魅力が強調されました。参加者同士の交流が活発で、ユニークな話題や感情豊かな表現が印象的でした。また、イベントの規模やデザインに対する称賛が多く、参加者の期待感が高まっている様子が伺えます。さらに、人口減少社会における事業の課題についての具体的な意見も交わされ、実践的な学びが得られたことが明らかになりました。","config":{"name":"Creative MTG 反応まとめ","question":"Creative MTGの参加者の反応にはどういう傾向があったのか","input":"CreativeMTG-20250123","model":"gpt-4o-mini","extraction":{"workers":3,"limit":80,"source_code":"import os\nimport json\nfrom tqdm import tqdm\nimport pandas as pd\nfrom langchain_openai import ChatOpenAI\nfrom utils import messages, update_progress\nimport concurrent.futures\n\n\ndef extraction(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/args.csv\"\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n\n    model = config['extraction']['model']\n    prompt = config['extraction']['prompt']\n    workers = config['extraction']['workers']\n    limit = config['extraction']['limit']\n\n    comment_ids = (comments['comment-id'].values)[:limit]\n    comments.set_index('comment-id', inplace=True)\n    results = pd.DataFrame()\n    update_progress(config, total=len(comment_ids))\n    for i in tqdm(range(0, len(comment_ids), workers)):\n        batch = comment_ids[i: i + workers]\n        batch_inputs = [comments.loc[id]['comment-body'] for id in batch]\n        batch_results = extract_batch(batch_inputs, prompt, model, workers)\n        for comment_id, extracted_args in zip(batch, batch_results):\n            for j, arg in enumerate(extracted_args):\n                new_row = {\"arg-id\": f\"A{comment_id}_{j}\",\n                           \"comment-id\": int(comment_id), \"argument\": arg}\n                results = pd.concat(\n                    [results, pd.DataFrame([new_row])], ignore_index=True)\n        update_progress(config, incr=len(batch))\n    results.to_csv(path, index=False)\n\n\ndef extract_batch(batch, prompt, model, workers):\n    with concurrent.futures.ThreadPoolExecutor(max_workers=workers) as executor:\n        futures = [executor.submit(\n            extract_arguments, input, prompt, model) for input in list(batch)]\n        concurrent.futures.wait(futures)\n        return [future.result() for future in futures]\n\n\ndef extract_arguments(input, prompt, model, retries=3):\n    llm = ChatOpenAI(model=model, temperature=0.0)\n    messages_list = messages(prompt, input)\n    response = llm.invoke(messages_list).content.strip()\n    try:\n        obj = json.loads(response)\n        # LLM sometimes returns valid JSON string\n        if isinstance(obj, str):\n            obj = [obj]\n        items = [a.strip() for a in obj]\n        items = filter(None, items)  # omit empty strings\n        return items\n    except json.decoder.JSONDecodeError as e:\n        print(\"JSON error:\", e)\n        print(\"Input was:\", input)\n        print(\"Response was:\", response)\n        if retries \u003e 0:\n            print(\"Retrying...\")\n            return extract_arguments(input, prompt, model, retries - 1)\n        else:\n            print(\"Silently giving up on trying to generate valid list.\")\n            return []","prompt":"/system\n\nあなたはプロのリサーチアシスタントであり、私の仕事は論拠のきれいなデータセットを準備することです。\n\n背景として、私はCreative MTGに参加した人のコメントを集めています。\nCreative MTGでは、「AkeruE」、「マクセル×SHIOMER」という2つのプロジェクトが、プロジェクトを進める上で使った「技」についてプレゼンテーションを行いました。\nCreative MTGでどのような反応があったのかを分類するお手伝いをしていただきたいです。\nこれから与えるのはCreative MTGに参加した人のコメントのリストです。\nこれから与える投稿をJSONリストとして返してください。\n本当に必要な場合は、2つ以上の別々の意見に分けることもできるが、1つのトピックを返すのが最善であることが多いでしょう。\n以下にポストを要約する際の事例を挙げます。\nこれらはあくまで文脈の切り離された例であり、この例で与えた文章を返すことはしないでください。\n\n結果は、きちんとフォーマットされた文字列形式（strings）のJSONリストとして返してください。\n\n\n/human\n\n気候変動を考慮したさらなる風水害対策の強化について、都の具体的な計画をお伺いします。\n\n/ai \n\n[\n  \"気候変動を考慮したさらなる風水害対策の強化について、都の具体的な計画をお伺いします。\"\n]\n\n/human \n\n豪雨対策全般の基本方針の検討を進める中、具体的にどのような施策を作ってほしい。\n\n/ai \n\n[\n  \"豪雨対策全般の基本方針の検討を進める中、具体的にどのような施策を作ってほしい。\",\n]\n\n/human\n\nAI技術は、そのライフサイクルにおける環境負荷の低減に重点を置いて開発されるべきである。\n\n/ai\n\n[\n  \"AI技術は、そのライフサイクルにおける環境負荷の低減に重点を置いて開発されるべきである。\"\n]\n\n\n/human\n\nいい\n\n/ai\n\n[\n  \"いい\"\n]\n\n/human\n\nあとで読む\n\n/ai\n\n[\n  \"あとで読む\"\n]\n\n/human\n\n読んだ\n\n/ai\n\n[\n  \"読んだ\"\n]\n\n/human\n\n期待\n\n/ai\n\n[\n  \"期待\"\n]","model":"gpt-4o-mini"},"clustering":{"clusters":6,"source_code":"import pandas as pd\nimport numpy as np\nfrom importlib import import_module\nimport MeCab\n\ndef clustering(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/clusters.csv\"\n    arguments_df = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    arguments_array = arguments_df[\"argument\"].values\n\n    embeddings_df = pd.read_pickle(f\"outputs/{dataset}/embeddings.pkl\")\n    embeddings_array = np.asarray(embeddings_df[\"embedding\"].values.tolist())\n    clusters = config['clustering']['clusters']\n\n    result = cluster_embeddings(\n        docs=arguments_array,\n        embeddings=embeddings_array,\n        metadatas={\n            \"arg-id\": arguments_df[\"arg-id\"].values,\n            \"comment-id\": arguments_df[\"comment-id\"].values,\n        },\n        n_topics=clusters,\n    )\n    result.to_csv(path, index=False)\n\n\ndef cluster_embeddings(\n    docs,\n    embeddings,\n    metadatas,\n    min_cluster_size=2,\n    n_components=2,\n    n_topics=6,\n):\n    # 必要なモジュールのインポート\n    SpectralClustering = import_module('sklearn.cluster').SpectralClustering\n    HDBSCAN = import_module('hdbscan').HDBSCAN\n    UMAP = import_module('umap').UMAP\n    CountVectorizer = import_module('sklearn.feature_extraction.text').CountVectorizer\n    BERTopic = import_module('bertopic').BERTopic\n\n    # NEologdの辞書パスを指定\n    neologd_path = '/usr/local/lib/mecab/dic/mecab-ipadic-neologd'\n    mecab = MeCab.Tagger(f\"-d {neologd_path} -Ochasen\")\n\n    # 品詞フィルタリングを行うトークナイザー\n    def tokenizer_mecab(text):\n        node = mecab.parseToNode(text)\n        words = []\n        while node:\n            # 名詞、動詞、形容詞だけを抽出する\n            if node.feature.startswith('名詞') or node.feature.startswith('動詞') or node.feature.startswith('形容詞'):\n                words.append(node.surface)\n            node = node.next\n        return words\n\n    umap_model = UMAP(\n        random_state=42,\n        n_components=n_components,\n    )\n    hdbscan_model = HDBSCAN(min_cluster_size=min_cluster_size)\n\n    # 日本語のストップワードリストを作成（必要に応じて拡張可能）\n    japanese_stopwords = [\"これ\", \"それ\", \"あれ\", \"こと\", \"もの\", \"ため\", \"よう\", \"さん\", \"する\", \"なる\", \"ある\", \"いる\"]\n\n    # 日本語トークナイザーとストップワードを使用する\n    vectorizer_model = CountVectorizer(tokenizer=tokenizer_mecab, stop_words=japanese_stopwords)\n\n    topic_model = BERTopic(\n        umap_model=umap_model,\n        hdbscan_model=hdbscan_model,\n        vectorizer_model=vectorizer_model,\n        verbose=True,\n    )\n\n    # トピックモデルのフィッティング\n    _, __ = topic_model.fit_transform(docs, embeddings=embeddings)\n\n    n_samples = len(embeddings)\n    n_neighbors = min(n_samples - 1, 10)\n    spectral_model = SpectralClustering(\n        n_clusters=n_topics,\n        affinity=\"nearest_neighbors\",\n        n_neighbors=n_neighbors,\n        random_state=42\n    )\n    umap_embeds = umap_model.fit_transform(embeddings)\n    cluster_labels = spectral_model.fit_predict(umap_embeds)\n\n    result = topic_model.get_document_info(\n        docs=docs,\n        metadata={\n            **metadatas,\n            \"x\": umap_embeds[:, 0],\n            \"y\": umap_embeds[:, 1],\n        },\n    )\n\n    result.columns = [c.lower() for c in result.columns]\n    result = result[['arg-id', 'x', 'y', 'probability']]\n    result['cluster-id'] = cluster_labels\n\n    return result"},"intro":"このレポートは、Slidoに集まったコメントを元にAIによって生成されました。","output_dir":"CreativeMTG-20250123","previous":{"name":"Creative MTG 反応まとめ","question":"Creative MTGの参加者の反応にはどういう傾向があったのか","input":"CreativeMTG-20250123","model":"gpt-4o-mini","extraction":{"workers":3,"limit":80,"source_code":"import os\nimport json\nfrom tqdm import tqdm\nimport pandas as pd\nfrom langchain_openai import ChatOpenAI\nfrom utils import messages, update_progress\nimport concurrent.futures\n\n\ndef extraction(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/args.csv\"\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n\n    model = config['extraction']['model']\n    prompt = config['extraction']['prompt']\n    workers = config['extraction']['workers']\n    limit = config['extraction']['limit']\n\n    comment_ids = (comments['comment-id'].values)[:limit]\n    comments.set_index('comment-id', inplace=True)\n    results = pd.DataFrame()\n    update_progress(config, total=len(comment_ids))\n    for i in tqdm(range(0, len(comment_ids), workers)):\n        batch = comment_ids[i: i + workers]\n        batch_inputs = [comments.loc[id]['comment-body'] for id in batch]\n        batch_results = extract_batch(batch_inputs, prompt, model, workers)\n        for comment_id, extracted_args in zip(batch, batch_results):\n            for j, arg in enumerate(extracted_args):\n                new_row = {\"arg-id\": f\"A{comment_id}_{j}\",\n                           \"comment-id\": int(comment_id), \"argument\": arg}\n                results = pd.concat(\n                    [results, pd.DataFrame([new_row])], ignore_index=True)\n        update_progress(config, incr=len(batch))\n    results.to_csv(path, index=False)\n\n\ndef extract_batch(batch, prompt, model, workers):\n    with concurrent.futures.ThreadPoolExecutor(max_workers=workers) as executor:\n        futures = [executor.submit(\n            extract_arguments, input, prompt, model) for input in list(batch)]\n        concurrent.futures.wait(futures)\n        return [future.result() for future in futures]\n\n\ndef extract_arguments(input, prompt, model, retries=3):\n    llm = ChatOpenAI(model=model, temperature=0.0)\n    messages_list = messages(prompt, input)\n    response = llm.invoke(messages_list).content.strip()\n    try:\n        obj = json.loads(response)\n        # LLM sometimes returns valid JSON string\n        if isinstance(obj, str):\n            obj = [obj]\n        items = [a.strip() for a in obj]\n        items = filter(None, items)  # omit empty strings\n        return items\n    except json.decoder.JSONDecodeError as e:\n        print(\"JSON error:\", e)\n        print(\"Input was:\", input)\n        print(\"Response was:\", response)\n        if retries \u003e 0:\n            print(\"Retrying...\")\n            return extract_arguments(input, prompt, model, retries - 1)\n        else:\n            print(\"Silently giving up on trying to generate valid list.\")\n            return []","prompt":"/system\n\nあなたはプロのリサーチアシスタントであり、私の仕事は論拠のきれいなデータセットを準備することです。\n\n背景として、私はCreative MTGに参加した人のコメントを集めています。\nCreative MTGでは、「AkeruE」、「マクセル×SHIOMER」という2つのプロジェクトが、プロジェクトを進める上で使った「技」についてプレゼンテーションを行いました。\nCreative MTGでどのような反応があったのかを分類するお手伝いをしていただきたいです。\nこれから与えるのはCreative MTGに参加した人のコメントのリストです。\nこれから与える投稿をJSONリストとして返してください。\n本当に必要な場合は、2つ以上の別々の意見に分けることもできるが、1つのトピックを返すのが最善であることが多いでしょう。\n以下にポストを要約する際の事例を挙げます。\nこれらはあくまで文脈の切り離された例であり、この例で与えた文章を返すことはしないでください。\n\n結果は、きちんとフォーマットされた文字列形式（strings）のJSONリストとして返してください。\n\n\n/human\n\n気候変動を考慮したさらなる風水害対策の強化について、都の具体的な計画をお伺いします。\n\n/ai \n\n[\n  \"気候変動を考慮したさらなる風水害対策の強化について、都の具体的な計画をお伺いします。\"\n]\n\n/human \n\n豪雨対策全般の基本方針の検討を進める中、具体的にどのような施策を作ってほしい。\n\n/ai \n\n[\n  \"豪雨対策全般の基本方針の検討を進める中、具体的にどのような施策を作ってほしい。\",\n]\n\n/human\n\nAI技術は、そのライフサイクルにおける環境負荷の低減に重点を置いて開発されるべきである。\n\n/ai\n\n[\n  \"AI技術は、そのライフサイクルにおける環境負荷の低減に重点を置いて開発されるべきである。\"\n]\n\n\n/human\n\nいい\n\n/ai\n\n[\n  \"いい\"\n]\n\n/human\n\nあとで読む\n\n/ai\n\n[\n  \"あとで読む\"\n]\n\n/human\n\n読んだ\n\n/ai\n\n[\n  \"読んだ\"\n]\n\n/human\n\n期待\n\n/ai\n\n[\n  \"期待\"\n]","model":"gpt-4o-mini"},"clustering":{"clusters":5,"source_code":"import pandas as pd\nimport numpy as np\nfrom importlib import import_module\nimport MeCab\n\ndef clustering(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/clusters.csv\"\n    arguments_df = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    arguments_array = arguments_df[\"argument\"].values\n\n    embeddings_df = pd.read_pickle(f\"outputs/{dataset}/embeddings.pkl\")\n    embeddings_array = np.asarray(embeddings_df[\"embedding\"].values.tolist())\n    clusters = config['clustering']['clusters']\n\n    result = cluster_embeddings(\n        docs=arguments_array,\n        embeddings=embeddings_array,\n        metadatas={\n            \"arg-id\": arguments_df[\"arg-id\"].values,\n            \"comment-id\": arguments_df[\"comment-id\"].values,\n        },\n        n_topics=clusters,\n    )\n    result.to_csv(path, index=False)\n\n\ndef cluster_embeddings(\n    docs,\n    embeddings,\n    metadatas,\n    min_cluster_size=2,\n    n_components=2,\n    n_topics=6,\n):\n    # 必要なモジュールのインポート\n    SpectralClustering = import_module('sklearn.cluster').SpectralClustering\n    HDBSCAN = import_module('hdbscan').HDBSCAN\n    UMAP = import_module('umap').UMAP\n    CountVectorizer = import_module('sklearn.feature_extraction.text').CountVectorizer\n    BERTopic = import_module('bertopic').BERTopic\n\n    # NEologdの辞書パスを指定\n    neologd_path = '/usr/local/lib/mecab/dic/mecab-ipadic-neologd'\n    mecab = MeCab.Tagger(f\"-d {neologd_path} -Ochasen\")\n\n    # 品詞フィルタリングを行うトークナイザー\n    def tokenizer_mecab(text):\n        node = mecab.parseToNode(text)\n        words = []\n        while node:\n            # 名詞、動詞、形容詞だけを抽出する\n            if node.feature.startswith('名詞') or node.feature.startswith('動詞') or node.feature.startswith('形容詞'):\n                words.append(node.surface)\n            node = node.next\n        return words\n\n    umap_model = UMAP(\n        random_state=42,\n        n_components=n_components,\n    )\n    hdbscan_model = HDBSCAN(min_cluster_size=min_cluster_size)\n\n    # 日本語のストップワードリストを作成（必要に応じて拡張可能）\n    japanese_stopwords = [\"これ\", \"それ\", \"あれ\", \"こと\", \"もの\", \"ため\", \"よう\", \"さん\", \"する\", \"なる\", \"ある\", \"いる\"]\n\n    # 日本語トークナイザーとストップワードを使用する\n    vectorizer_model = CountVectorizer(tokenizer=tokenizer_mecab, stop_words=japanese_stopwords)\n\n    topic_model = BERTopic(\n        umap_model=umap_model,\n        hdbscan_model=hdbscan_model,\n        vectorizer_model=vectorizer_model,\n        verbose=True,\n    )\n\n    # トピックモデルのフィッティング\n    _, __ = topic_model.fit_transform(docs, embeddings=embeddings)\n\n    n_samples = len(embeddings)\n    n_neighbors = min(n_samples - 1, 10)\n    spectral_model = SpectralClustering(\n        n_clusters=n_topics,\n        affinity=\"nearest_neighbors\",\n        n_neighbors=n_neighbors,\n        random_state=42\n    )\n    umap_embeds = umap_model.fit_transform(embeddings)\n    cluster_labels = spectral_model.fit_predict(umap_embeds)\n\n    result = topic_model.get_document_info(\n        docs=docs,\n        metadata={\n            **metadatas,\n            \"x\": umap_embeds[:, 0],\n            \"y\": umap_embeds[:, 1],\n        },\n    )\n\n    result.columns = [c.lower() for c in result.columns]\n    result = result[['arg-id', 'x', 'y', 'probability']]\n    result['cluster-id'] = cluster_labels\n\n    return result"},"intro":"このレポートは、Slidoに集まったコメントを元にAIによって生成されました。","output_dir":"CreativeMTG-20250123","embedding":{"source_code":"from langchain_openai import OpenAIEmbeddings\nfrom langchain_community.chat_models import ChatOpenAI\nimport pandas as pd\nfrom tqdm import tqdm\n\n\ndef embedding(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/embeddings.pkl\"\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    embeddings = []\n    for i in tqdm(range(0, len(arguments), 1000)):\n        args = arguments[\"argument\"].tolist()[i: i + 1000]\n        embeddings_model = OpenAIEmbeddings()\n        embeds = embeddings_model.embed_documents(args)\n\n        embeddings.extend(embeds)\n    df = pd.DataFrame(\n        [\n            {\"arg-id\": arguments.iloc[i][\"arg-id\"], \"embedding\": e}\n            for i, e in enumerate(embeddings)\n        ]\n    )\n    df.to_pickle(path)"},"labelling":{"sample_size":30,"source_code":"\"\"\"Create labels for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain_openai import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef labelling(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/labels.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['labelling']['sample_size']\n    prompt = config['labelling']['prompt']\n    model = config['labelling']['model']\n\n    question = config['question']\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n\n        args_ids_outside = clusters[clusters['cluster-id']\n                                    != cluster_id]['arg-id'].values\n        args_ids_outside = np.random.choice(args_ids_outside, size=min(\n            len(args_ids_outside), sample_size), replace=False)\n        args_sample_outside = arguments[arguments['arg-id']\n                                        .isin(args_ids_outside)]['argument'].values\n\n        label = generate_label(question, args_sample,\n                               args_sample_outside, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'label': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_label(question, args_sample, args_sample_outside, prompt, model):\n    llm = ChatOpenAI(model=model, temperature=0.0)\n    outside = '\\n * ' + '\\n * '.join(args_sample_outside)\n    inside = '\\n * ' + '\\n * '.join(args_sample)\n    input = f\"Question of the consultation:{question}\\n\\n\" + \\\n        f\"Examples of arguments OUTSIDE the cluster:\\n {outside}\" + \\\n        f\"Examples of arguments INSIDE the cluster:\\n {inside}\"\n    response = llm.invoke(input=messages(prompt, input)).content.strip()\n\n    return response","prompt":"/system \n\nあなたは、Creative MTGに関する一連のコメントに対するカテゴリラベルを生成するカテゴリラベリングアシスタントです。\nCreative MTGでは、「AkeruE」、「マクセル×SHIOMER」という2つのプロジェクトが、プロジェクトを進める上で使った「技」についてプレゼンテーションを行いました。\nあなたには、相談の主な質問、クラスタ内の議論のリスト、およびこのクラスタ外の議論のリストが与えられます。あなたはクラスターを要約する1つのカテゴリーラベルで回答します。\n\n質問からすでに明らかな文脈は含めない（「Creative MTGの参加者の反応にはどういう傾向があったのか」のようなものであれば、クラスターのラベルに「Creative MTGの参加者の反応」と繰り返す必要はない）。\n\nラベルは非常に簡潔でなければならず、クラスターとその外側にある論点を区別するのに十分な正確さでなければならない。\nラベルは全て重複してはならない。\n「参加者の反応の傾向」「参加者の具体的な反応」のようなものはやめてください。\n具体的にどんな話に注目が集まったかを知りたいです。\nクラスター外の論点と明確に区別されるようなラベルを回答してください。\n\n/human\n\nコンサルテーションの質問 「英国のEU離脱決定の影響は何だと思いますか？\n\n関心のあるクラスター以外の論点の例\n\n * エラスムス・プログラムからの除外により、教育・文化交流の機会が制限された。\n * 英国は、国境検問の強化による旅行時間の延長に対処し、通勤客や旅行客に影響を与えた。\n * 環境基準における協力が減少し、気候変動と闘う努力が妨げられた。\n * 相互医療協定の中断により、患者ケアに課題を感じた。\n * Brexit関連の変更により、家族の居住権や市民権の申請が複雑になった。\n * 英国は、共同研究機会の減少により、研究の課題に取り組む世界的な取り組みに支障をきたすことを目の当たりにした。\n * EUの文化助成プログラムからの除外により、創造的なプロジェクトの制限に直面した。\n * 英国は、EUの資金提供の喪失により、慈善活動やコミュニティ支援の後退を目の当たりにした。\n * 消費者保護の弱体化により、国境を越えた紛争解決に課題が生じた。\n * 英国はプロの音楽家としてEU諸国をツアーする際の制限に直面し、キャリアに影響を与えた。\n\nクラスター内部での議論の例\n\n * Brexitによりサプライチェーンが混乱し、企業にとってコスト増と納期遅延につながった。\n * ブレグジットのため、市場の変動や投資・退職金の不確実性に直面した。\n * 新たな関税や通関手続きにより、英国は輸出業者として利益率の低下に対処した。\n * ブレグジット後、企業がEU市場内にとどまるために事業を移転したため、雇用を失った。\n * 英国は輸入品価格の高騰による生活費の増加に苦しんだ。\n * 英国のハイテク産業への投資が減少し、技術革新と雇用機会に影響を与えた。\n * 新たなビザ規制による観光客の減少を目の当たりにし、接客業に影響。\n * ポンド価値の下落により購買力が低下し、旅費が増加した。\n\n\n/ai \n\n財務上のマイナス影響","model":"gpt-4o-mini"},"takeaways":{"sample_size":30,"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain_community.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef takeaways(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/takeaways.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['takeaways']['sample_size']\n    prompt = config['takeaways']['prompt']\n    model = config['takeaways']['model']\n\n    model = config.get('model_takeaways', config.get('model', 'gpt3.5-turbo'))\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n        label = generate_takeaways(args_sample, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'takeaways': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_takeaways(args_sample, prompt, model):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    input = \"\\n\".join(args_sample)\n    response = llm.invoke(input=messages(prompt, input)).content.strip()\n    return response","prompt":"/system \n\nあなたはシンクタンクで働くリサーチアシスタントのエキスパートです。Creative MTGに参加した人のコメントのリストが渡されます。\nCreative MTGでは、「AkeruE」、「マクセル×SHIOMER」という2つのプロジェクトが、プロジェクトを進める上で使った「技」についてプレゼンテーションを行いました。\nあなたは、どんな話に注目が集まったか、主な要点を1~2段落にまとめて回答します。あなたは簡潔で読みやすい短い文章を書くことができます。 \n \n/human\n\n[\n  \"銃による暴力は、私たちの社会における深刻な公衆衛生の危機を構成していると固く信じています。\",\n  \"包括的な銃規制策を通じて、この問題に早急に取り組む必要がある。\",\n  \"すべての銃購入者に対する身元調査の実施を支持します。\",\n  \"アサルト・ウェポンと大容量弾倉の禁止に賛成します。\",\n  \"違法な銃の売買を防ぐため、より厳しい規制を提唱します。\",\n  \"銃の購入プロセスにおいて、精神鑑定を義務付けるべきである。\"\n]\n\n/ai \n\n参加者は、包括的な銃規制を求め、普遍的な身元調査、突撃兵器の禁止、違法な銃売買の抑制、精神衛生評価の優先などを強調した。","model":"gpt-4o-mini"},"overview":{"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain_community.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef overview(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/overview.txt\"\n\n    takeaways = pd.read_csv(f\"outputs/{dataset}/takeaways.csv\")\n    labels = pd.read_csv(f\"outputs/{dataset}/labels.csv\")\n\n    prompt = config['overview']['prompt']\n    model = config['overview']['model']\n\n    ids = labels['cluster-id'].to_list()\n    takeaways.set_index('cluster-id', inplace=True)\n    labels.set_index('cluster-id', inplace=True)\n\n    input = ''\n    for i, id in enumerate(ids):\n        input += f\"# Cluster {i}/{len(ids)}: {labels.loc[id]['label']}\\n\\n\"\n        input += takeaways.loc[id]['takeaways'] + '\\n\\n'\n\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    response = llm(messages=messages(prompt, input)).content.strip()\n\n    with open(path, 'w') as file:\n        file.write(response)","prompt":"/system \nあなたはシンクタンクで働く専門家リサーチアシスタントです。あなたのチームは、あるトピックに関する公開コンサルテーションを実施し、さまざまな選択肢のクラスターを分析し始めました。あなたは今、クラスターのリストと各クラスターの簡単な分析を受け取ります。あなたの仕事は、CreativeMTGでどんな話に注目が集まったかを簡潔にまとめることです。あなたの要約は非常に簡潔でなければならず（せいぜい1段落、せいぜい4文）、平凡な表現は避けなければなりません。\n補足として、Creative MTGでは、「AkeruE」、「マクセル×SHIOMER」という2つのプロジェクトが、プロジェクトを進める上で使った「技」についてプレゼンテーションを行いました。","model":"gpt-4o-mini"},"aggregation":{"source_code":"\"\"\"Generate a convenient JSON output file.\"\"\"\n\nfrom tqdm import tqdm\nfrom typing import List\nimport pandas as pd\nfrom langchain_community.chat_models import ChatOpenAI\nimport json\n\n\ndef aggregation(config):\n\n    path = f\"outputs/{config['output_dir']}/result.json\"\n\n    results = {\n        \"clusters\": [],\n        \"comments\": {},\n        \"overview\": \"\",\n        \"config\": config,\n    }\n\n    arguments = pd.read_csv(f\"outputs/{config['output_dir']}/args.csv\")\n    arguments.set_index('arg-id', inplace=True)\n\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n    useful_comment_ids = set(arguments['comment-id'].values)\n    for _, row in comments.iterrows():\n        id = row['comment-id']\n        if id in useful_comment_ids:\n            res = {'comment': row['comment-body']}\n            numeric_cols = ['agrees', 'disagrees']\n            string_cols = ['video', 'interview', 'timestamp']\n            for col in numeric_cols:\n                if col in row:\n                    res[col] = float(row[col])\n            for col in string_cols:\n                if col in row:\n                    res[col] = row[col]\n            results['comments'][str(id)] = res\n\n    languages = list(config.get('translation', {}).get('languages', []))\n    if len(languages) \u003e 0:\n        with open(f\"outputs/{config['output_dir']}/translations.json\") as f:\n            translations = f.read()\n        results['translations'] = json.loads(translations)\n\n    clusters = pd.read_csv(f\"outputs/{config['output_dir']}/clusters.csv\")\n    labels = pd.read_csv(f\"outputs/{config['output_dir']}/labels.csv\")\n    takeaways = pd.read_csv(f\"outputs/{config['output_dir']}/takeaways.csv\")\n    takeaways.set_index('cluster-id', inplace=True)\n\n    with open(f\"outputs/{config['output_dir']}/overview.txt\") as f:\n        overview = f.read()\n    results['overview'] = overview\n\n    for _, row in labels.iterrows():\n        cid = row['cluster-id']\n        label = row['label']\n        arg_rows = clusters[clusters['cluster-id'] == cid]\n        arguments_in_cluster = []\n        for _, arg_row in arg_rows.iterrows():\n            arg_id = arg_row['arg-id']\n            argument = arguments.loc[arg_id]['argument']\n            comment_id = arguments.loc[arg_id]['comment-id']\n            x = float(arg_row['x'])\n            y = float(arg_row['y'])\n            p = float(arg_row['probability'])\n            obj = {\n                'arg_id': arg_id,\n                'argument': argument,\n                'comment_id': str(comment_id),\n                'x': x,\n                'y': y,\n                'p': p,\n            }\n            arguments_in_cluster.append(obj)\n        results['clusters'].append({\n            'cluster': label,\n            'cluster_id': str(cid),\n            'takeaways': takeaways.loc[cid]['takeaways'],\n            'arguments': arguments_in_cluster\n        })\n\n    with open(path, 'w') as file:\n        json.dump(results, file, indent=2)\n"},"visualization":{"replacements":[],"source_code":"\nimport subprocess\n\n\ndef visualization(config):\n    output_dir = config['output_dir']\n    with open(f\"outputs/{output_dir}/result.json\") as f:\n        result = f.read()\n\n    cwd = \"../next-app\"\n    command = f\"REPORT={output_dir} npm run build\"\n\n    try:\n        process = subprocess.Popen(command, shell=True, cwd=cwd, stdout=subprocess.PIPE,\n                                   stderr=subprocess.PIPE, universal_newlines=True)\n        while True:\n            output_line = process.stdout.readline()\n            if output_line == '' and process.poll() is not None:\n                break\n            if output_line:\n                print(output_line.strip())\n        process.wait()\n        errors = process.stderr.read()\n        if errors:\n            print(\"Errors:\")\n            print(errors)\n    except subprocess.CalledProcessError as e:\n        print(\"Error: \", e)\n"},"plan":[{"step":"extraction","run":true,"reason":"some parameters changed: prompt"},{"step":"embedding","run":true,"reason":"some dependent steps will re-run: extraction"},{"step":"clustering","run":true,"reason":"some dependent steps will re-run: embedding"},{"step":"labelling","run":true,"reason":"some dependent steps will re-run: clustering"},{"step":"takeaways","run":true,"reason":"some dependent steps will re-run: clustering"},{"step":"overview","run":true,"reason":"some dependent steps will re-run: labelling, takeaways"},{"step":"aggregation","run":true,"reason":"some dependent steps will re-run: extraction, clustering, labelling, takeaways, overview"},{"step":"visualization","run":true,"reason":"some dependent steps will re-run: aggregation"}],"status":"completed","start_time":"2025-01-24T18:34:47.570221","completed_jobs":[{"step":"extraction","completed":"2025-01-24T18:36:14.152792","duration":86.575595,"params":{"workers":3,"limit":80,"source_code":"import os\nimport json\nfrom tqdm import tqdm\nimport pandas as pd\nfrom langchain_openai import ChatOpenAI\nfrom utils import messages, update_progress\nimport concurrent.futures\n\n\ndef extraction(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/args.csv\"\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n\n    model = config['extraction']['model']\n    prompt = config['extraction']['prompt']\n    workers = config['extraction']['workers']\n    limit = config['extraction']['limit']\n\n    comment_ids = (comments['comment-id'].values)[:limit]\n    comments.set_index('comment-id', inplace=True)\n    results = pd.DataFrame()\n    update_progress(config, total=len(comment_ids))\n    for i in tqdm(range(0, len(comment_ids), workers)):\n        batch = comment_ids[i: i + workers]\n        batch_inputs = [comments.loc[id]['comment-body'] for id in batch]\n        batch_results = extract_batch(batch_inputs, prompt, model, workers)\n        for comment_id, extracted_args in zip(batch, batch_results):\n            for j, arg in enumerate(extracted_args):\n                new_row = {\"arg-id\": f\"A{comment_id}_{j}\",\n                           \"comment-id\": int(comment_id), \"argument\": arg}\n                results = pd.concat(\n                    [results, pd.DataFrame([new_row])], ignore_index=True)\n        update_progress(config, incr=len(batch))\n    results.to_csv(path, index=False)\n\n\ndef extract_batch(batch, prompt, model, workers):\n    with concurrent.futures.ThreadPoolExecutor(max_workers=workers) as executor:\n        futures = [executor.submit(\n            extract_arguments, input, prompt, model) for input in list(batch)]\n        concurrent.futures.wait(futures)\n        return [future.result() for future in futures]\n\n\ndef extract_arguments(input, prompt, model, retries=3):\n    llm = ChatOpenAI(model=model, temperature=0.0)\n    messages_list = messages(prompt, input)\n    response = llm.invoke(messages_list).content.strip()\n    try:\n        obj = json.loads(response)\n        # LLM sometimes returns valid JSON string\n        if isinstance(obj, str):\n            obj = [obj]\n        items = [a.strip() for a in obj]\n        items = filter(None, items)  # omit empty strings\n        return items\n    except json.decoder.JSONDecodeError as e:\n        print(\"JSON error:\", e)\n        print(\"Input was:\", input)\n        print(\"Response was:\", response)\n        if retries \u003e 0:\n            print(\"Retrying...\")\n            return extract_arguments(input, prompt, model, retries - 1)\n        else:\n            print(\"Silently giving up on trying to generate valid list.\")\n            return []","prompt":"/system\n\nあなたはプロのリサーチアシスタントであり、私の仕事は論拠のきれいなデータセットを準備することです。\n\n背景として、私はCreative MTGに参加した人のコメントを集めています。\nCreative MTGでは、「AkeruE」、「マクセル×SHIOMER」という2つのプロジェクトが、プロジェクトを進める上で使った「技」についてプレゼンテーションを行いました。\nCreative MTGでどのような反応があったのかを分類するお手伝いをしていただきたいです。\nこれから与えるのはCreative MTGに参加した人のコメントのリストです。\nこれから与える投稿をJSONリストとして返してください。\n本当に必要な場合は、2つ以上の別々の意見に分けることもできるが、1つのトピックを返すのが最善であることが多いでしょう。\n以下にポストを要約する際の事例を挙げます。\nこれらはあくまで文脈の切り離された例であり、この例で与えた文章を返すことはしないでください。\n\n結果は、きちんとフォーマットされた文字列形式（strings）のJSONリストとして返してください。\n\n\n/human\n\n気候変動を考慮したさらなる風水害対策の強化について、都の具体的な計画をお伺いします。\n\n/ai \n\n[\n  \"気候変動を考慮したさらなる風水害対策の強化について、都の具体的な計画をお伺いします。\"\n]\n\n/human \n\n豪雨対策全般の基本方針の検討を進める中、具体的にどのような施策を作ってほしい。\n\n/ai \n\n[\n  \"豪雨対策全般の基本方針の検討を進める中、具体的にどのような施策を作ってほしい。\",\n]\n\n/human\n\nAI技術は、そのライフサイクルにおける環境負荷の低減に重点を置いて開発されるべきである。\n\n/ai\n\n[\n  \"AI技術は、そのライフサイクルにおける環境負荷の低減に重点を置いて開発されるべきである。\"\n]\n\n\n/human\n\nいい\n\n/ai\n\n[\n  \"いい\"\n]\n\n/human\n\nあとで読む\n\n/ai\n\n[\n  \"あとで読む\"\n]\n\n/human\n\n読んだ\n\n/ai\n\n[\n  \"読んだ\"\n]\n\n/human\n\n期待\n\n/ai\n\n[\n  \"期待\"\n]","model":"gpt-4o-mini"}},{"step":"embedding","completed":"2025-01-24T18:36:16.303376","duration":2.147389,"params":{"source_code":"from langchain_openai import OpenAIEmbeddings\nfrom langchain_community.chat_models import ChatOpenAI\nimport pandas as pd\nfrom tqdm import tqdm\n\n\ndef embedding(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/embeddings.pkl\"\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    embeddings = []\n    for i in tqdm(range(0, len(arguments), 1000)):\n        args = arguments[\"argument\"].tolist()[i: i + 1000]\n        embeddings_model = OpenAIEmbeddings()\n        embeds = embeddings_model.embed_documents(args)\n\n        embeddings.extend(embeds)\n    df = pd.DataFrame(\n        [\n            {\"arg-id\": arguments.iloc[i][\"arg-id\"], \"embedding\": e}\n            for i, e in enumerate(embeddings)\n        ]\n    )\n    df.to_pickle(path)"}},{"step":"clustering","completed":"2025-01-24T18:36:49.118022","duration":32.813041,"params":{"clusters":5,"source_code":"import pandas as pd\nimport numpy as np\nfrom importlib import import_module\nimport MeCab\n\ndef clustering(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/clusters.csv\"\n    arguments_df = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    arguments_array = arguments_df[\"argument\"].values\n\n    embeddings_df = pd.read_pickle(f\"outputs/{dataset}/embeddings.pkl\")\n    embeddings_array = np.asarray(embeddings_df[\"embedding\"].values.tolist())\n    clusters = config['clustering']['clusters']\n\n    result = cluster_embeddings(\n        docs=arguments_array,\n        embeddings=embeddings_array,\n        metadatas={\n            \"arg-id\": arguments_df[\"arg-id\"].values,\n            \"comment-id\": arguments_df[\"comment-id\"].values,\n        },\n        n_topics=clusters,\n    )\n    result.to_csv(path, index=False)\n\n\ndef cluster_embeddings(\n    docs,\n    embeddings,\n    metadatas,\n    min_cluster_size=2,\n    n_components=2,\n    n_topics=6,\n):\n    # 必要なモジュールのインポート\n    SpectralClustering = import_module('sklearn.cluster').SpectralClustering\n    HDBSCAN = import_module('hdbscan').HDBSCAN\n    UMAP = import_module('umap').UMAP\n    CountVectorizer = import_module('sklearn.feature_extraction.text').CountVectorizer\n    BERTopic = import_module('bertopic').BERTopic\n\n    # NEologdの辞書パスを指定\n    neologd_path = '/usr/local/lib/mecab/dic/mecab-ipadic-neologd'\n    mecab = MeCab.Tagger(f\"-d {neologd_path} -Ochasen\")\n\n    # 品詞フィルタリングを行うトークナイザー\n    def tokenizer_mecab(text):\n        node = mecab.parseToNode(text)\n        words = []\n        while node:\n            # 名詞、動詞、形容詞だけを抽出する\n            if node.feature.startswith('名詞') or node.feature.startswith('動詞') or node.feature.startswith('形容詞'):\n                words.append(node.surface)\n            node = node.next\n        return words\n\n    umap_model = UMAP(\n        random_state=42,\n        n_components=n_components,\n    )\n    hdbscan_model = HDBSCAN(min_cluster_size=min_cluster_size)\n\n    # 日本語のストップワードリストを作成（必要に応じて拡張可能）\n    japanese_stopwords = [\"これ\", \"それ\", \"あれ\", \"こと\", \"もの\", \"ため\", \"よう\", \"さん\", \"する\", \"なる\", \"ある\", \"いる\"]\n\n    # 日本語トークナイザーとストップワードを使用する\n    vectorizer_model = CountVectorizer(tokenizer=tokenizer_mecab, stop_words=japanese_stopwords)\n\n    topic_model = BERTopic(\n        umap_model=umap_model,\n        hdbscan_model=hdbscan_model,\n        vectorizer_model=vectorizer_model,\n        verbose=True,\n    )\n\n    # トピックモデルのフィッティング\n    _, __ = topic_model.fit_transform(docs, embeddings=embeddings)\n\n    n_samples = len(embeddings)\n    n_neighbors = min(n_samples - 1, 10)\n    spectral_model = SpectralClustering(\n        n_clusters=n_topics,\n        affinity=\"nearest_neighbors\",\n        n_neighbors=n_neighbors,\n        random_state=42\n    )\n    umap_embeds = umap_model.fit_transform(embeddings)\n    cluster_labels = spectral_model.fit_predict(umap_embeds)\n\n    result = topic_model.get_document_info(\n        docs=docs,\n        metadata={\n            **metadatas,\n            \"x\": umap_embeds[:, 0],\n            \"y\": umap_embeds[:, 1],\n        },\n    )\n\n    result.columns = [c.lower() for c in result.columns]\n    result = result[['arg-id', 'x', 'y', 'probability']]\n    result['cluster-id'] = cluster_labels\n\n    return result"}},{"step":"labelling","completed":"2025-01-24T18:36:54.548469","duration":5.426989,"params":{"sample_size":30,"source_code":"\"\"\"Create labels for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain_openai import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef labelling(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/labels.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['labelling']['sample_size']\n    prompt = config['labelling']['prompt']\n    model = config['labelling']['model']\n\n    question = config['question']\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n\n        args_ids_outside = clusters[clusters['cluster-id']\n                                    != cluster_id]['arg-id'].values\n        args_ids_outside = np.random.choice(args_ids_outside, size=min(\n            len(args_ids_outside), sample_size), replace=False)\n        args_sample_outside = arguments[arguments['arg-id']\n                                        .isin(args_ids_outside)]['argument'].values\n\n        label = generate_label(question, args_sample,\n                               args_sample_outside, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'label': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_label(question, args_sample, args_sample_outside, prompt, model):\n    llm = ChatOpenAI(model=model, temperature=0.0)\n    outside = '\\n * ' + '\\n * '.join(args_sample_outside)\n    inside = '\\n * ' + '\\n * '.join(args_sample)\n    input = f\"Question of the consultation:{question}\\n\\n\" + \\\n        f\"Examples of arguments OUTSIDE the cluster:\\n {outside}\" + \\\n        f\"Examples of arguments INSIDE the cluster:\\n {inside}\"\n    response = llm.invoke(input=messages(prompt, input)).content.strip()\n\n    return response","prompt":"/system \n\nあなたは、Creative MTGに関する一連のコメントに対するカテゴリラベルを生成するカテゴリラベリングアシスタントです。\nCreative MTGでは、「AkeruE」、「マクセル×SHIOMER」という2つのプロジェクトが、プロジェクトを進める上で使った「技」についてプレゼンテーションを行いました。\nあなたには、相談の主な質問、クラスタ内の議論のリスト、およびこのクラスタ外の議論のリストが与えられます。あなたはクラスターを要約する1つのカテゴリーラベルで回答します。\n\n質問からすでに明らかな文脈は含めない（「Creative MTGの参加者の反応にはどういう傾向があったのか」のようなものであれば、クラスターのラベルに「Creative MTGの参加者の反応」と繰り返す必要はない）。\n\nラベルは非常に簡潔でなければならず、クラスターとその外側にある論点を区別するのに十分な正確さでなければならない。\nラベルは全て重複してはならない。\n「参加者の反応の傾向」「参加者の具体的な反応」のようなものはやめてください。\n具体的にどんな話に注目が集まったかを知りたいです。\nクラスター外の論点と明確に区別されるようなラベルを回答してください。\n\n/human\n\nコンサルテーションの質問 「英国のEU離脱決定の影響は何だと思いますか？\n\n関心のあるクラスター以外の論点の例\n\n * エラスムス・プログラムからの除外により、教育・文化交流の機会が制限された。\n * 英国は、国境検問の強化による旅行時間の延長に対処し、通勤客や旅行客に影響を与えた。\n * 環境基準における協力が減少し、気候変動と闘う努力が妨げられた。\n * 相互医療協定の中断により、患者ケアに課題を感じた。\n * Brexit関連の変更により、家族の居住権や市民権の申請が複雑になった。\n * 英国は、共同研究機会の減少により、研究の課題に取り組む世界的な取り組みに支障をきたすことを目の当たりにした。\n * EUの文化助成プログラムからの除外により、創造的なプロジェクトの制限に直面した。\n * 英国は、EUの資金提供の喪失により、慈善活動やコミュニティ支援の後退を目の当たりにした。\n * 消費者保護の弱体化により、国境を越えた紛争解決に課題が生じた。\n * 英国はプロの音楽家としてEU諸国をツアーする際の制限に直面し、キャリアに影響を与えた。\n\nクラスター内部での議論の例\n\n * Brexitによりサプライチェーンが混乱し、企業にとってコスト増と納期遅延につながった。\n * ブレグジットのため、市場の変動や投資・退職金の不確実性に直面した。\n * 新たな関税や通関手続きにより、英国は輸出業者として利益率の低下に対処した。\n * ブレグジット後、企業がEU市場内にとどまるために事業を移転したため、雇用を失った。\n * 英国は輸入品価格の高騰による生活費の増加に苦しんだ。\n * 英国のハイテク産業への投資が減少し、技術革新と雇用機会に影響を与えた。\n * 新たなビザ規制による観光客の減少を目の当たりにし、接客業に影響。\n * ポンド価値の下落により購買力が低下し、旅費が増加した。\n\n\n/ai \n\n財務上のマイナス影響","model":"gpt-4o-mini"}},{"step":"takeaways","completed":"2025-01-24T18:37:15.085204","duration":20.534217,"params":{"sample_size":30,"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain_community.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef takeaways(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/takeaways.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['takeaways']['sample_size']\n    prompt = config['takeaways']['prompt']\n    model = config['takeaways']['model']\n\n    model = config.get('model_takeaways', config.get('model', 'gpt3.5-turbo'))\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n        label = generate_takeaways(args_sample, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'takeaways': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_takeaways(args_sample, prompt, model):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    input = \"\\n\".join(args_sample)\n    response = llm.invoke(input=messages(prompt, input)).content.strip()\n    return response","prompt":"/system \n\nあなたはシンクタンクで働くリサーチアシスタントのエキスパートです。Creative MTGに参加した人のコメントのリストが渡されます。\nCreative MTGでは、「AkeruE」、「マクセル×SHIOMER」という2つのプロジェクトが、プロジェクトを進める上で使った「技」についてプレゼンテーションを行いました。\nあなたは、どんな話に注目が集まったか、主な要点を1~2段落にまとめて回答します。あなたは簡潔で読みやすい短い文章を書くことができます。 \n \n/human\n\n[\n  \"銃による暴力は、私たちの社会における深刻な公衆衛生の危機を構成していると固く信じています。\",\n  \"包括的な銃規制策を通じて、この問題に早急に取り組む必要がある。\",\n  \"すべての銃購入者に対する身元調査の実施を支持します。\",\n  \"アサルト・ウェポンと大容量弾倉の禁止に賛成します。\",\n  \"違法な銃の売買を防ぐため、より厳しい規制を提唱します。\",\n  \"銃の購入プロセスにおいて、精神鑑定を義務付けるべきである。\"\n]\n\n/ai \n\n参加者は、包括的な銃規制を求め、普遍的な身元調査、突撃兵器の禁止、違法な銃売買の抑制、精神衛生評価の優先などを強調した。","model":"gpt-4o-mini"}},{"step":"overview","completed":"2025-01-24T18:37:19.235863","duration":4.147972,"params":{"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain_community.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef overview(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/overview.txt\"\n\n    takeaways = pd.read_csv(f\"outputs/{dataset}/takeaways.csv\")\n    labels = pd.read_csv(f\"outputs/{dataset}/labels.csv\")\n\n    prompt = config['overview']['prompt']\n    model = config['overview']['model']\n\n    ids = labels['cluster-id'].to_list()\n    takeaways.set_index('cluster-id', inplace=True)\n    labels.set_index('cluster-id', inplace=True)\n\n    input = ''\n    for i, id in enumerate(ids):\n        input += f\"# Cluster {i}/{len(ids)}: {labels.loc[id]['label']}\\n\\n\"\n        input += takeaways.loc[id]['takeaways'] + '\\n\\n'\n\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    response = llm(messages=messages(prompt, input)).content.strip()\n\n    with open(path, 'w') as file:\n        file.write(response)","prompt":"/system \nあなたはシンクタンクで働く専門家リサーチアシスタントです。あなたのチームは、あるトピックに関する公開コンサルテーションを実施し、さまざまな選択肢のクラスターを分析し始めました。あなたは今、クラスターのリストと各クラスターの簡単な分析を受け取ります。あなたの仕事は、CreativeMTGでどんな話に注目が集まったかを簡潔にまとめることです。あなたの要約は非常に簡潔でなければならず（せいぜい1段落、せいぜい4文）、平凡な表現は避けなければなりません。\n補足として、Creative MTGでは、「AkeruE」、「マクセル×SHIOMER」という2つのプロジェクトが、プロジェクトを進める上で使った「技」についてプレゼンテーションを行いました。","model":"gpt-4o-mini"}},{"step":"aggregation","completed":"2025-01-24T18:37:19.359094","duration":0.119161,"params":{"source_code":"\"\"\"Generate a convenient JSON output file.\"\"\"\n\nfrom tqdm import tqdm\nfrom typing import List\nimport pandas as pd\nfrom langchain_community.chat_models import ChatOpenAI\nimport json\n\n\ndef aggregation(config):\n\n    path = f\"outputs/{config['output_dir']}/result.json\"\n\n    results = {\n        \"clusters\": [],\n        \"comments\": {},\n        \"overview\": \"\",\n        \"config\": config,\n    }\n\n    arguments = pd.read_csv(f\"outputs/{config['output_dir']}/args.csv\")\n    arguments.set_index('arg-id', inplace=True)\n\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n    useful_comment_ids = set(arguments['comment-id'].values)\n    for _, row in comments.iterrows():\n        id = row['comment-id']\n        if id in useful_comment_ids:\n            res = {'comment': row['comment-body']}\n            numeric_cols = ['agrees', 'disagrees']\n            string_cols = ['video', 'interview', 'timestamp']\n            for col in numeric_cols:\n                if col in row:\n                    res[col] = float(row[col])\n            for col in string_cols:\n                if col in row:\n                    res[col] = row[col]\n            results['comments'][str(id)] = res\n\n    languages = list(config.get('translation', {}).get('languages', []))\n    if len(languages) \u003e 0:\n        with open(f\"outputs/{config['output_dir']}/translations.json\") as f:\n            translations = f.read()\n        results['translations'] = json.loads(translations)\n\n    clusters = pd.read_csv(f\"outputs/{config['output_dir']}/clusters.csv\")\n    labels = pd.read_csv(f\"outputs/{config['output_dir']}/labels.csv\")\n    takeaways = pd.read_csv(f\"outputs/{config['output_dir']}/takeaways.csv\")\n    takeaways.set_index('cluster-id', inplace=True)\n\n    with open(f\"outputs/{config['output_dir']}/overview.txt\") as f:\n        overview = f.read()\n    results['overview'] = overview\n\n    for _, row in labels.iterrows():\n        cid = row['cluster-id']\n        label = row['label']\n        arg_rows = clusters[clusters['cluster-id'] == cid]\n        arguments_in_cluster = []\n        for _, arg_row in arg_rows.iterrows():\n            arg_id = arg_row['arg-id']\n            argument = arguments.loc[arg_id]['argument']\n            comment_id = arguments.loc[arg_id]['comment-id']\n            x = float(arg_row['x'])\n            y = float(arg_row['y'])\n            p = float(arg_row['probability'])\n            obj = {\n                'arg_id': arg_id,\n                'argument': argument,\n                'comment_id': str(comment_id),\n                'x': x,\n                'y': y,\n                'p': p,\n            }\n            arguments_in_cluster.append(obj)\n        results['clusters'].append({\n            'cluster': label,\n            'cluster_id': str(cid),\n            'takeaways': takeaways.loc[cid]['takeaways'],\n            'arguments': arguments_in_cluster\n        })\n\n    with open(path, 'w') as file:\n        json.dump(results, file, indent=2)\n"}},{"step":"visualization","completed":"2025-01-24T18:37:52.952930","duration":33.591244,"params":{"replacements":[],"source_code":"\nimport subprocess\n\n\ndef visualization(config):\n    output_dir = config['output_dir']\n    with open(f\"outputs/{output_dir}/result.json\") as f:\n        result = f.read()\n\n    cwd = \"../next-app\"\n    command = f\"REPORT={output_dir} npm run build\"\n\n    try:\n        process = subprocess.Popen(command, shell=True, cwd=cwd, stdout=subprocess.PIPE,\n                                   stderr=subprocess.PIPE, universal_newlines=True)\n        while True:\n            output_line = process.stdout.readline()\n            if output_line == '' and process.poll() is not None:\n                break\n            if output_line:\n                print(output_line.strip())\n        process.wait()\n        errors = process.stderr.read()\n        if errors:\n            print(\"Errors:\")\n            print(errors)\n    except subprocess.CalledProcessError as e:\n        print(\"Error: \", e)\n"}}],"lock_until":"2025-01-24T18:42:52.958857","current_job":"visualization","current_job_started":"2025-01-24T18:37:19.361761","current_job_progress":null,"current_jop_tasks":null,"previously_completed_jobs":[],"end_time":"2025-01-24T18:37:52.958828"},"embedding":{"source_code":"from langchain_openai import OpenAIEmbeddings\nfrom langchain_community.chat_models import ChatOpenAI\nimport pandas as pd\nfrom tqdm import tqdm\n\n\ndef embedding(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/embeddings.pkl\"\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    embeddings = []\n    for i in tqdm(range(0, len(arguments), 1000)):\n        args = arguments[\"argument\"].tolist()[i: i + 1000]\n        embeddings_model = OpenAIEmbeddings()\n        embeds = embeddings_model.embed_documents(args)\n\n        embeddings.extend(embeds)\n    df = pd.DataFrame(\n        [\n            {\"arg-id\": arguments.iloc[i][\"arg-id\"], \"embedding\": e}\n            for i, e in enumerate(embeddings)\n        ]\n    )\n    df.to_pickle(path)"},"labelling":{"sample_size":30,"source_code":"\"\"\"Create labels for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain_openai import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef labelling(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/labels.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['labelling']['sample_size']\n    prompt = config['labelling']['prompt']\n    model = config['labelling']['model']\n\n    question = config['question']\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n\n        args_ids_outside = clusters[clusters['cluster-id']\n                                    != cluster_id]['arg-id'].values\n        args_ids_outside = np.random.choice(args_ids_outside, size=min(\n            len(args_ids_outside), sample_size), replace=False)\n        args_sample_outside = arguments[arguments['arg-id']\n                                        .isin(args_ids_outside)]['argument'].values\n\n        label = generate_label(question, args_sample,\n                               args_sample_outside, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'label': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_label(question, args_sample, args_sample_outside, prompt, model):\n    llm = ChatOpenAI(model=model, temperature=0.0)\n    outside = '\\n * ' + '\\n * '.join(args_sample_outside)\n    inside = '\\n * ' + '\\n * '.join(args_sample)\n    input = f\"Question of the consultation:{question}\\n\\n\" + \\\n        f\"Examples of arguments OUTSIDE the cluster:\\n {outside}\" + \\\n        f\"Examples of arguments INSIDE the cluster:\\n {inside}\"\n    response = llm.invoke(input=messages(prompt, input)).content.strip()\n\n    return response","prompt":"/system \n\nあなたは、Creative MTGに関する一連のコメントに対するカテゴリラベルを生成するカテゴリラベリングアシスタントです。\nCreative MTGでは、「AkeruE」、「マクセル×SHIOMER」という2つのプロジェクトが、プロジェクトを進める上で使った「技」についてプレゼンテーションを行いました。\nあなたには、相談の主な質問、クラスタ内の議論のリスト、およびこのクラスタ外の議論のリストが与えられます。あなたはクラスターを要約する1つのカテゴリーラベルで回答します。\n\n質問からすでに明らかな文脈は含めない（「Creative MTGの参加者の反応にはどういう傾向があったのか」のようなものであれば、クラスターのラベルに「Creative MTGの参加者の反応」と繰り返す必要はない）。\n\nラベルは非常に簡潔でなければならず、クラスターとその外側にある論点を区別するのに十分な正確さでなければならない。\nラベルは全て重複してはならない。\n「参加者の反応の傾向」「参加者の具体的な反応」のようなものはやめてください。\n具体的にどんな話に注目が集まったかを知りたいです。\nクラスター外の論点と明確に区別されるようなラベルを回答してください。\n\n/human\n\nコンサルテーションの質問 「英国のEU離脱決定の影響は何だと思いますか？\n\n関心のあるクラスター以外の論点の例\n\n * エラスムス・プログラムからの除外により、教育・文化交流の機会が制限された。\n * 英国は、国境検問の強化による旅行時間の延長に対処し、通勤客や旅行客に影響を与えた。\n * 環境基準における協力が減少し、気候変動と闘う努力が妨げられた。\n * 相互医療協定の中断により、患者ケアに課題を感じた。\n * Brexit関連の変更により、家族の居住権や市民権の申請が複雑になった。\n * 英国は、共同研究機会の減少により、研究の課題に取り組む世界的な取り組みに支障をきたすことを目の当たりにした。\n * EUの文化助成プログラムからの除外により、創造的なプロジェクトの制限に直面した。\n * 英国は、EUの資金提供の喪失により、慈善活動やコミュニティ支援の後退を目の当たりにした。\n * 消費者保護の弱体化により、国境を越えた紛争解決に課題が生じた。\n * 英国はプロの音楽家としてEU諸国をツアーする際の制限に直面し、キャリアに影響を与えた。\n\nクラスター内部での議論の例\n\n * Brexitによりサプライチェーンが混乱し、企業にとってコスト増と納期遅延につながった。\n * ブレグジットのため、市場の変動や投資・退職金の不確実性に直面した。\n * 新たな関税や通関手続きにより、英国は輸出業者として利益率の低下に対処した。\n * ブレグジット後、企業がEU市場内にとどまるために事業を移転したため、雇用を失った。\n * 英国は輸入品価格の高騰による生活費の増加に苦しんだ。\n * 英国のハイテク産業への投資が減少し、技術革新と雇用機会に影響を与えた。\n * 新たなビザ規制による観光客の減少を目の当たりにし、接客業に影響。\n * ポンド価値の下落により購買力が低下し、旅費が増加した。\n\n\n/ai \n\n財務上のマイナス影響","model":"gpt-4o-mini"},"takeaways":{"sample_size":30,"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain_openai import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef takeaways(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/takeaways.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['takeaways']['sample_size']\n    prompt = config['takeaways']['prompt']\n    model = config['takeaways']['model']\n\n    model = config.get('model_takeaways', config.get('model', 'gpt3.5-turbo'))\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n        label = generate_takeaways(args_sample, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'takeaways': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_takeaways(args_sample, prompt, model):\n    llm = ChatOpenAI(model=model, temperature=0.0)\n    input = \"\\n\".join(args_sample)\n    response = llm.invoke(input=messages(prompt, input)).content.strip()\n    return response","prompt":"/system \n\nあなたはシンクタンクで働くリサーチアシスタントのエキスパートです。Creative MTGに参加した人のコメントのリストが渡されます。\nCreative MTGでは、「AkeruE」、「マクセル×SHIOMER」という2つのプロジェクトが、プロジェクトを進める上で使った「技」についてプレゼンテーションを行いました。\nあなたは、どんな話に注目が集まったか、主な要点を1~2段落にまとめて回答します。あなたは簡潔で読みやすい短い文章を書くことができます。 \n \n/human\n\n[\n  \"銃による暴力は、私たちの社会における深刻な公衆衛生の危機を構成していると固く信じています。\",\n  \"包括的な銃規制策を通じて、この問題に早急に取り組む必要がある。\",\n  \"すべての銃購入者に対する身元調査の実施を支持します。\",\n  \"アサルト・ウェポンと大容量弾倉の禁止に賛成します。\",\n  \"違法な銃の売買を防ぐため、より厳しい規制を提唱します。\",\n  \"銃の購入プロセスにおいて、精神鑑定を義務付けるべきである。\"\n]\n\n/ai \n\n参加者は、包括的な銃規制を求め、普遍的な身元調査、突撃兵器の禁止、違法な銃売買の抑制、精神衛生評価の優先などを強調した。","model":"gpt-4o-mini"},"overview":{"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain_community.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef overview(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/overview.txt\"\n\n    takeaways = pd.read_csv(f\"outputs/{dataset}/takeaways.csv\")\n    labels = pd.read_csv(f\"outputs/{dataset}/labels.csv\")\n\n    prompt = config['overview']['prompt']\n    model = config['overview']['model']\n\n    ids = labels['cluster-id'].to_list()\n    takeaways.set_index('cluster-id', inplace=True)\n    labels.set_index('cluster-id', inplace=True)\n\n    input = ''\n    for i, id in enumerate(ids):\n        input += f\"# Cluster {i}/{len(ids)}: {labels.loc[id]['label']}\\n\\n\"\n        input += takeaways.loc[id]['takeaways'] + '\\n\\n'\n\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    messages_list = messages(prompt, input)  # メッセージをリストに変換\n    response = llm.invoke(messages_list).content.strip()  # invoke() を使用\n\n\n    with open(path, 'w') as file:\n        file.write(response)","prompt":"/system \nあなたはシンクタンクで働く専門家リサーチアシスタントです。あなたのチームは、あるトピックに関する公開コンサルテーションを実施し、さまざまな選択肢のクラスターを分析し始めました。あなたは今、クラスターのリストと各クラスターの簡単な分析を受け取ります。あなたの仕事は、CreativeMTGでどんな話に注目が集まったかを簡潔にまとめることです。あなたの要約は非常に簡潔でなければならず（せいぜい1段落、せいぜい4文）、平凡な表現は避けなければなりません。\n補足として、Creative MTGでは、「AkeruE」、「マクセル×SHIOMER」という2つのプロジェクトが、プロジェクトを進める上で使った「技」についてプレゼンテーションを行いました。","model":"gpt-4o-mini"},"aggregation":{"source_code":"\"\"\"Generate a convenient JSON output file.\"\"\"\n\nfrom tqdm import tqdm\nfrom typing import List\nimport pandas as pd\nfrom langchain_community.chat_models import ChatOpenAI\nimport json\n\n\ndef aggregation(config):\n\n    path = f\"outputs/{config['output_dir']}/result.json\"\n\n    results = {\n        \"clusters\": [],\n        \"comments\": {},\n        \"overview\": \"\",\n        \"config\": config,\n    }\n\n    arguments = pd.read_csv(f\"outputs/{config['output_dir']}/args.csv\")\n    arguments.set_index('arg-id', inplace=True)\n\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n    useful_comment_ids = set(arguments['comment-id'].values)\n    for _, row in comments.iterrows():\n        id = row['comment-id']\n        if id in useful_comment_ids:\n            res = {'comment': row['comment-body']}\n            numeric_cols = ['agrees', 'disagrees']\n            string_cols = ['video', 'interview', 'timestamp']\n            for col in numeric_cols:\n                if col in row:\n                    res[col] = float(row[col])\n            for col in string_cols:\n                if col in row:\n                    res[col] = row[col]\n            results['comments'][str(id)] = res\n\n    languages = list(config.get('translation', {}).get('languages', []))\n    if len(languages) \u003e 0:\n        with open(f\"outputs/{config['output_dir']}/translations.json\") as f:\n            translations = f.read()\n        results['translations'] = json.loads(translations)\n\n    clusters = pd.read_csv(f\"outputs/{config['output_dir']}/clusters.csv\")\n    labels = pd.read_csv(f\"outputs/{config['output_dir']}/labels.csv\")\n    takeaways = pd.read_csv(f\"outputs/{config['output_dir']}/takeaways.csv\")\n    takeaways.set_index('cluster-id', inplace=True)\n\n    with open(f\"outputs/{config['output_dir']}/overview.txt\") as f:\n        overview = f.read()\n    results['overview'] = overview\n\n    for _, row in labels.iterrows():\n        cid = row['cluster-id']\n        label = row['label']\n        arg_rows = clusters[clusters['cluster-id'] == cid]\n        arguments_in_cluster = []\n        for _, arg_row in arg_rows.iterrows():\n            arg_id = arg_row['arg-id']\n            argument = arguments.loc[arg_id]['argument']\n            comment_id = arguments.loc[arg_id]['comment-id']\n            x = float(arg_row['x'])\n            y = float(arg_row['y'])\n            p = float(arg_row['probability'])\n            obj = {\n                'arg_id': arg_id,\n                'argument': argument,\n                'comment_id': str(comment_id),\n                'x': x,\n                'y': y,\n                'p': p,\n            }\n            arguments_in_cluster.append(obj)\n        results['clusters'].append({\n            'cluster': label,\n            'cluster_id': str(cid),\n            'takeaways': takeaways.loc[cid]['takeaways'],\n            'arguments': arguments_in_cluster\n        })\n\n    with open(path, 'w') as file:\n        json.dump(results, file, indent=2)\n"},"visualization":{"replacements":[],"source_code":"\nimport subprocess\n\n\ndef visualization(config):\n    output_dir = config['output_dir']\n    with open(f\"outputs/{output_dir}/result.json\") as f:\n        result = f.read()\n\n    cwd = \"../next-app\"\n    command = f\"REPORT={output_dir} npm run build\"\n\n    try:\n        process = subprocess.Popen(command, shell=True, cwd=cwd, stdout=subprocess.PIPE,\n                                   stderr=subprocess.PIPE, universal_newlines=True)\n        while True:\n            output_line = process.stdout.readline()\n            if output_line == '' and process.poll() is not None:\n                break\n            if output_line:\n                print(output_line.strip())\n        process.wait()\n        errors = process.stderr.read()\n        if errors:\n            print(\"Errors:\")\n            print(errors)\n    except subprocess.CalledProcessError as e:\n        print(\"Error: \", e)\n"},"plan":[{"step":"extraction","run":false,"reason":"nothing changed"},{"step":"embedding","run":false,"reason":"nothing changed"},{"step":"clustering","run":true,"reason":"some parameters changed: clusters"},{"step":"labelling","run":true,"reason":"some dependent steps will re-run: clustering"},{"step":"takeaways","run":true,"reason":"some dependent steps will re-run: clustering"},{"step":"overview","run":true,"reason":"some dependent steps will re-run: labelling, takeaways"},{"step":"aggregation","run":true,"reason":"some dependent steps will re-run: clustering, labelling, takeaways, overview"},{"step":"visualization","run":true,"reason":"some dependent steps will re-run: aggregation"}],"status":"running","start_time":"2025-01-24T18:41:48.189985","completed_jobs":[{"step":"clustering","completed":"2025-01-24T18:42:18.195419","duration":30.001477,"params":{"clusters":6,"source_code":"import pandas as pd\nimport numpy as np\nfrom importlib import import_module\nimport MeCab\n\ndef clustering(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/clusters.csv\"\n    arguments_df = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    arguments_array = arguments_df[\"argument\"].values\n\n    embeddings_df = pd.read_pickle(f\"outputs/{dataset}/embeddings.pkl\")\n    embeddings_array = np.asarray(embeddings_df[\"embedding\"].values.tolist())\n    clusters = config['clustering']['clusters']\n\n    result = cluster_embeddings(\n        docs=arguments_array,\n        embeddings=embeddings_array,\n        metadatas={\n            \"arg-id\": arguments_df[\"arg-id\"].values,\n            \"comment-id\": arguments_df[\"comment-id\"].values,\n        },\n        n_topics=clusters,\n    )\n    result.to_csv(path, index=False)\n\n\ndef cluster_embeddings(\n    docs,\n    embeddings,\n    metadatas,\n    min_cluster_size=2,\n    n_components=2,\n    n_topics=6,\n):\n    # 必要なモジュールのインポート\n    SpectralClustering = import_module('sklearn.cluster').SpectralClustering\n    HDBSCAN = import_module('hdbscan').HDBSCAN\n    UMAP = import_module('umap').UMAP\n    CountVectorizer = import_module('sklearn.feature_extraction.text').CountVectorizer\n    BERTopic = import_module('bertopic').BERTopic\n\n    # NEologdの辞書パスを指定\n    neologd_path = '/usr/local/lib/mecab/dic/mecab-ipadic-neologd'\n    mecab = MeCab.Tagger(f\"-d {neologd_path} -Ochasen\")\n\n    # 品詞フィルタリングを行うトークナイザー\n    def tokenizer_mecab(text):\n        node = mecab.parseToNode(text)\n        words = []\n        while node:\n            # 名詞、動詞、形容詞だけを抽出する\n            if node.feature.startswith('名詞') or node.feature.startswith('動詞') or node.feature.startswith('形容詞'):\n                words.append(node.surface)\n            node = node.next\n        return words\n\n    umap_model = UMAP(\n        random_state=42,\n        n_components=n_components,\n    )\n    hdbscan_model = HDBSCAN(min_cluster_size=min_cluster_size)\n\n    # 日本語のストップワードリストを作成（必要に応じて拡張可能）\n    japanese_stopwords = [\"これ\", \"それ\", \"あれ\", \"こと\", \"もの\", \"ため\", \"よう\", \"さん\", \"する\", \"なる\", \"ある\", \"いる\"]\n\n    # 日本語トークナイザーとストップワードを使用する\n    vectorizer_model = CountVectorizer(tokenizer=tokenizer_mecab, stop_words=japanese_stopwords)\n\n    topic_model = BERTopic(\n        umap_model=umap_model,\n        hdbscan_model=hdbscan_model,\n        vectorizer_model=vectorizer_model,\n        verbose=True,\n    )\n\n    # トピックモデルのフィッティング\n    _, __ = topic_model.fit_transform(docs, embeddings=embeddings)\n\n    n_samples = len(embeddings)\n    n_neighbors = min(n_samples - 1, 10)\n    spectral_model = SpectralClustering(\n        n_clusters=n_topics,\n        affinity=\"nearest_neighbors\",\n        n_neighbors=n_neighbors,\n        random_state=42\n    )\n    umap_embeds = umap_model.fit_transform(embeddings)\n    cluster_labels = spectral_model.fit_predict(umap_embeds)\n\n    result = topic_model.get_document_info(\n        docs=docs,\n        metadata={\n            **metadatas,\n            \"x\": umap_embeds[:, 0],\n            \"y\": umap_embeds[:, 1],\n        },\n    )\n\n    result.columns = [c.lower() for c in result.columns]\n    result = result[['arg-id', 'x', 'y', 'probability']]\n    result['cluster-id'] = cluster_labels\n\n    return result"}},{"step":"labelling","completed":"2025-01-24T18:42:23.969932","duration":5.770414,"params":{"sample_size":30,"source_code":"\"\"\"Create labels for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain_openai import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef labelling(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/labels.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['labelling']['sample_size']\n    prompt = config['labelling']['prompt']\n    model = config['labelling']['model']\n\n    question = config['question']\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n\n        args_ids_outside = clusters[clusters['cluster-id']\n                                    != cluster_id]['arg-id'].values\n        args_ids_outside = np.random.choice(args_ids_outside, size=min(\n            len(args_ids_outside), sample_size), replace=False)\n        args_sample_outside = arguments[arguments['arg-id']\n                                        .isin(args_ids_outside)]['argument'].values\n\n        label = generate_label(question, args_sample,\n                               args_sample_outside, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'label': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_label(question, args_sample, args_sample_outside, prompt, model):\n    llm = ChatOpenAI(model=model, temperature=0.0)\n    outside = '\\n * ' + '\\n * '.join(args_sample_outside)\n    inside = '\\n * ' + '\\n * '.join(args_sample)\n    input = f\"Question of the consultation:{question}\\n\\n\" + \\\n        f\"Examples of arguments OUTSIDE the cluster:\\n {outside}\" + \\\n        f\"Examples of arguments INSIDE the cluster:\\n {inside}\"\n    response = llm.invoke(input=messages(prompt, input)).content.strip()\n\n    return response","prompt":"/system \n\nあなたは、Creative MTGに関する一連のコメントに対するカテゴリラベルを生成するカテゴリラベリングアシスタントです。\nCreative MTGでは、「AkeruE」、「マクセル×SHIOMER」という2つのプロジェクトが、プロジェクトを進める上で使った「技」についてプレゼンテーションを行いました。\nあなたには、相談の主な質問、クラスタ内の議論のリスト、およびこのクラスタ外の議論のリストが与えられます。あなたはクラスターを要約する1つのカテゴリーラベルで回答します。\n\n質問からすでに明らかな文脈は含めない（「Creative MTGの参加者の反応にはどういう傾向があったのか」のようなものであれば、クラスターのラベルに「Creative MTGの参加者の反応」と繰り返す必要はない）。\n\nラベルは非常に簡潔でなければならず、クラスターとその外側にある論点を区別するのに十分な正確さでなければならない。\nラベルは全て重複してはならない。\n「参加者の反応の傾向」「参加者の具体的な反応」のようなものはやめてください。\n具体的にどんな話に注目が集まったかを知りたいです。\nクラスター外の論点と明確に区別されるようなラベルを回答してください。\n\n/human\n\nコンサルテーションの質問 「英国のEU離脱決定の影響は何だと思いますか？\n\n関心のあるクラスター以外の論点の例\n\n * エラスムス・プログラムからの除外により、教育・文化交流の機会が制限された。\n * 英国は、国境検問の強化による旅行時間の延長に対処し、通勤客や旅行客に影響を与えた。\n * 環境基準における協力が減少し、気候変動と闘う努力が妨げられた。\n * 相互医療協定の中断により、患者ケアに課題を感じた。\n * Brexit関連の変更により、家族の居住権や市民権の申請が複雑になった。\n * 英国は、共同研究機会の減少により、研究の課題に取り組む世界的な取り組みに支障をきたすことを目の当たりにした。\n * EUの文化助成プログラムからの除外により、創造的なプロジェクトの制限に直面した。\n * 英国は、EUの資金提供の喪失により、慈善活動やコミュニティ支援の後退を目の当たりにした。\n * 消費者保護の弱体化により、国境を越えた紛争解決に課題が生じた。\n * 英国はプロの音楽家としてEU諸国をツアーする際の制限に直面し、キャリアに影響を与えた。\n\nクラスター内部での議論の例\n\n * Brexitによりサプライチェーンが混乱し、企業にとってコスト増と納期遅延につながった。\n * ブレグジットのため、市場の変動や投資・退職金の不確実性に直面した。\n * 新たな関税や通関手続きにより、英国は輸出業者として利益率の低下に対処した。\n * ブレグジット後、企業がEU市場内にとどまるために事業を移転したため、雇用を失った。\n * 英国は輸入品価格の高騰による生活費の増加に苦しんだ。\n * 英国のハイテク産業への投資が減少し、技術革新と雇用機会に影響を与えた。\n * 新たなビザ規制による観光客の減少を目の当たりにし、接客業に影響。\n * ポンド価値の下落により購買力が低下し、旅費が増加した。\n\n\n/ai \n\n財務上のマイナス影響","model":"gpt-4o-mini"}},{"step":"takeaways","completed":"2025-01-24T18:42:44.455530","duration":20.475404,"params":{"sample_size":30,"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain_openai import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef takeaways(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/takeaways.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['takeaways']['sample_size']\n    prompt = config['takeaways']['prompt']\n    model = config['takeaways']['model']\n\n    model = config.get('model_takeaways', config.get('model', 'gpt3.5-turbo'))\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n        label = generate_takeaways(args_sample, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'takeaways': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_takeaways(args_sample, prompt, model):\n    llm = ChatOpenAI(model=model, temperature=0.0)\n    input = \"\\n\".join(args_sample)\n    response = llm.invoke(input=messages(prompt, input)).content.strip()\n    return response","prompt":"/system \n\nあなたはシンクタンクで働くリサーチアシスタントのエキスパートです。Creative MTGに参加した人のコメントのリストが渡されます。\nCreative MTGでは、「AkeruE」、「マクセル×SHIOMER」という2つのプロジェクトが、プロジェクトを進める上で使った「技」についてプレゼンテーションを行いました。\nあなたは、どんな話に注目が集まったか、主な要点を1~2段落にまとめて回答します。あなたは簡潔で読みやすい短い文章を書くことができます。 \n \n/human\n\n[\n  \"銃による暴力は、私たちの社会における深刻な公衆衛生の危機を構成していると固く信じています。\",\n  \"包括的な銃規制策を通じて、この問題に早急に取り組む必要がある。\",\n  \"すべての銃購入者に対する身元調査の実施を支持します。\",\n  \"アサルト・ウェポンと大容量弾倉の禁止に賛成します。\",\n  \"違法な銃の売買を防ぐため、より厳しい規制を提唱します。\",\n  \"銃の購入プロセスにおいて、精神鑑定を義務付けるべきである。\"\n]\n\n/ai \n\n参加者は、包括的な銃規制を求め、普遍的な身元調査、突撃兵器の禁止、違法な銃売買の抑制、精神衛生評価の優先などを強調した。","model":"gpt-4o-mini"}},{"step":"overview","completed":"2025-01-24T18:42:47.146221","duration":2.685419,"params":{"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain_community.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef overview(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/overview.txt\"\n\n    takeaways = pd.read_csv(f\"outputs/{dataset}/takeaways.csv\")\n    labels = pd.read_csv(f\"outputs/{dataset}/labels.csv\")\n\n    prompt = config['overview']['prompt']\n    model = config['overview']['model']\n\n    ids = labels['cluster-id'].to_list()\n    takeaways.set_index('cluster-id', inplace=True)\n    labels.set_index('cluster-id', inplace=True)\n\n    input = ''\n    for i, id in enumerate(ids):\n        input += f\"# Cluster {i}/{len(ids)}: {labels.loc[id]['label']}\\n\\n\"\n        input += takeaways.loc[id]['takeaways'] + '\\n\\n'\n\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    messages_list = messages(prompt, input)  # メッセージをリストに変換\n    response = llm.invoke(messages_list).content.strip()  # invoke() を使用\n\n\n    with open(path, 'w') as file:\n        file.write(response)","prompt":"/system \nあなたはシンクタンクで働く専門家リサーチアシスタントです。あなたのチームは、あるトピックに関する公開コンサルテーションを実施し、さまざまな選択肢のクラスターを分析し始めました。あなたは今、クラスターのリストと各クラスターの簡単な分析を受け取ります。あなたの仕事は、CreativeMTGでどんな話に注目が集まったかを簡潔にまとめることです。あなたの要約は非常に簡潔でなければならず（せいぜい1段落、せいぜい4文）、平凡な表現は避けなければなりません。\n補足として、Creative MTGでは、「AkeruE」、「マクセル×SHIOMER」という2つのプロジェクトが、プロジェクトを進める上で使った「技」についてプレゼンテーションを行いました。","model":"gpt-4o-mini"}}],"lock_until":"2025-01-24T18:47:47.150255","current_job":"aggregation","current_job_started":"2025-01-24T18:42:47.150232","current_job_progress":null,"current_jop_tasks":null}}},"__N_SSG":true},"page":"/","query":{},"buildId":"CV6WqzivbkPeR90C6i50t","assetPrefix":".","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>