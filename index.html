<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><meta name="next-head-count" content="2"/><link rel="preload" href="./_next/static/css/d1893b45984f5972.css" as="style"/><link rel="stylesheet" href="./_next/static/css/d1893b45984f5972.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="./_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="./_next/static/chunks/webpack-6f0e0dcf15b6875d.js" defer=""></script><script src="./_next/static/chunks/framework-49c6cecf1f6d5795.js" defer=""></script><script src="./_next/static/chunks/main-723f98eb367cc52a.js" defer=""></script><script src="./_next/static/chunks/pages/_app-4ac3cada10d020c2.js" defer=""></script><script src="./_next/static/chunks/413-9ff854af82ce4d76.js" defer=""></script><script src="./_next/static/chunks/664-d254d21a6fe56bff.js" defer=""></script><script src="./_next/static/chunks/39-45fee9698b3cd58c.js" defer=""></script><script src="./_next/static/chunks/pages/index-4106543ad8e86225.js" defer=""></script><script src="./_next/static/CV6WqzivbkPeR90C6i50t/_buildManifest.js" defer=""></script><script src="./_next/static/CV6WqzivbkPeR90C6i50t/_ssgManifest.js" defer=""></script></head><body><div id="__next"></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"result":{"clusters":[{"cluster":"å‚åŠ è€…ã®ãƒã‚¸ãƒ†ã‚£ãƒ–ãªåå¿œ","cluster_id":"3","takeaways":"å‚åŠ è€…ã®ã‚³ãƒ¡ãƒ³ãƒˆã‹ã‚‰ã¯ã€Creative MTGã®é›°å›²æ°—ãŒéå¸¸ã«æ´»æ°—ã«æº€ã¡ã¦ã„ãŸã“ã¨ãŒä¼ºãˆã¾ã™ã€‚ç‰¹ã«ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®å¼•ãå–ã‚Šæ‰‹ãŒã„ã‚‹ã“ã¨ã‚„ã€ã‚¸ãƒ£ãƒ³ãƒ‘ãƒ¼ã®é­…åŠ›ã«ã¤ã„ã¦ã®åå¿œãŒå¥½æ„çš„ã§ã€å‚åŠ è€…åŒå£«ã®äº¤æµãŒç››ã‚“ã ã£ãŸã“ã¨ãŒå¼·èª¿ã•ã‚Œã¦ã„ã¾ã™ã€‚ã¾ãŸã€ãƒ–ãƒ¬ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒŸãƒ³ã‚°ã®æ™‚é–“ã‚’è¨­ã‘ã‚‹ã“ã¨ã§ã€å…¨å“¡ãŒæ„è¦‹ã‚’å‡ºã—åˆã†é‡è¦æ€§ã‚„ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®æ ¸å¿ƒã‚’å†ç¢ºèªã™ã‚‹ã“ã¨ã®å¤§åˆ‡ã•ãŒå…±æœ‰ã•ã‚Œã€å®Ÿè·µçš„ãªå­¦ã³ãŒã‚ã£ãŸã“ã¨ãŒå°è±¡çš„ã§ã™ã€‚","arguments":[{"arg_id":"A0_0","argument":"è‰¯ã„å£°ww","comment_id":"0","x":4.9333386,"y":14.132209,"p":0.8737562118804985},{"arg_id":"A1_0","argument":"ã¯ã˜ã¾ã‚‹ã‚ˆã€œï¼","comment_id":"1","x":4.601118,"y":14.728456,"p":1},{"arg_id":"A2_0","argument":"ã‚ãƒ¼ï¼","comment_id":"2","x":4.420931,"y":14.109039,"p":1},{"arg_id":"A26_0","argument":"ã™ã§ã«å¼•ãå–ã‚Šæ‰‹ãŒã„ã‚‹ã®ã‚ˆã‹ã£ãŸâ€¼ï¸","comment_id":"26","x":4.3670187,"y":14.519595,"p":1},{"arg_id":"A36_0","argument":"ã‹ã‚ã„ã„ï¼","comment_id":"36","x":4.536664,"y":13.969583,"p":0.8186284207170899},{"arg_id":"A37_0","argument":"ã‚¸ãƒ£ãƒ³ãƒ‘ãƒ¼ã»ã—ã„ï¼ï¼","comment_id":"37","x":4.634155,"y":14.356778,"p":1},{"arg_id":"A43_0","argument":"å¼•ãç¶™ãPMç›®ç·šã§ã‚¿ãƒ¡ã«ãªã‚‹è©±ï¼","comment_id":"43","x":4.872645,"y":15.194779,"p":0},{"arg_id":"A45_0","argument":"ãƒªãƒ”ãƒ¼ãƒˆã™ã°ã‚‰ã—ã„ï¼ï¼","comment_id":"45","x":4.960383,"y":14.433292,"p":0.9754727677750452},{"arg_id":"A55_0","argument":"ã‚ãŸã—ã‚‚é€”ä¸­ã§ãƒ–ãƒ¬ã‚¹ãƒˆã‚¿ã‚¤ãƒ ã„ã‚Œã¦ã€å…¨å“¡åŠå¼·åˆ¶çš„ã«ãƒãƒ£ãƒƒãƒˆã«æ„è¦‹æ›¸ã‹ã›ãŸã“ã¨ã‚ã‚Šã¾ã™ï¼","comment_id":"55","x":5.3616967,"y":14.9055,"p":0},{"arg_id":"A71_0","argument":"çŸ¥ã‚‰ãªã‹ã£ãŸ...","comment_id":"71","x":3.9523778,"y":14.777444,"p":0},{"arg_id":"A79_0","argument":"ãƒ“ã‚·ãƒƒã¨ã€Œä½•ãŒä¸€ç•ªå¤§äº‹ã‹æ€ã„å‡ºã›!!ã€ç¬‘","comment_id":"79","x":4.4957848,"y":14.754319,"p":1}]},{"cluster":"å‚åŠ è€…ã®ç†±æ„ã¨åå¿œ","cluster_id":"4","takeaways":"å‚åŠ è€…ã®ã‚³ãƒ¡ãƒ³ãƒˆã‹ã‚‰ã¯ã€AkeruEãƒãƒ¼ãƒ ã¸ã®å¼·ã„æ„›æƒ…ã¨ç†±æ„ãŒä¼ã‚ã£ã¦ãã¾ã™ã€‚ç‰¹ã«ã€ãƒãƒ¼ãƒ ã®æ©Ÿæ•ãªå‹•ãã‚„ç¾å ´æ„Ÿã«æ„Ÿå‹•ã—ãŸã¨ã„ã†å£°ãŒå¤šãã€ã‚¢ã‚±ãƒ«ã‚¨ã®æ´»å‹•ãŒå‚åŠ è€…ã«ã¨ã£ã¦å¤§ããªã‚¤ãƒ³ã‚¹ãƒ”ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¨ãªã£ã¦ã„ã‚‹ã“ã¨ãŒä¼ºãˆã¾ã™ã€‚ã¾ãŸã€ã‚¢ãƒ«ã‚±ãƒŸã‚¹ãƒˆãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®å‚åŠ è€…ãŒãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«å¯¾ã™ã‚‹æƒ…ç†±ã‚’æŒã¡ç¶šã‘ã¦ã„ã‚‹ç‚¹ã‚‚å°è±¡çš„ã§ã™ã€‚å…¨ä½“ã¨ã—ã¦ã€AkeruEã®æˆåŠŸã¨ãã®å½±éŸ¿åŠ›ã«å¯¾ã™ã‚‹æœŸå¾…ãŒé«˜ã¾ã£ã¦ã„ã‚‹æ§˜å­ãŒè¦‹å—ã‘ã‚‰ã‚Œã¾ã™ã€‚","arguments":[{"arg_id":"A3_0","argument":"ä»Šå›ã‚‚ã‚³ãƒ¡ãƒ³ãƒˆåˆ†æãŸã®ã—ã¿ã€œ","comment_id":"3","x":5.521326,"y":14.986865,"p":0},{"arg_id":"A5_0","argument":"AIåˆ†æã•ã‚“ã«è¤’ã‚ã¦ã‚‚ã‚‰ãˆã‚‹ã‚ˆã†é ‘å¼µã‚‹ãã„","comment_id":"5","x":5.906033,"y":14.635072,"p":0},{"arg_id":"A7_0","argument":"AkeruEãƒãƒ¼ãƒ ã®ç†±é‡ã¯æœ¬å½“ã«ã™ã”ã‹ã£ãŸã§ã™","comment_id":"7","x":6.332323,"y":13.811634,"p":1},{"arg_id":"A16_0","argument":"ã‚¢ã‚±ãƒ«ã‚¨æ„›ã•ã‚Œã¦ã‚‹ï¼","comment_id":"16","x":6.415863,"y":14.6888075,"p":1},{"arg_id":"A18_0","argument":"ç¾å ´ã®ã‚¢ã‚±ãƒ«ã‚¨ãƒãƒ¼ãƒ ã®å‹•ããŒæ©Ÿæ•ã™ãã‚‹ã®ãŒã¨ã¦ã‚‚ã™ã”ã„ã—ã€ç¾å ´æ„Ÿã®å®Ÿæ„Ÿã§ãã¦æ„Ÿå‹•ã€‚","comment_id":"18","x":6.5289865,"y":13.937571,"p":1},{"arg_id":"A22_0","argument":"ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã¯æ¬¡ã«ç¹‹ãŒã‚Šã¾ã™ã­ã€‚","comment_id":"22","x":5.7861176,"y":15.357857,"p":0},{"arg_id":"A23_0","argument":"ã‚¢ã‚±ãƒ«ã‚¨ã®ç«¶åˆã¨ã„ã†ã‹ã€ä¼¼ãŸæ–½è¨­ã£ã¦å­˜åœ¨ã—ã¦ã‚‹ã®ã§ã—ã‚‡ã†ã‹ï¼Ÿ","comment_id":"23","x":6.538934,"y":15.025101,"p":1},{"arg_id":"A27_0","argument":"ã©ã®ãã‚‰ã„ã®åºƒã•ãŒå¿…è¦ãªã®ï¼Ÿã‚¢ãƒ«ã‚±ãƒŸã‚¹ãƒˆãƒ—ãƒ­ã‚°ãƒ©ãƒ ","comment_id":"27","x":6.8153467,"y":14.386611,"p":1},{"arg_id":"A28_0","argument":"ã‚¢ãƒ«ã‚±ãƒŸã‚¹ãƒˆãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®å‚åŠ è€…ãƒ¡ãƒ³ãƒãƒ¼ã¯çµ‚ã‚ã£ãŸä»Šã§ã‚‚å¤‰ã‚ã‚‰ãšã“ã‚Œã¤ãã£ãŸï¼ã“ã‚Œã«å‡ºå±•ã—ã¾ã™ï¼ã¨ã„ã†ã‚ˆã†ãªé€£çµ¡ã—ã¦ãã¦ãã‚Œã¦ã¾ã™ã€œæƒ…ç†±ã¯å¤‰ã‚ã‚‰ãšã¤ã¥ã„ã¦ãŠã‚Šã¾ã™ã€‚(ã‚ãŸã‘ã‚“)","comment_id":"28","x":6.450236,"y":14.193749,"p":1},{"arg_id":"A31_0","argument":"ã‚¢ã‚±ãƒ«ã‚¨ã¿ãŸã„ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä½œã‚ŠãŸã„","comment_id":"31","x":6.699807,"y":14.698245,"p":1},{"arg_id":"A32_0","argument":"ã‚¢ã‚±ãƒ«ã‚¨ã‚’ç· ã‚ã‚‹ã­","comment_id":"32","x":6.355016,"y":15.209399,"p":0},{"arg_id":"A42_0","argument":"SDSã®æ´»ç”¨æ–¹æ³•ã™ã”ãã„ã„ã§ã™ã­ã€‚å€‹åˆ¥ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ä½¿ã†ã®ã„ã„ãªã¨æ€ã„ã¾ã™ã€‚","comment_id":"42","x":6.9057446,"y":14.264206,"p":0}]},{"cluster":"å‚åŠ è€…ã®å…·ä½“çš„ãªåå¿œ","cluster_id":"5","takeaways":"å‚åŠ è€…ã®ã‚³ãƒ¡ãƒ³ãƒˆã‹ã‚‰ã¯ã€ã‚¬ãƒ¼ãƒ«ã‚ºãƒãƒ¼ã®ç››ã‚Šä¸ŠãŒã‚Šã‚„ã‚¯ãƒªã‚¹ãƒã‚¹ã®çµ‚æ¥­å¼ã®æ€ã„å‡ºãŒå¼·èª¿ã•ã‚Œã¦ãŠã‚Šã€æ¥½ã—ã„é›°å›²æ°—ãŒä¼ã‚ã£ã¦ãã¾ã™ã€‚ã¾ãŸã€ã€Œé­”è²«å…‰æ®ºç ²ã€ã‚„ã€Œãƒãƒ†ãƒãŠã§ã‚“ã€ãªã©ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªè©±é¡Œã‚‚ã‚ã‚Šã€å‚åŠ è€…åŒå£«ã®è»½å¦™ãªã‚„ã‚Šå–ã‚ŠãŒè¦‹å—ã‘ã‚‰ã‚Œã¾ã™ã€‚å…¨ä½“ã¨ã—ã¦ã€ãƒªãƒ©ãƒƒã‚¯ã‚¹ã—ãŸé›°å›²æ°—ã®ä¸­ã§ã®äº¤æµãŒå°è±¡çš„ã§ã™ã€‚","arguments":[{"arg_id":"A4_0","argument":"å‰å›ã¯ã‚¬ãƒ¼ãƒ«ã‚ºãƒãƒ¼ãŒã‚ã¡ã‚ƒãã¡ã‚ƒç››ã‚Šä¸ŠãŒã£ã¦ã¾ã—ãŸã­","comment_id":"4","x":3.5498753,"y":15.268645,"p":0},{"arg_id":"A12_0","argument":"ãŸã—ã‹ã«ã‚¯ãƒªã‚¹ãƒã‚¹ã‚‰ã¸ã‚“çµ‚æ¥­å¼ã—ã¦ãŸãªã€œ","comment_id":"12","x":3.2992067,"y":14.907526,"p":0.6607589975739088},{"arg_id":"A14_0","argument":"åœ§å·»ã§ã™ã­","comment_id":"14","x":3.2964206,"y":15.343674,"p":1},{"arg_id":"A34_0","argument":"ãƒ‘ãƒŠã‚½ãƒ‹ãƒƒã‚¯ç¶šãã§ã™ã­","comment_id":"34","x":3.0935,"y":15.18904,"p":1},{"arg_id":"A44_0","argument":"é­”è²«å…‰æ®ºç ²ã¯ãªã‚“ã ã£ãŸã‚“ã ã‚ã†","comment_id":"44","x":3.168245,"y":15.662149,"p":0.9281613935520102},{"arg_id":"A46_0","argument":"ã“ã‚Œã™ã£ã”ã„è‹¦åŠ´ã—ã¦ãŸã‚ˆã­","comment_id":"46","x":3.5308466,"y":15.760292,"p":0},{"arg_id":"A53_0","argument":"ã‚ã–ã§ã™ã­","comment_id":"53","x":2.6698785,"y":14.638079,"p":0.7637298249832616},{"arg_id":"A66_0","argument":"ãŸã—ã‹ã«ç¬‘","comment_id":"66","x":3.141727,"y":14.537296,"p":1},{"arg_id":"A67_0","argument":"ãƒãƒ†ãƒã‚’ç®¸ã§é£Ÿã¹ã¦ã‚‹ãªğŸ‘€","comment_id":"67","x":2.5611708,"y":15.325407,"p":1},{"arg_id":"A68_0","argument":"ãƒãƒ†ãƒãŠã§ã‚“ã®æ±ã«ã¤ã‘ã¦ã‚‹ï¼Ÿ","comment_id":"68","x":2.635554,"y":15.461565,"p":0},{"arg_id":"A72_0","argument":"ãƒãƒ«ã®ä¸­ã«ã‚¯ã‚»ãªã‚“ã§ã™ã­","comment_id":"72","x":2.6862075,"y":15.007106,"p":1}]},{"cluster":"å‚åŠ è€…ã®å…·ä½“çš„ãªåå¿œ","cluster_id":"2","takeaways":"æ¥å ´è€…57ä¸‡äººã¨ã„ã†å¤§è¦æ¨¡ãªã‚¤ãƒ™ãƒ³ãƒˆã«å¯¾ã™ã‚‹ç§°è³›ãŒç›®ç«‹ã¡ã€ç‰¹ã«300äººã®å¸¸é€£å‚åŠ è€…ã®å­˜åœ¨ãŒæ³¨ç›®ã•ã‚Œã¾ã—ãŸã€‚ãƒ‡ã‚¶ã‚¤ãƒ³ã‚„ãƒ¦ãƒ‹ãƒ•ã‚©ãƒ¼ãƒ ã€ã‚¹ã‚¿ãƒƒãƒ•ã®æœè£…ã«å¯¾ã™ã‚‹å¥½è©•ã‚‚å¤šãã€ç‰¹ã«èƒŒä¸­ã®ãƒ­ã‚´ã‚„ãƒãƒƒã‚¯ãƒ—ãƒªãƒ³ãƒˆãŒå¯æ„›ã‚‰ã—ã„ã¨è©•ä¾¡ã•ã‚Œã¦ã„ã¾ã™ã€‚ã¾ãŸã€ã‚ªãƒ³ãƒ©ã‚¤ãƒ³MTGã®é‡è¦æ€§ã‚„ãƒãƒ¼ãƒ ã®é›°å›²æ°—ã®è‰¯ã•ã«ã¤ã„ã¦ã‚‚è¨€åŠã•ã‚Œã€ã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ãªå–ã‚Šçµ„ã¿ã‚„ã‚¢ãƒ¼ãƒˆã‚’é€šã˜ãŸãƒãƒ¼ãƒ ãƒ“ãƒ«ãƒ‡ã‚£ãƒ³ã‚°ã®ã‚¢ã‚¤ãƒ‡ã‚¢ãŒç´ æ™´ã‚‰ã—ã„ã¨ã•ã‚Œã¾ã—ãŸã€‚å…¨ä½“ã¨ã—ã¦ã€å‚åŠ è€…ã®ç†±æ„ã¨ã‚¤ãƒ™ãƒ³ãƒˆã®é­…åŠ›ãŒå¼·èª¿ã•ã‚Œã¦ã„ã¾ã™ã€‚","arguments":[{"arg_id":"A6_0","argument":"æ¥å ´è€…57ä¸‡ã€ç«‹æ´¾","comment_id":"6","x":4.842225,"y":12.75003,"p":0},{"arg_id":"A8_0","argument":"Yãƒãƒ¼ãƒ ã‚ãŸã‘ã‚“ã§ã™ã€‚åå¤å±‹ã‹ã‚‰å¿œæ´ï¼","comment_id":"8","x":5.867913,"y":13.008045,"p":1},{"arg_id":"A15_0","argument":"300äººã®å¸¸é€£ã£ã¦ã¨ã£ã¦ã‚‚å‡„ã„ï¼ï¼","comment_id":"15","x":5.195941,"y":12.844196,"p":0},{"arg_id":"A21_0","argument":"ãã‚Œãã‚Œã®ãƒ‡ã‚¶ã‚¤ãƒ³ã§ã¶ã‚“å›ã—ã¤ã¤ã€ãƒœãƒƒã‚¯ã‚¹ã«å…¥ã‚Œã¦ã¾ã¨ã¾ã‚Šè‰¯ãæ•´ãˆã‚‹ã€ç´ æ•µâ—â—","comment_id":"21","x":5.3045845,"y":13.343089,"p":1},{"arg_id":"A35_0","argument":"ã‚¨ãƒªã‚¢ã®ãƒ–ãƒ­ãƒƒã‚¯è¡¨ç¤ºã‹ã‚ã„ã„","comment_id":"35","x":5.502761,"y":13.179381,"p":0.8312594111747644},{"arg_id":"A38_0","argument":"ãƒ‡ã‚¶ã‚¤ãƒ³ã™ã¦ã","comment_id":"38","x":5.468476,"y":13.550887,"p":1},{"arg_id":"A39_0","argument":"èƒŒä¸­ãƒ­ã‚´ã®ãƒ¦ãƒ‹ãƒ•ã‚©ãƒ¼ãƒ ã€ã™ã¦ãï¼","comment_id":"39","x":5.0179286,"y":13.259673,"p":1},{"arg_id":"A40_0","argument":"ãƒãƒƒã‚¯ãƒ—ãƒªãƒ³ãƒˆãªã‚¹ã‚¿ãƒƒãƒ•ã˜ã‚ƒã‚“ã±ãƒ¼ã‹ã‚ã„ã„","comment_id":"40","x":4.730774,"y":13.255287,"p":0},{"arg_id":"A41_0","argument":"ã‚ã£ã¡ã‚ƒã„ã‚ã‚“ãªã“ã¨ã‚„ã£ã¦ã‚‹ã€ã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ã‚‚ç´ æ•µ","comment_id":"41","x":5.9874535,"y":13.559447,"p":0.7869462244490851},{"arg_id":"A51_0","argument":"ã‚ªãƒ³ãƒ©ã‚¤ãƒ³MTGã¯ãƒ•ã‚¡ã‚·ãƒªå¤§äº‹","comment_id":"51","x":5.5346484,"y":13.853875,"p":1},{"arg_id":"A58_0","argument":"CLã®ãƒãƒ¼ãƒ ã®é›°å›²æ°—ã‚‚è‰¯ããªã£ã¦ãã†ã§ç´ æ•µï¼","comment_id":"58","x":6.249745,"y":13.0206785,"p":0.7885905508761044},{"arg_id":"A60_0","argument":"ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã§ã‚‚ã„ã„ç©ºæ°—ã«ãªã‚‹ã®ã™ã”ã„","comment_id":"60","x":5.76178,"y":13.858039,"p":0.8286039417360355},{"arg_id":"A70_0","argument":"ã“ã®ãƒ­ã‚´ã™ã¦ãã§ã™ï¼","comment_id":"70","x":5.03687,"y":13.669512,"p":0},{"arg_id":"A74_0","argument":"ãƒãƒ¼ãƒ ãƒ“ãƒ«ãƒ‡ã‚£ãƒ³ã‚°ã®ãŠé¡Œç›®ã§ã‚¢ãƒ¼ãƒˆã‚’å·¡ã‚‹ã®ã€ç´ æ•µï¼","comment_id":"74","x":6.104269,"y":13.194865,"p":1},{"arg_id":"A75_0","argument":"CLã¨ç¾è¡“é¤¨ã„ãã®ã„ã„ã§ã™ã­ï¼","comment_id":"75","x":5.9651814,"y":12.723752,"p":0}]},{"cluster":"å‚åŠ è€…ã®æ„Ÿæƒ…è¡¨ç¾","cluster_id":"0","takeaways":"å‚åŠ è€…ã®ã‚³ãƒ¡ãƒ³ãƒˆã‹ã‚‰ã¯ã€æ„Ÿæƒ…è±Šã‹ãªåå¿œãŒå¤šãè¦‹ã‚‰ã‚Œã€ç‰¹ã«ã€Œæ³£ãã€ã¨ã„ã†è¡¨ç¾ãŒå°è±¡çš„ã§ã™ã€‚ã¾ãŸã€ã€Œã²ã¨ã„ã£ã±ã„ã ã€ã‚„ã€Œå¯æ„›ã„ã‚·ãƒ­ã‚¯ãƒã€ã¨ã„ã£ãŸè¨€è‘‰ã‹ã‚‰ã¯ã€ã‚¤ãƒ™ãƒ³ãƒˆã®é›°å›²æ°—ãŒè³‘ã‚„ã‹ã§è¦ªã—ã¿ã‚„ã™ã„ã“ã¨ãŒä¼ã‚ã‚Šã¾ã™ã€‚ç‰¹ã«ã€Œç™ºè¨€åˆ‡ã‚Šè¾¼ã¿éšŠé•·ã€ã‚„ã€Œã³ã£ãã‚Šã•ã£ã•ã‚“ã‹ã‚ã„ã„ã§ã™ã€ã¨ã„ã£ãŸå…·ä½“çš„ãªåå‰ã®è¨€åŠã¯ã€å‚åŠ è€…åŒå£«ã®é–¢ä¿‚æ€§ã‚„æ¥½ã—ã•ã‚’æ„Ÿã˜ã•ã›ã‚‹è¦ç´ ã¨ãªã£ã¦ã„ã¾ã™ã€‚å…¨ä½“ã¨ã—ã¦ã€æ„Ÿè¬ã®æ°—æŒã¡ã‚„æ¥½ã—ã•ãŒå¼·èª¿ã•ã‚Œã¦ã„ã‚‹å°è±¡ã§ã™ã€‚","arguments":[{"arg_id":"A9_0","argument":"åå‰ãŒã™ã§ã«ã“ã‚ã„ç¬‘","comment_id":"9","x":3.6360285,"y":14.567654,"p":0.7003434197928847},{"arg_id":"A13_0","argument":"ã²ã¨ã„ã£ã±ã„ã ","comment_id":"13","x":2.5166864,"y":14.228303,"p":1},{"arg_id":"A19_0","argument":"èª­ã‚“ã ã‚‰æ³£ããª","comment_id":"19","x":3.376239,"y":14.420805,"p":1},{"arg_id":"A20_0","argument":"èª­ã‚“ã ã‚‰æ³£ã(ã‚ãŸã‘ã‚“)","comment_id":"20","x":3.2541199,"y":14.29638,"p":1},{"arg_id":"A25_0","argument":"ä¹ƒæ‘å·¥è—ç¤¾ã‚ªãƒˆã‚³ãƒã‚¨","comment_id":"25","x":4.1501255,"y":13.019125,"p":0},{"arg_id":"A29_0","argument":"å¤§æ¾¤ãã‚“ã®ã‚„ã¤ã ","comment_id":"29","x":3.2608957,"y":13.7423115,"p":0},{"arg_id":"A30_0","argument":"ã‚ã¤ã™ãã‚‹","comment_id":"30","x":2.447597,"y":14.2249565,"p":1},{"arg_id":"A33_0","argument":"ã‚ãŸã‘ã‚“ã€ã‚ã‚ŠãŒã¨ã†ï¼","comment_id":"33","x":4.0794735,"y":14.058209,"p":0.8926199667308271},{"arg_id":"A52_0","argument":"ç™ºè¨€åˆ‡ã‚Šè¾¼ã¿éšŠé•·","comment_id":"52","x":4.387159,"y":13.586059,"p":0},{"arg_id":"A62_0","argument":"ã•ã£ã£ã£ã£ã•ã‚“","comment_id":"62","x":3.4675756,"y":13.4627695,"p":1},{"arg_id":"A65_0","argument":"ã³ã£ãã‚Šã•ã£ã•ã‚“ã‹ã‚ã„ã„ã§ã™","comment_id":"65","x":3.7478266,"y":13.9029665,"p":0.7054121425462443},{"arg_id":"A69_0","argument":"è¦‹ã¦ã‚‹ã§","comment_id":"69","x":2.6759205,"y":13.981031,"p":1},{"arg_id":"A73_0","argument":"ã—ã‚ãã¾ã•ã‚“","comment_id":"73","x":3.5186422,"y":13.275846,"p":1},{"arg_id":"A78_0","argument":"å¯æ„›ã„ã‚·ãƒ­ã‚¯ãƒ","comment_id":"78","x":3.8303468,"y":13.417092,"p":0.9508089790845944}]},{"cluster":"å‚åŠ è€…ã®å…·ä½“çš„ãªæ„è¦‹","cluster_id":"1","takeaways":"å‚åŠ è€…ã¯ã€äººå£æ¸›å°‘ç¤¾ä¼šã«ãŠã‘ã‚‹äº‹æ¥­ã®é–‰é–ã‚„ã€Œç· ã‚æ–¹ã®ãƒ‡ã‚¶ã‚¤ãƒ³ã€ã«é–¢å¿ƒã‚’å¯„ã›ã¦ãŠã‚Šã€ç‰¹ã«ãã®ç†æƒ³çš„ãªå½¢ã‚„å›ºå®šè³‡ç”£å•é¡Œã«ã¤ã„ã¦ã®æ‡¸å¿µãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚ã¾ãŸã€ãƒãƒ¼ãƒŸãƒ³ã‚°ã‚„å•†æ¨™ã®è¡¨ç¾ã«é–¢ã™ã‚‹é›£ã—ã•ã‚„ã€æ„è¦‹ã‚’å¼•ãå‡ºã™éš›ã®ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®å·¥å¤«ã«ã¤ã„ã¦ã‚‚è­°è«–ãŒäº¤ã‚ã•ã‚Œã¾ã—ãŸã€‚ç‰¹ã«ã€è‹¥æ‰‹ã®æ„è¦‹ã‚’å°Šé‡ã—ã¤ã¤ã€å‰ã„äººã®æ„è¦‹ã«æµã•ã‚Œãªã„ã‚ˆã†ã«ã™ã‚‹æ–¹æ³•ã‚„ã€è¦–å¯Ÿã®æ„ç¾©ã‚’æ˜ç¢ºã«ã™ã‚‹ã“ã¨ã®é‡è¦æ€§ãŒå¼·èª¿ã•ã‚Œã¾ã—ãŸã€‚","arguments":[{"arg_id":"A10_0","argument":"äººå£æ¸›å°‘ç¤¾ä¼šã ã‹ã‚‰äº‹æ¥­ã‚’é–‰ã˜ã‚‹ä¼šç¤¾ã‚‚ã©ã‚“ã©ã‚“å¤šããªã‚‹ã¯ãšã€‚ã€Œç· ã‚æ–¹ã®ãƒ‡ã‚¶ã‚¤ãƒ³ã€ã¯ç¤¾ä¼šçš„ã«å‚è€ƒã«ãªã‚‹äººå¤šãã†ã€‚","comment_id":"10","x":4.1613336,"y":16.213236,"p":0.6286910228790943},{"arg_id":"A11_0","argument":"ãƒ•ã‚¡ãƒ³ã®æ•°ã‚‚ã™ã”ãå¤šã‹ã£ãŸã‹ã‚‰ç· ã‚æ–¹ã¯æœ¬å½“ã«é›£ã—ãã†","comment_id":"11","x":3.9043355,"y":16.00661,"p":0},{"arg_id":"A17_0","argument":"ãã®ç†æƒ³ã®æ§˜å­ã‚’ã©ã‚“ãªå½¢ã§è¦‹ã›ãŸã‚“ã ã‚ã†ï¼Ÿ","comment_id":"17","x":3.5396814,"y":16.935394,"p":0.5768170706405911},{"arg_id":"A24_0","argument":"å›ºå®šè³‡ç”£å•é¡Œã€ã©ã†ãªã‚‹ã®ï¼Ÿ","comment_id":"24","x":4.0865474,"y":16.946564,"p":0},{"arg_id":"A47_0","argument":"åå‰ã§ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«é£Ÿã„ã¤ã¶ã•ã‚Œã‚‹â‰ï¸","comment_id":"47","x":4.401593,"y":15.522259,"p":1},{"arg_id":"A48_0","argument":"å•†æ¨™ã¨ãƒãƒ¼ãƒŸãƒ³ã‚°ã®è¡¨ç¾ã¯ä¸¡ç«‹ã•ã›ã‚‹ã®ã‚€ãšã„ã‚ˆã­","comment_id":"48","x":4.4940815,"y":16.529984,"p":0.5048353447328134},{"arg_id":"A49_0","argument":"ãã‚‚ãã‚‚ãƒãƒ¼ãƒŸãƒ³ã‚°ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®çµ„ã¿æ–¹ãªã‚“ã¦ã€ã¨ã£ã¦ã‚‚é›£ã—ãã†â€¦","comment_id":"49","x":4.2084394,"y":15.71706,"p":0},{"arg_id":"A50_0","argument":"åå‰ã‚’å‘¼ã¶ã®å¤§äº‹","comment_id":"50","x":4.763368,"y":15.656555,"p":1},{"arg_id":"A54_0","argument":"ç¢ºã‹ã«å£°ãŒå¤§ãã„äººã®æ„è¦‹ã‚’å–ã‚Šå…¥ã‚Œãã†ã«ãªã‚‹...ã¨ã¦ã‚‚å¤§åˆ‡ï¼","comment_id":"54","x":5.0513873,"y":15.848535,"p":1},{"arg_id":"A56_0","argument":"ãã®æ–¹ãŒLWã®ã‚„ã‚ŠãŸã„æ–¹å‘ã«ã‚‚ã£ã¦ãã‚„ã™ã„ã“ã¨ã‚‚ã‚ã‚Šã¾ã™ã‚ˆã­ãƒ¼","comment_id":"56","x":3.7707007,"y":16.560917,"p":0.8562025323897753},{"arg_id":"A57_0","argument":"å‰ã„äººã®å£°ãŒå¤§ãã„å ´åˆã€è‹¥æ‰‹ã«ã©ã†ã§ã™ã‹ï¼Ÿã¨æŒ¯ã£ã¦ã‚‚ã€Œå‰ã®äººã¨åŒã˜ã§ã™ã€ã£ã¦ãªã‚ŠãŒã¡ãªå ´åˆã‚‚ã‚ã‚‹ã‹ãªã¨æ€ã„ã¾ã™ã€‚ãã†è¨€ã†æ™‚ã«ç™½ã‘ãšã«æ„è¦‹ã‚’èãå‡ºã™ã‚³ãƒ„ã‚ã‚Šã¾ã™ã‹ï¼Ÿ","comment_id":"57","x":5.0538216,"y":16.185717,"p":1},{"arg_id":"A59_0","argument":"ã€‡ã€‡ã•ã‚“ãŒæŠ•ç¥¨ã—ãŸã‹ã‚‰ãã®æ¡ˆã‹ãªâ€¦ã¨ã„ã†ã‚ˆã†ãªå¿–åº¦ã¯ãªã‹ã£ãŸã®ã‹æ°—ã«ãªã‚‹","comment_id":"59","x":3.5639927,"y":16.576801,"p":1},{"arg_id":"A61_0","argument":"ãŠã˜å±¤ã¨è‹¥æ‰‹å±¤ã®ç›¸äº’åŠ¹æœã„ã„ã§ã™ã­","comment_id":"61","x":4.6425705,"y":16.262861,"p":0.4954718616767886},{"arg_id":"A63_0","argument":"ã©ã†ã‚·ãƒ³ãƒ—ãƒ«ã«ãªã£ãŸã®ã‹æ°—ã«ãªã‚‹ãªã","comment_id":"63","x":3.620397,"y":16.750755,"p":1},{"arg_id":"A64_0","argument":"ä½•äº‹ã‚‚å¼•ãç¶™ãã¯å¼•ãç¶™ãæ–¹ã‚‚å¼•ãç¶™ãŒã‚Œã‚‹æ–¹ã‚‚é›£ã—ã„ã§ã™ã‚ˆã­","comment_id":"64","x":4.0834517,"y":16.52473,"p":0.6456805827384603},{"arg_id":"A76_0","argument":"é¿ã‘ãŸã„ã»ã†ãŒæ°—ã«ãªã‚Šã¾ã™","comment_id":"76","x":3.2415693,"y":16.403961,"p":0},{"arg_id":"A77_0","argument":"è¦–å¯Ÿã£ã¦ã‚„ã‚ŠãŸã„ã‘ã©ã€ãã‚Œã‚’ã‚„ã£ãŸæ„ç¾©ã‚’è¨€èªåŒ–ã™ã‚‹ã®å¤§äº‹ã§ã™ã‚ˆã­ã€‚çµæ§‹ãƒãƒ¼ãƒ ãƒ“ãƒ«ãƒ‡ã‚£ãƒ³ã‚°ã‚ˆã‚Šã‚‚ãƒ¯ãƒ¼ã‚¯çš„ã«ãªã‚‹ã®ã‹ãªã¨æ€ã„ã¾ã™ãŒã€ã©ã‚“ãªæº–å‚™ã—ã¾ã—ãŸã‹ï¼Ÿã‚‚ã—ãã¯ã—ã¦ãªã„ã§ã™ã‹ï¼Ÿ","comment_id":"77","x":5.3912244,"y":16.296833,"p":0}]}],"comments":{"0":{"comment":"è‰¯ã„å£°ww"},"1":{"comment":"ã¯ã˜ã¾ã‚‹ã‚ˆã€œï¼"},"2":{"comment":"ã‚ãƒ¼ï¼"},"3":{"comment":"ä»Šå›ã‚‚ã‚³ãƒ¡ãƒ³ãƒˆåˆ†æãŸã®ã—ã¿ã€œ"},"4":{"comment":"å‰å›ã¯ã‚¬ãƒ¼ãƒ«ã‚ºãƒãƒ¼ãŒã‚ã¡ã‚ƒãã¡ã‚ƒç››ã‚Šä¸ŠãŒã£ã¦ã¾ã—ãŸã­"},"5":{"comment":"AIåˆ†æã•ã‚“ã«è¤’ã‚ã¦ã‚‚ã‚‰ãˆã‚‹ã‚ˆã†é ‘å¼µã‚‹ãã„"},"6":{"comment":"æ¥å ´è€…57ä¸‡ã€ç«‹æ´¾"},"7":{"comment":"AkeruEãƒãƒ¼ãƒ ã®ç†±é‡ã¯æœ¬å½“ã«ã™ã”ã‹ã£ãŸã§ã™"},"8":{"comment":"Yãƒãƒ¼ãƒ ã‚ãŸã‘ã‚“ã§ã™ã€‚åå¤å±‹ã‹ã‚‰å¿œæ´ï¼"},"9":{"comment":"åå‰ãŒã™ã§ã«ã“ã‚ã„ç¬‘"},"10":{"comment":"äººå£æ¸›å°‘ç¤¾ä¼šã ã‹ã‚‰äº‹æ¥­ã‚’é–‰ã˜ã‚‹ä¼šç¤¾ã‚‚ã©ã‚“ã©ã‚“å¤šããªã‚‹ã¯ãšã€‚ã€Œç· ã‚æ–¹ã®ãƒ‡ã‚¶ã‚¤ãƒ³ã€ã¯ç¤¾ä¼šçš„ã«å‚è€ƒã«ãªã‚‹äººå¤šãã†ã€‚"},"11":{"comment":"ãƒ•ã‚¡ãƒ³ã®æ•°ã‚‚ã™ã”ãå¤šã‹ã£ãŸã‹ã‚‰ç· ã‚æ–¹ã¯æœ¬å½“ã«é›£ã—ãã†"},"12":{"comment":"ãŸã—ã‹ã«ã‚¯ãƒªã‚¹ãƒã‚¹ã‚‰ã¸ã‚“çµ‚æ¥­å¼ã—ã¦ãŸãªã€œ"},"13":{"comment":"ã²ã¨ã„ã£ã±ã„ã "},"14":{"comment":"åœ§å·»ã§ã™ã­"},"15":{"comment":"300äººã®å¸¸é€£ã£ã¦ã¨ã£ã¦ã‚‚å‡„ã„ï¼ï¼"},"16":{"comment":"ã‚¢ã‚±ãƒ«ã‚¨æ„›ã•ã‚Œã¦ã‚‹ï¼"},"17":{"comment":"ãã®ç†æƒ³ã®æ§˜å­ã‚’ã©ã‚“ãªå½¢ã§è¦‹ã›ãŸã‚“ã ã‚ã†ï¼Ÿ"},"18":{"comment":"ç¾å ´ã®ã‚¢ã‚±ãƒ«ã‚¨ãƒãƒ¼ãƒ ã®å‹•ãã°æ©Ÿæ•ã™ãã‚‹ã®ãŒã¨ã¦ã‚‚ã™ã”ã„ã—ï½¤ç¾å ´æ„Ÿã®å®Ÿæ„Ÿã§ãã¦æ„Ÿå‹•ï½¡"},"19":{"comment":"èª­ã‚“ã ã‚‰æ³£ããª"},"20":{"comment":"èª­ã‚“ã ã‚‰æ³£ã(ã‚ãŸã‘ã‚“"},"21":{"comment":"ãã‚Œãã‚Œã®ãƒ‡ã‚¶ã‚¤ãƒ³ã§ã¶ã‚“å›ã—ã¤ã¤ã€ãƒœãƒƒã‚¯ã‚¹ã«å…¥ã‚Œã¦ã¾ã¨ã¾ã‚Šè‰¯ãæ•´ãˆã‚‹ã€ç´ æ•µâ—â—"},"22":{"comment":"ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã¯æ¬¡ã«ç¹‹ãŒã‚Šã¾ã™ã­ã€‚"},"23":{"comment":"ã‚¢ã‚±ãƒ«ã‚¨ã®ç«¶åˆã¨ã„ã†ã‹ã€ä¼¼ãŸæ–½è¨­ã£ã¦å­˜åœ¨ã—ã¦ã‚‹ã®ã§ã—ã‚‡ã†ã‹ï¼Ÿ"},"24":{"comment":"å›ºå®šè³‡ç”£å•é¡Œã€ã©ã†ãªã‚‹ã®ï¼Ÿ"},"25":{"comment":"ä¹ƒæ‘å·¥è—ç¤¾ã‚ªãƒˆã‚³ãƒã‚¨"},"26":{"comment":"ã™ã§ã«å¼•ãå–ã‚Šæ‰‹ãŒã„ã‚‹ã®ã‚ˆã‹ã£ãŸâ€¼ï¸"},"27":{"comment":"ã©ã®ãã‚‰ã„ã®åºƒã•ãŒå¿…è¦ãªã®ï¼Ÿã‚¢ãƒ«ã‚±ãƒŸã‚¹ãƒˆãƒ—ãƒ­ã‚°ãƒ©ãƒ "},"28":{"comment":"ã‚¢ãƒ«ã‚±ãƒŸã‚¹ãƒˆãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®å‚åŠ è€…ãƒ¡ãƒ³ãƒãƒ¼ã¯çµ‚ã‚ã£ãŸä»Šã§ã‚‚å¤‰ã‚ã‚‰ãšã“ã‚Œã¤ãã£ãŸï¼ã“ã‚Œã«å‡ºå±•ã—ã¾ã™ï¼ã¨ã„ã†ã‚ˆã†ãªé€£çµ¡ã—ã¦ãã¦ãã‚Œã¦ã¾ã™ã€œæƒ…ç†±ã¯å¤‰ã‚ã‚‰ãšã¤ã¥ã„ã¦ãŠã‚Šã¾ã™ã€‚(ã‚ãŸã‘ã‚“)"},"29":{"comment":"å¤§æ¾¤ãã‚“ã®ã‚„ã¤ã "},"30":{"comment":"ã‚ã¤ã™ãã‚‹"},"31":{"comment":"ã‚¢ã‚±ãƒ«ã‚¨ã¿ãŸã„ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä½œã‚ŠãŸã„"},"32":{"comment":"ã‚¢ã‚±ãƒ«ã‚¨ã‚’ç· ã‚ã‚‹ã­"},"33":{"comment":"ã‚ãŸã‘ã‚“ã€ã‚ã‚ŠãŒã¨ã†ï¼"},"34":{"comment":"ãƒ‘ãƒŠã‚½ãƒ‹ãƒƒã‚¯ç¶šãã§ã™ã­"},"35":{"comment":"ã‚¨ãƒªã‚¢ã®ãƒ–ãƒ­ãƒƒã‚¯è¡¨ç¤ºã‹ã‚ã„ã„"},"36":{"comment":"ã‹ã‚ã„ã„ï¼"},"37":{"comment":"ã‚¸ãƒ£ãƒ³ãƒ‘ãƒ¼ã»ã—ã„ï¼ï¼"},"38":{"comment":"ãƒ‡ã‚¶ã‚¤ãƒ³ã™ã¦ã"},"39":{"comment":"èƒŒä¸­ãƒ­ã‚´ã®ãƒ¦ãƒ‹ãƒ•ã‚©ãƒ¼ãƒ ã€ã™ã¦ãï¼"},"40":{"comment":"ãƒãƒƒã‚¯ãƒ—ãƒªãƒ³ãƒˆãªã‚¹ã‚¿ãƒƒãƒ•ã˜ã‚ƒã‚“ã±ãƒ¼ã‹ã‚ã„ã„"},"41":{"comment":"ã‚ã£ã¡ã‚ƒã„ã‚ã‚“ãªã“ã¨ã‚„ã£ã¦ã‚‹ã€ã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ã‚‚ç´ æ•µ"},"42":{"comment":"SDSã®æ´»ç”¨æ–¹æ³•ã™ã”ãã„ã„ã§ã™ã­ã€‚å€‹åˆ¥ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ä½¿ã†ã®ã„ã„ãªã¨æ€ã„ã¾ã™"},"43":{"comment":"å¼•ãç¶™ãPMç›®ç·šã§ã‚¿ãƒ¡ã«ãªã‚‹è©±ï¼"},"44":{"comment":"é­”è²«å…‰æ®ºç ²ã¯ãªã‚“ã ã£ãŸã‚“ã ã‚ã†"},"45":{"comment":"ãƒªãƒ”ãƒ¼ãƒˆã™ã°ã‚‰ã—ã„ï¼ï¼"},"46":{"comment":"ã“ã‚Œã™ã£ã”ã„è‹¦åŠ´ã—ã¦ãŸã‚ˆã­"},"47":{"comment":"åå‰ã§ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«é£Ÿã„ã¤ã¶ã•ã‚Œã‚‹â‰ï¸"},"48":{"comment":"å•†æ¨™ã¨ãƒãƒ¼ãƒŸãƒ³ã‚°ã®è¡¨ç¾ã¯ä¸¡ç«‹ã•ã›ã‚‹ã®ã‚€ãšã„ã‚ˆã­"},"49":{"comment":"ãã‚‚ãã‚‚ãƒãƒ¼ãƒŸãƒ³ã‚°ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®çµ„ã¿æ–¹ãªã‚“ã¦ã€ã¨ã£ã¦ã‚‚é›£ã—ãã†â€¦"},"50":{"comment":"åå‰ã‚’å‘¼ã¶ã®å¤§äº‹"},"51":{"comment":"ã‚ªãƒ³ãƒ©ã‚¤ãƒ³MTGã¯ãƒ•ã‚¡ã‚·ãƒªå¤§äº‹"},"52":{"comment":"ç™ºè¨€åˆ‡ã‚Šè¾¼ã¿éšŠé•·"},"53":{"comment":"ã‚ã–ã§ã™ã­"},"54":{"comment":"ç¢ºã‹ã«å£°ãŒå¤§ãã„äººã®æ„è¦‹ã‚’å–ã‚Šå…¥ã‚Œãã†ã«ãªã‚‹...ã¨ã¦ã‚‚å¤§åˆ‡ï¼"},"55":{"comment":"ã‚ãŸã—ã‚‚é€”ä¸­ã§ãƒ–ãƒ¬ã‚¹ãƒˆã‚¿ã‚¤ãƒ ã„ã‚Œã¦ã€å…¨å“¡åŠå¼·åˆ¶çš„ã«ãƒãƒ£ãƒƒãƒˆã«æ„è¦‹æ›¸ã‹ã›ãŸã“ã¨ã‚ã‚Šã¾ã™ï¼"},"56":{"comment":"ãã®æ–¹ãŒLWã®ã‚„ã‚ŠãŸã„æ–¹å‘ã«ã‚‚ã£ã¦ãã‚„ã™ã„ã“ã¨ã‚‚ã‚ã‚Šã¾ã™ã‚ˆã­ãƒ¼"},"57":{"comment":"å‰ã„äººã®å£°ãŒå¤§ãã„å ´åˆã€è‹¥æ‰‹ã«ã©ã†ã§ã™ã‹ï¼Ÿã¨æŒ¯ã£ã¦ã‚‚ã€Œå‰ã®äººã¨åŒã˜ã§ã™ã€ã£ã¦ãªã‚ŠãŒã¡ãªå ´åˆã‚‚ã‚ã‚‹ã‹ãªã¨æ€ã„ã¾ã™ã€‚ãã†è¨€ã†æ™‚ã«ç™½ã‘ãšã«æ„è¦‹ã‚’èãå‡ºã™ã‚³ãƒ„ã‚ã‚Šã¾ã™ã‹ï¼Ÿ"},"58":{"comment":"CLã®ãƒãƒ¼ãƒ ã®é›°å›²æ°—ã‚‚è‰¯ããªã£ã¦ãã†ã§ç´ æ•µï¼"},"59":{"comment":"ã€‡ã€‡ã•ã‚“ãŒæŠ•ç¥¨ã—ãŸã‹ã‚‰ãã®æ¡ˆã‹ãªâ€¦ã¨ã„ã†ã‚ˆã†ãªå¿–åº¦ã¯ãªã‹ã£ãŸã®ã‹æ°—ã«ãªã‚‹"},"60":{"comment":"ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã§ã‚‚ã„ã„ç©ºæ°—ã«ãªã‚‹ã®ã™ã”ã„"},"61":{"comment":"ãŠã˜å±¤ã¨è‹¥æ‰‹å±¤ã®ç›¸äº’åŠ¹æœã„ã„ã§ã™ã­"},"62":{"comment":"ã•ã£ã£ã£ã£ã•ã‚“"},"63":{"comment":"ã©ã†ã‚·ãƒ³ãƒ—ãƒ«ã«ãªã£ãŸã®ã‹æ°—ã«ãªã‚‹ãªã"},"64":{"comment":"ä½•äº‹ã‚‚å¼•ãç¶™ãã¯å¼•ãç¶™ãæ–¹ã‚‚å¼•ãç¶™ãŒã‚Œã‚‹æ–¹ã‚‚é›£ã—ã„ã§ã™ã‚ˆã­"},"65":{"comment":"ã³ã£ãã‚Šã•ã£ã•ã‚“ã‹ã‚ã„ã„ã§ã™"},"66":{"comment":"ãŸã—ã‹ã«ç¬‘"},"67":{"comment":"ãƒãƒ†ãƒã‚’ç®¸ã§é£Ÿã¹ã¦ã‚‹ãªğŸ‘€"},"68":{"comment":"ãƒãƒ†ãƒãŠã§ã‚“ã®æ±ã«ã¤ã‘ã¦ã‚‹ï¼Ÿ"},"69":{"comment":"è¦‹ã¦ã‚‹ã§"},"70":{"comment":"ã“ã®ãƒ­ã‚´ã™ã¦ãã§ã™ï¼"},"71":{"comment":"çŸ¥ã‚‰ãªã‹ã£ãŸ..."},"72":{"comment":"ãƒãƒ«ã®ä¸­ã«ã‚¯ã‚»ãªã‚“ã§ã™ã­"},"73":{"comment":"ã—ã‚ãã¾ã•ã‚“"},"74":{"comment":"ãƒãƒ¼ãƒ ãƒ“ãƒ«ãƒ‡ã‚£ãƒ³ã‚°ã®ãŠé¡Œç›®ã§ã‚¢ãƒ¼ãƒˆã‚’å·¡ã‚‹ã®ã€ç´ æ•µï¼"},"75":{"comment":"CLã¨ç¾è¡“é¤¨ã„ãã®ã„ã„ã§ã™ã­ï¼"},"76":{"comment":"é¿ã‘ãŸã„ã»ã†ãŒæ°—ã«ãªã‚Šã¾ã™"},"77":{"comment":"è¦–å¯Ÿã£ã¦ã‚„ã‚ŠãŸã„ã‘ã©ã€ãã‚Œã‚’ã‚„ã£ãŸæ„ç¾©ã‚’è¨€èªåŒ–ã™ã‚‹ã®å¤§äº‹ã§ã™ã‚ˆã­ã€‚çµæ§‹ãƒãƒ¼ãƒ ãƒ“ãƒ«ãƒ‡ã‚£ãƒ³ã‚°ã‚ˆã‚Šã‚‚ãƒ¯ãƒ¼ã‚¯çš„ã«ãªã‚‹ã®ã‹ãªã¨æ€ã„ã¾ã™ãŒã€ã©ã‚“ãªæº–å‚™ã—ã¾ã—ãŸã‹ï¼Ÿã‚‚ã—ãã¯ã—ã¦ãªã„ã§ã™ã‹ï¼Ÿ"},"78":{"comment":"å¯æ„›ã„ã‚·ãƒ­ã‚¯ãƒ"},"79":{"comment":"ãƒ“ã‚·ãƒƒã¨ã€Œä½•ãŒä¸€ç•ªå¤§äº‹ã‹æ€ã„å‡ºã›!!ã€ç¬‘"}},"overview":"Creative MTGã§ã¯ã€å‚åŠ è€…ã‹ã‚‰ã®ãƒã‚¸ãƒ†ã‚£ãƒ–ãªåå¿œãŒéš›ç«‹ã¡ã€ç‰¹ã«AkeruEãƒãƒ¼ãƒ ã¸ã®ç†±æ„ã‚„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®é­…åŠ›ãŒå¼·èª¿ã•ã‚Œã¾ã—ãŸã€‚å‚åŠ è€…åŒå£«ã®äº¤æµãŒæ´»ç™ºã§ã€ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªè©±é¡Œã‚„æ„Ÿæƒ…è±Šã‹ãªè¡¨ç¾ãŒå°è±¡çš„ã§ã—ãŸã€‚ã¾ãŸã€ã‚¤ãƒ™ãƒ³ãƒˆã®è¦æ¨¡ã‚„ãƒ‡ã‚¶ã‚¤ãƒ³ã«å¯¾ã™ã‚‹ç§°è³›ãŒå¤šãã€å‚åŠ è€…ã®æœŸå¾…æ„ŸãŒé«˜ã¾ã£ã¦ã„ã‚‹æ§˜å­ãŒä¼ºãˆã¾ã™ã€‚ã•ã‚‰ã«ã€äººå£æ¸›å°‘ç¤¾ä¼šã«ãŠã‘ã‚‹äº‹æ¥­ã®èª²é¡Œã«ã¤ã„ã¦ã®å…·ä½“çš„ãªæ„è¦‹ã‚‚äº¤ã‚ã•ã‚Œã€å®Ÿè·µçš„ãªå­¦ã³ãŒå¾—ã‚‰ã‚ŒãŸã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã‚Šã¾ã—ãŸã€‚","config":{"name":"Creative MTG åå¿œã¾ã¨ã‚","question":"Creative MTGã®å‚åŠ è€…ã®åå¿œã«ã¯ã©ã†ã„ã†å‚¾å‘ãŒã‚ã£ãŸã®ã‹","input":"CreativeMTG-20250123","model":"gpt-4o-mini","extraction":{"workers":3,"limit":80,"source_code":"import os\nimport json\nfrom tqdm import tqdm\nimport pandas as pd\nfrom langchain_openai import ChatOpenAI\nfrom utils import messages, update_progress\nimport concurrent.futures\n\n\ndef extraction(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/args.csv\"\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n\n    model = config['extraction']['model']\n    prompt = config['extraction']['prompt']\n    workers = config['extraction']['workers']\n    limit = config['extraction']['limit']\n\n    comment_ids = (comments['comment-id'].values)[:limit]\n    comments.set_index('comment-id', inplace=True)\n    results = pd.DataFrame()\n    update_progress(config, total=len(comment_ids))\n    for i in tqdm(range(0, len(comment_ids), workers)):\n        batch = comment_ids[i: i + workers]\n        batch_inputs = [comments.loc[id]['comment-body'] for id in batch]\n        batch_results = extract_batch(batch_inputs, prompt, model, workers)\n        for comment_id, extracted_args in zip(batch, batch_results):\n            for j, arg in enumerate(extracted_args):\n                new_row = {\"arg-id\": f\"A{comment_id}_{j}\",\n                           \"comment-id\": int(comment_id), \"argument\": arg}\n                results = pd.concat(\n                    [results, pd.DataFrame([new_row])], ignore_index=True)\n        update_progress(config, incr=len(batch))\n    results.to_csv(path, index=False)\n\n\ndef extract_batch(batch, prompt, model, workers):\n    with concurrent.futures.ThreadPoolExecutor(max_workers=workers) as executor:\n        futures = [executor.submit(\n            extract_arguments, input, prompt, model) for input in list(batch)]\n        concurrent.futures.wait(futures)\n        return [future.result() for future in futures]\n\n\ndef extract_arguments(input, prompt, model, retries=3):\n    llm = ChatOpenAI(model=model, temperature=0.0)\n    messages_list = messages(prompt, input)\n    response = llm.invoke(messages_list).content.strip()\n    try:\n        obj = json.loads(response)\n        # LLM sometimes returns valid JSON string\n        if isinstance(obj, str):\n            obj = [obj]\n        items = [a.strip() for a in obj]\n        items = filter(None, items)  # omit empty strings\n        return items\n    except json.decoder.JSONDecodeError as e:\n        print(\"JSON error:\", e)\n        print(\"Input was:\", input)\n        print(\"Response was:\", response)\n        if retries \u003e 0:\n            print(\"Retrying...\")\n            return extract_arguments(input, prompt, model, retries - 1)\n        else:\n            print(\"Silently giving up on trying to generate valid list.\")\n            return []","prompt":"/system\n\nã‚ãªãŸã¯ãƒ—ãƒ­ã®ãƒªã‚µãƒ¼ãƒã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã‚ã‚Šã€ç§ã®ä»•äº‹ã¯è«–æ‹ ã®ãã‚Œã„ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æº–å‚™ã™ã‚‹ã“ã¨ã§ã™ã€‚\n\nèƒŒæ™¯ã¨ã—ã¦ã€ç§ã¯Creative MTGã«å‚åŠ ã—ãŸäººã®ã‚³ãƒ¡ãƒ³ãƒˆã‚’é›†ã‚ã¦ã„ã¾ã™ã€‚\nCreative MTGã§ã¯ã€ã€ŒAkeruEã€ã€ã€Œãƒã‚¯ã‚»ãƒ«Ã—SHIOMERã€ã¨ã„ã†2ã¤ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãŒã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’é€²ã‚ã‚‹ä¸Šã§ä½¿ã£ãŸã€ŒæŠ€ã€ã«ã¤ã„ã¦ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¡Œã„ã¾ã—ãŸã€‚\nCreative MTGã§ã©ã®ã‚ˆã†ãªåå¿œãŒã‚ã£ãŸã®ã‹ã‚’åˆ†é¡ã™ã‚‹ãŠæ‰‹ä¼ã„ã‚’ã—ã¦ã„ãŸã ããŸã„ã§ã™ã€‚\nã“ã‚Œã‹ã‚‰ä¸ãˆã‚‹ã®ã¯Creative MTGã«å‚åŠ ã—ãŸäººã®ã‚³ãƒ¡ãƒ³ãƒˆã®ãƒªã‚¹ãƒˆã§ã™ã€‚\nã“ã‚Œã‹ã‚‰ä¸ãˆã‚‹æŠ•ç¨¿ã‚’JSONãƒªã‚¹ãƒˆã¨ã—ã¦è¿”ã—ã¦ãã ã•ã„ã€‚\næœ¬å½“ã«å¿…è¦ãªå ´åˆã¯ã€2ã¤ä»¥ä¸Šã®åˆ¥ã€…ã®æ„è¦‹ã«åˆ†ã‘ã‚‹ã“ã¨ã‚‚ã§ãã‚‹ãŒã€1ã¤ã®ãƒˆãƒ”ãƒƒã‚¯ã‚’è¿”ã™ã®ãŒæœ€å–„ã§ã‚ã‚‹ã“ã¨ãŒå¤šã„ã§ã—ã‚‡ã†ã€‚\nä»¥ä¸‹ã«ãƒã‚¹ãƒˆã‚’è¦ç´„ã™ã‚‹éš›ã®äº‹ä¾‹ã‚’æŒ™ã’ã¾ã™ã€‚\nã“ã‚Œã‚‰ã¯ã‚ãã¾ã§æ–‡è„ˆã®åˆ‡ã‚Šé›¢ã•ã‚ŒãŸä¾‹ã§ã‚ã‚Šã€ã“ã®ä¾‹ã§ä¸ãˆãŸæ–‡ç« ã‚’è¿”ã™ã“ã¨ã¯ã—ãªã„ã§ãã ã•ã„ã€‚\n\nçµæœã¯ã€ãã¡ã‚“ã¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã•ã‚ŒãŸæ–‡å­—åˆ—å½¢å¼ï¼ˆstringsï¼‰ã®JSONãƒªã‚¹ãƒˆã¨ã—ã¦è¿”ã—ã¦ãã ã•ã„ã€‚\n\n\n/human\n\næ°—å€™å¤‰å‹•ã‚’è€ƒæ…®ã—ãŸã•ã‚‰ãªã‚‹é¢¨æ°´å®³å¯¾ç­–ã®å¼·åŒ–ã«ã¤ã„ã¦ã€éƒ½ã®å…·ä½“çš„ãªè¨ˆç”»ã‚’ãŠä¼ºã„ã—ã¾ã™ã€‚\n\n/ai \n\n[\n  \"æ°—å€™å¤‰å‹•ã‚’è€ƒæ…®ã—ãŸã•ã‚‰ãªã‚‹é¢¨æ°´å®³å¯¾ç­–ã®å¼·åŒ–ã«ã¤ã„ã¦ã€éƒ½ã®å…·ä½“çš„ãªè¨ˆç”»ã‚’ãŠä¼ºã„ã—ã¾ã™ã€‚\"\n]\n\n/human \n\nè±ªé›¨å¯¾ç­–å…¨èˆ¬ã®åŸºæœ¬æ–¹é‡ã®æ¤œè¨ã‚’é€²ã‚ã‚‹ä¸­ã€å…·ä½“çš„ã«ã©ã®ã‚ˆã†ãªæ–½ç­–ã‚’ä½œã£ã¦ã»ã—ã„ã€‚\n\n/ai \n\n[\n  \"è±ªé›¨å¯¾ç­–å…¨èˆ¬ã®åŸºæœ¬æ–¹é‡ã®æ¤œè¨ã‚’é€²ã‚ã‚‹ä¸­ã€å…·ä½“çš„ã«ã©ã®ã‚ˆã†ãªæ–½ç­–ã‚’ä½œã£ã¦ã»ã—ã„ã€‚\",\n]\n\n/human\n\nAIæŠ€è¡“ã¯ã€ãã®ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ã«ãŠã‘ã‚‹ç’°å¢ƒè² è·ã®ä½æ¸›ã«é‡ç‚¹ã‚’ç½®ã„ã¦é–‹ç™ºã•ã‚Œã‚‹ã¹ãã§ã‚ã‚‹ã€‚\n\n/ai\n\n[\n  \"AIæŠ€è¡“ã¯ã€ãã®ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ã«ãŠã‘ã‚‹ç’°å¢ƒè² è·ã®ä½æ¸›ã«é‡ç‚¹ã‚’ç½®ã„ã¦é–‹ç™ºã•ã‚Œã‚‹ã¹ãã§ã‚ã‚‹ã€‚\"\n]\n\n\n/human\n\nã„ã„\n\n/ai\n\n[\n  \"ã„ã„\"\n]\n\n/human\n\nã‚ã¨ã§èª­ã‚€\n\n/ai\n\n[\n  \"ã‚ã¨ã§èª­ã‚€\"\n]\n\n/human\n\nèª­ã‚“ã \n\n/ai\n\n[\n  \"èª­ã‚“ã \"\n]\n\n/human\n\næœŸå¾…\n\n/ai\n\n[\n  \"æœŸå¾…\"\n]","model":"gpt-4o-mini"},"clustering":{"clusters":6,"source_code":"import pandas as pd\nimport numpy as np\nfrom importlib import import_module\nimport MeCab\n\ndef clustering(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/clusters.csv\"\n    arguments_df = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    arguments_array = arguments_df[\"argument\"].values\n\n    embeddings_df = pd.read_pickle(f\"outputs/{dataset}/embeddings.pkl\")\n    embeddings_array = np.asarray(embeddings_df[\"embedding\"].values.tolist())\n    clusters = config['clustering']['clusters']\n\n    result = cluster_embeddings(\n        docs=arguments_array,\n        embeddings=embeddings_array,\n        metadatas={\n            \"arg-id\": arguments_df[\"arg-id\"].values,\n            \"comment-id\": arguments_df[\"comment-id\"].values,\n        },\n        n_topics=clusters,\n    )\n    result.to_csv(path, index=False)\n\n\ndef cluster_embeddings(\n    docs,\n    embeddings,\n    metadatas,\n    min_cluster_size=2,\n    n_components=2,\n    n_topics=6,\n):\n    # å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n    SpectralClustering = import_module('sklearn.cluster').SpectralClustering\n    HDBSCAN = import_module('hdbscan').HDBSCAN\n    UMAP = import_module('umap').UMAP\n    CountVectorizer = import_module('sklearn.feature_extraction.text').CountVectorizer\n    BERTopic = import_module('bertopic').BERTopic\n\n    # NEologdã®è¾æ›¸ãƒ‘ã‚¹ã‚’æŒ‡å®š\n    neologd_path = '/usr/local/lib/mecab/dic/mecab-ipadic-neologd'\n    mecab = MeCab.Tagger(f\"-d {neologd_path} -Ochasen\")\n\n    # å“è©ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’è¡Œã†ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼\n    def tokenizer_mecab(text):\n        node = mecab.parseToNode(text)\n        words = []\n        while node:\n            # åè©ã€å‹•è©ã€å½¢å®¹è©ã ã‘ã‚’æŠ½å‡ºã™ã‚‹\n            if node.feature.startswith('åè©') or node.feature.startswith('å‹•è©') or node.feature.startswith('å½¢å®¹è©'):\n                words.append(node.surface)\n            node = node.next\n        return words\n\n    umap_model = UMAP(\n        random_state=42,\n        n_components=n_components,\n    )\n    hdbscan_model = HDBSCAN(min_cluster_size=min_cluster_size)\n\n    # æ—¥æœ¬èªã®ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆã‚’ä½œæˆï¼ˆå¿…è¦ã«å¿œã˜ã¦æ‹¡å¼µå¯èƒ½ï¼‰\n    japanese_stopwords = [\"ã“ã‚Œ\", \"ãã‚Œ\", \"ã‚ã‚Œ\", \"ã“ã¨\", \"ã‚‚ã®\", \"ãŸã‚\", \"ã‚ˆã†\", \"ã•ã‚“\", \"ã™ã‚‹\", \"ãªã‚‹\", \"ã‚ã‚‹\", \"ã„ã‚‹\"]\n\n    # æ—¥æœ¬èªãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã¨ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ã‚’ä½¿ç”¨ã™ã‚‹\n    vectorizer_model = CountVectorizer(tokenizer=tokenizer_mecab, stop_words=japanese_stopwords)\n\n    topic_model = BERTopic(\n        umap_model=umap_model,\n        hdbscan_model=hdbscan_model,\n        vectorizer_model=vectorizer_model,\n        verbose=True,\n    )\n\n    # ãƒˆãƒ”ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°\n    _, __ = topic_model.fit_transform(docs, embeddings=embeddings)\n\n    n_samples = len(embeddings)\n    n_neighbors = min(n_samples - 1, 10)\n    spectral_model = SpectralClustering(\n        n_clusters=n_topics,\n        affinity=\"nearest_neighbors\",\n        n_neighbors=n_neighbors,\n        random_state=42\n    )\n    umap_embeds = umap_model.fit_transform(embeddings)\n    cluster_labels = spectral_model.fit_predict(umap_embeds)\n\n    result = topic_model.get_document_info(\n        docs=docs,\n        metadata={\n            **metadatas,\n            \"x\": umap_embeds[:, 0],\n            \"y\": umap_embeds[:, 1],\n        },\n    )\n\n    result.columns = [c.lower() for c in result.columns]\n    result = result[['arg-id', 'x', 'y', 'probability']]\n    result['cluster-id'] = cluster_labels\n\n    return result"},"intro":"ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯ã€Slidoã«é›†ã¾ã£ãŸã‚³ãƒ¡ãƒ³ãƒˆã‚’å…ƒã«AIã«ã‚ˆã£ã¦ç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚","output_dir":"CreativeMTG-20250123","previous":{"name":"Creative MTG åå¿œã¾ã¨ã‚","question":"Creative MTGã®å‚åŠ è€…ã®åå¿œã«ã¯ã©ã†ã„ã†å‚¾å‘ãŒã‚ã£ãŸã®ã‹","input":"CreativeMTG-20250123","model":"gpt-4o-mini","extraction":{"workers":3,"limit":80,"source_code":"import os\nimport json\nfrom tqdm import tqdm\nimport pandas as pd\nfrom langchain_openai import ChatOpenAI\nfrom utils import messages, update_progress\nimport concurrent.futures\n\n\ndef extraction(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/args.csv\"\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n\n    model = config['extraction']['model']\n    prompt = config['extraction']['prompt']\n    workers = config['extraction']['workers']\n    limit = config['extraction']['limit']\n\n    comment_ids = (comments['comment-id'].values)[:limit]\n    comments.set_index('comment-id', inplace=True)\n    results = pd.DataFrame()\n    update_progress(config, total=len(comment_ids))\n    for i in tqdm(range(0, len(comment_ids), workers)):\n        batch = comment_ids[i: i + workers]\n        batch_inputs = [comments.loc[id]['comment-body'] for id in batch]\n        batch_results = extract_batch(batch_inputs, prompt, model, workers)\n        for comment_id, extracted_args in zip(batch, batch_results):\n            for j, arg in enumerate(extracted_args):\n                new_row = {\"arg-id\": f\"A{comment_id}_{j}\",\n                           \"comment-id\": int(comment_id), \"argument\": arg}\n                results = pd.concat(\n                    [results, pd.DataFrame([new_row])], ignore_index=True)\n        update_progress(config, incr=len(batch))\n    results.to_csv(path, index=False)\n\n\ndef extract_batch(batch, prompt, model, workers):\n    with concurrent.futures.ThreadPoolExecutor(max_workers=workers) as executor:\n        futures = [executor.submit(\n            extract_arguments, input, prompt, model) for input in list(batch)]\n        concurrent.futures.wait(futures)\n        return [future.result() for future in futures]\n\n\ndef extract_arguments(input, prompt, model, retries=3):\n    llm = ChatOpenAI(model=model, temperature=0.0)\n    messages_list = messages(prompt, input)\n    response = llm.invoke(messages_list).content.strip()\n    try:\n        obj = json.loads(response)\n        # LLM sometimes returns valid JSON string\n        if isinstance(obj, str):\n            obj = [obj]\n        items = [a.strip() for a in obj]\n        items = filter(None, items)  # omit empty strings\n        return items\n    except json.decoder.JSONDecodeError as e:\n        print(\"JSON error:\", e)\n        print(\"Input was:\", input)\n        print(\"Response was:\", response)\n        if retries \u003e 0:\n            print(\"Retrying...\")\n            return extract_arguments(input, prompt, model, retries - 1)\n        else:\n            print(\"Silently giving up on trying to generate valid list.\")\n            return []","prompt":"/system\n\nã‚ãªãŸã¯ãƒ—ãƒ­ã®ãƒªã‚µãƒ¼ãƒã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã‚ã‚Šã€ç§ã®ä»•äº‹ã¯è«–æ‹ ã®ãã‚Œã„ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æº–å‚™ã™ã‚‹ã“ã¨ã§ã™ã€‚\n\nèƒŒæ™¯ã¨ã—ã¦ã€ç§ã¯Creative MTGã«å‚åŠ ã—ãŸäººã®ã‚³ãƒ¡ãƒ³ãƒˆã‚’é›†ã‚ã¦ã„ã¾ã™ã€‚\nCreative MTGã§ã¯ã€ã€ŒAkeruEã€ã€ã€Œãƒã‚¯ã‚»ãƒ«Ã—SHIOMERã€ã¨ã„ã†2ã¤ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãŒã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’é€²ã‚ã‚‹ä¸Šã§ä½¿ã£ãŸã€ŒæŠ€ã€ã«ã¤ã„ã¦ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¡Œã„ã¾ã—ãŸã€‚\nCreative MTGã§ã©ã®ã‚ˆã†ãªåå¿œãŒã‚ã£ãŸã®ã‹ã‚’åˆ†é¡ã™ã‚‹ãŠæ‰‹ä¼ã„ã‚’ã—ã¦ã„ãŸã ããŸã„ã§ã™ã€‚\nã“ã‚Œã‹ã‚‰ä¸ãˆã‚‹ã®ã¯Creative MTGã«å‚åŠ ã—ãŸäººã®ã‚³ãƒ¡ãƒ³ãƒˆã®ãƒªã‚¹ãƒˆã§ã™ã€‚\nã“ã‚Œã‹ã‚‰ä¸ãˆã‚‹æŠ•ç¨¿ã‚’JSONãƒªã‚¹ãƒˆã¨ã—ã¦è¿”ã—ã¦ãã ã•ã„ã€‚\næœ¬å½“ã«å¿…è¦ãªå ´åˆã¯ã€2ã¤ä»¥ä¸Šã®åˆ¥ã€…ã®æ„è¦‹ã«åˆ†ã‘ã‚‹ã“ã¨ã‚‚ã§ãã‚‹ãŒã€1ã¤ã®ãƒˆãƒ”ãƒƒã‚¯ã‚’è¿”ã™ã®ãŒæœ€å–„ã§ã‚ã‚‹ã“ã¨ãŒå¤šã„ã§ã—ã‚‡ã†ã€‚\nä»¥ä¸‹ã«ãƒã‚¹ãƒˆã‚’è¦ç´„ã™ã‚‹éš›ã®äº‹ä¾‹ã‚’æŒ™ã’ã¾ã™ã€‚\nã“ã‚Œã‚‰ã¯ã‚ãã¾ã§æ–‡è„ˆã®åˆ‡ã‚Šé›¢ã•ã‚ŒãŸä¾‹ã§ã‚ã‚Šã€ã“ã®ä¾‹ã§ä¸ãˆãŸæ–‡ç« ã‚’è¿”ã™ã“ã¨ã¯ã—ãªã„ã§ãã ã•ã„ã€‚\n\nçµæœã¯ã€ãã¡ã‚“ã¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã•ã‚ŒãŸæ–‡å­—åˆ—å½¢å¼ï¼ˆstringsï¼‰ã®JSONãƒªã‚¹ãƒˆã¨ã—ã¦è¿”ã—ã¦ãã ã•ã„ã€‚\n\n\n/human\n\næ°—å€™å¤‰å‹•ã‚’è€ƒæ…®ã—ãŸã•ã‚‰ãªã‚‹é¢¨æ°´å®³å¯¾ç­–ã®å¼·åŒ–ã«ã¤ã„ã¦ã€éƒ½ã®å…·ä½“çš„ãªè¨ˆç”»ã‚’ãŠä¼ºã„ã—ã¾ã™ã€‚\n\n/ai \n\n[\n  \"æ°—å€™å¤‰å‹•ã‚’è€ƒæ…®ã—ãŸã•ã‚‰ãªã‚‹é¢¨æ°´å®³å¯¾ç­–ã®å¼·åŒ–ã«ã¤ã„ã¦ã€éƒ½ã®å…·ä½“çš„ãªè¨ˆç”»ã‚’ãŠä¼ºã„ã—ã¾ã™ã€‚\"\n]\n\n/human \n\nè±ªé›¨å¯¾ç­–å…¨èˆ¬ã®åŸºæœ¬æ–¹é‡ã®æ¤œè¨ã‚’é€²ã‚ã‚‹ä¸­ã€å…·ä½“çš„ã«ã©ã®ã‚ˆã†ãªæ–½ç­–ã‚’ä½œã£ã¦ã»ã—ã„ã€‚\n\n/ai \n\n[\n  \"è±ªé›¨å¯¾ç­–å…¨èˆ¬ã®åŸºæœ¬æ–¹é‡ã®æ¤œè¨ã‚’é€²ã‚ã‚‹ä¸­ã€å…·ä½“çš„ã«ã©ã®ã‚ˆã†ãªæ–½ç­–ã‚’ä½œã£ã¦ã»ã—ã„ã€‚\",\n]\n\n/human\n\nAIæŠ€è¡“ã¯ã€ãã®ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ã«ãŠã‘ã‚‹ç’°å¢ƒè² è·ã®ä½æ¸›ã«é‡ç‚¹ã‚’ç½®ã„ã¦é–‹ç™ºã•ã‚Œã‚‹ã¹ãã§ã‚ã‚‹ã€‚\n\n/ai\n\n[\n  \"AIæŠ€è¡“ã¯ã€ãã®ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ã«ãŠã‘ã‚‹ç’°å¢ƒè² è·ã®ä½æ¸›ã«é‡ç‚¹ã‚’ç½®ã„ã¦é–‹ç™ºã•ã‚Œã‚‹ã¹ãã§ã‚ã‚‹ã€‚\"\n]\n\n\n/human\n\nã„ã„\n\n/ai\n\n[\n  \"ã„ã„\"\n]\n\n/human\n\nã‚ã¨ã§èª­ã‚€\n\n/ai\n\n[\n  \"ã‚ã¨ã§èª­ã‚€\"\n]\n\n/human\n\nèª­ã‚“ã \n\n/ai\n\n[\n  \"èª­ã‚“ã \"\n]\n\n/human\n\næœŸå¾…\n\n/ai\n\n[\n  \"æœŸå¾…\"\n]","model":"gpt-4o-mini"},"clustering":{"clusters":5,"source_code":"import pandas as pd\nimport numpy as np\nfrom importlib import import_module\nimport MeCab\n\ndef clustering(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/clusters.csv\"\n    arguments_df = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    arguments_array = arguments_df[\"argument\"].values\n\n    embeddings_df = pd.read_pickle(f\"outputs/{dataset}/embeddings.pkl\")\n    embeddings_array = np.asarray(embeddings_df[\"embedding\"].values.tolist())\n    clusters = config['clustering']['clusters']\n\n    result = cluster_embeddings(\n        docs=arguments_array,\n        embeddings=embeddings_array,\n        metadatas={\n            \"arg-id\": arguments_df[\"arg-id\"].values,\n            \"comment-id\": arguments_df[\"comment-id\"].values,\n        },\n        n_topics=clusters,\n    )\n    result.to_csv(path, index=False)\n\n\ndef cluster_embeddings(\n    docs,\n    embeddings,\n    metadatas,\n    min_cluster_size=2,\n    n_components=2,\n    n_topics=6,\n):\n    # å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n    SpectralClustering = import_module('sklearn.cluster').SpectralClustering\n    HDBSCAN = import_module('hdbscan').HDBSCAN\n    UMAP = import_module('umap').UMAP\n    CountVectorizer = import_module('sklearn.feature_extraction.text').CountVectorizer\n    BERTopic = import_module('bertopic').BERTopic\n\n    # NEologdã®è¾æ›¸ãƒ‘ã‚¹ã‚’æŒ‡å®š\n    neologd_path = '/usr/local/lib/mecab/dic/mecab-ipadic-neologd'\n    mecab = MeCab.Tagger(f\"-d {neologd_path} -Ochasen\")\n\n    # å“è©ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’è¡Œã†ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼\n    def tokenizer_mecab(text):\n        node = mecab.parseToNode(text)\n        words = []\n        while node:\n            # åè©ã€å‹•è©ã€å½¢å®¹è©ã ã‘ã‚’æŠ½å‡ºã™ã‚‹\n            if node.feature.startswith('åè©') or node.feature.startswith('å‹•è©') or node.feature.startswith('å½¢å®¹è©'):\n                words.append(node.surface)\n            node = node.next\n        return words\n\n    umap_model = UMAP(\n        random_state=42,\n        n_components=n_components,\n    )\n    hdbscan_model = HDBSCAN(min_cluster_size=min_cluster_size)\n\n    # æ—¥æœ¬èªã®ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆã‚’ä½œæˆï¼ˆå¿…è¦ã«å¿œã˜ã¦æ‹¡å¼µå¯èƒ½ï¼‰\n    japanese_stopwords = [\"ã“ã‚Œ\", \"ãã‚Œ\", \"ã‚ã‚Œ\", \"ã“ã¨\", \"ã‚‚ã®\", \"ãŸã‚\", \"ã‚ˆã†\", \"ã•ã‚“\", \"ã™ã‚‹\", \"ãªã‚‹\", \"ã‚ã‚‹\", \"ã„ã‚‹\"]\n\n    # æ—¥æœ¬èªãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã¨ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ã‚’ä½¿ç”¨ã™ã‚‹\n    vectorizer_model = CountVectorizer(tokenizer=tokenizer_mecab, stop_words=japanese_stopwords)\n\n    topic_model = BERTopic(\n        umap_model=umap_model,\n        hdbscan_model=hdbscan_model,\n        vectorizer_model=vectorizer_model,\n        verbose=True,\n    )\n\n    # ãƒˆãƒ”ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°\n    _, __ = topic_model.fit_transform(docs, embeddings=embeddings)\n\n    n_samples = len(embeddings)\n    n_neighbors = min(n_samples - 1, 10)\n    spectral_model = SpectralClustering(\n        n_clusters=n_topics,\n        affinity=\"nearest_neighbors\",\n        n_neighbors=n_neighbors,\n        random_state=42\n    )\n    umap_embeds = umap_model.fit_transform(embeddings)\n    cluster_labels = spectral_model.fit_predict(umap_embeds)\n\n    result = topic_model.get_document_info(\n        docs=docs,\n        metadata={\n            **metadatas,\n            \"x\": umap_embeds[:, 0],\n            \"y\": umap_embeds[:, 1],\n        },\n    )\n\n    result.columns = [c.lower() for c in result.columns]\n    result = result[['arg-id', 'x', 'y', 'probability']]\n    result['cluster-id'] = cluster_labels\n\n    return result"},"intro":"ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯ã€Slidoã«é›†ã¾ã£ãŸã‚³ãƒ¡ãƒ³ãƒˆã‚’å…ƒã«AIã«ã‚ˆã£ã¦ç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚","output_dir":"CreativeMTG-20250123","embedding":{"source_code":"from langchain_openai import OpenAIEmbeddings\nfrom langchain_community.chat_models import ChatOpenAI\nimport pandas as pd\nfrom tqdm import tqdm\n\n\ndef embedding(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/embeddings.pkl\"\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    embeddings = []\n    for i in tqdm(range(0, len(arguments), 1000)):\n        args = arguments[\"argument\"].tolist()[i: i + 1000]\n        embeddings_model = OpenAIEmbeddings()\n        embeds = embeddings_model.embed_documents(args)\n\n        embeddings.extend(embeds)\n    df = pd.DataFrame(\n        [\n            {\"arg-id\": arguments.iloc[i][\"arg-id\"], \"embedding\": e}\n            for i, e in enumerate(embeddings)\n        ]\n    )\n    df.to_pickle(path)"},"labelling":{"sample_size":30,"source_code":"\"\"\"Create labels for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain_openai import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef labelling(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/labels.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['labelling']['sample_size']\n    prompt = config['labelling']['prompt']\n    model = config['labelling']['model']\n\n    question = config['question']\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n\n        args_ids_outside = clusters[clusters['cluster-id']\n                                    != cluster_id]['arg-id'].values\n        args_ids_outside = np.random.choice(args_ids_outside, size=min(\n            len(args_ids_outside), sample_size), replace=False)\n        args_sample_outside = arguments[arguments['arg-id']\n                                        .isin(args_ids_outside)]['argument'].values\n\n        label = generate_label(question, args_sample,\n                               args_sample_outside, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'label': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_label(question, args_sample, args_sample_outside, prompt, model):\n    llm = ChatOpenAI(model=model, temperature=0.0)\n    outside = '\\n * ' + '\\n * '.join(args_sample_outside)\n    inside = '\\n * ' + '\\n * '.join(args_sample)\n    input = f\"Question of the consultation:{question}\\n\\n\" + \\\n        f\"Examples of arguments OUTSIDE the cluster:\\n {outside}\" + \\\n        f\"Examples of arguments INSIDE the cluster:\\n {inside}\"\n    response = llm.invoke(input=messages(prompt, input)).content.strip()\n\n    return response","prompt":"/system \n\nã‚ãªãŸã¯ã€Creative MTGã«é–¢ã™ã‚‹ä¸€é€£ã®ã‚³ãƒ¡ãƒ³ãƒˆã«å¯¾ã™ã‚‹ã‚«ãƒ†ã‚´ãƒªãƒ©ãƒ™ãƒ«ã‚’ç”Ÿæˆã™ã‚‹ã‚«ãƒ†ã‚´ãƒªãƒ©ãƒ™ãƒªãƒ³ã‚°ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚\nCreative MTGã§ã¯ã€ã€ŒAkeruEã€ã€ã€Œãƒã‚¯ã‚»ãƒ«Ã—SHIOMERã€ã¨ã„ã†2ã¤ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãŒã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’é€²ã‚ã‚‹ä¸Šã§ä½¿ã£ãŸã€ŒæŠ€ã€ã«ã¤ã„ã¦ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¡Œã„ã¾ã—ãŸã€‚\nã‚ãªãŸã«ã¯ã€ç›¸è«‡ã®ä¸»ãªè³ªå•ã€ã‚¯ãƒ©ã‚¹ã‚¿å†…ã®è­°è«–ã®ãƒªã‚¹ãƒˆã€ãŠã‚ˆã³ã“ã®ã‚¯ãƒ©ã‚¹ã‚¿å¤–ã®è­°è«–ã®ãƒªã‚¹ãƒˆãŒä¸ãˆã‚‰ã‚Œã¾ã™ã€‚ã‚ãªãŸã¯ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã‚’è¦ç´„ã™ã‚‹1ã¤ã®ã‚«ãƒ†ã‚´ãƒªãƒ¼ãƒ©ãƒ™ãƒ«ã§å›ç­”ã—ã¾ã™ã€‚\n\nè³ªå•ã‹ã‚‰ã™ã§ã«æ˜ã‚‰ã‹ãªæ–‡è„ˆã¯å«ã‚ãªã„ï¼ˆã€ŒCreative MTGã®å‚åŠ è€…ã®åå¿œã«ã¯ã©ã†ã„ã†å‚¾å‘ãŒã‚ã£ãŸã®ã‹ã€ã®ã‚ˆã†ãªã‚‚ã®ã§ã‚ã‚Œã°ã€ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®ãƒ©ãƒ™ãƒ«ã«ã€ŒCreative MTGã®å‚åŠ è€…ã®åå¿œã€ã¨ç¹°ã‚Šè¿”ã™å¿…è¦ã¯ãªã„ï¼‰ã€‚\n\nãƒ©ãƒ™ãƒ«ã¯éå¸¸ã«ç°¡æ½”ã§ãªã‘ã‚Œã°ãªã‚‰ãšã€ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã¨ãã®å¤–å´ã«ã‚ã‚‹è«–ç‚¹ã‚’åŒºåˆ¥ã™ã‚‹ã®ã«ååˆ†ãªæ­£ç¢ºã•ã§ãªã‘ã‚Œã°ãªã‚‰ãªã„ã€‚\nãƒ©ãƒ™ãƒ«ã¯å…¨ã¦é‡è¤‡ã—ã¦ã¯ãªã‚‰ãªã„ã€‚\nã€Œå‚åŠ è€…ã®åå¿œã®å‚¾å‘ã€ã€Œå‚åŠ è€…ã®å…·ä½“çš„ãªåå¿œã€ã®ã‚ˆã†ãªã‚‚ã®ã¯ã‚„ã‚ã¦ãã ã•ã„ã€‚\nå…·ä½“çš„ã«ã©ã‚“ãªè©±ã«æ³¨ç›®ãŒé›†ã¾ã£ãŸã‹ã‚’çŸ¥ã‚ŠãŸã„ã§ã™ã€‚\nã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼å¤–ã®è«–ç‚¹ã¨æ˜ç¢ºã«åŒºåˆ¥ã•ã‚Œã‚‹ã‚ˆã†ãªãƒ©ãƒ™ãƒ«ã‚’å›ç­”ã—ã¦ãã ã•ã„ã€‚\n\n/human\n\nã‚³ãƒ³ã‚µãƒ«ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®è³ªå• ã€Œè‹±å›½ã®EUé›¢è„±æ±ºå®šã®å½±éŸ¿ã¯ä½•ã ã¨æ€ã„ã¾ã™ã‹ï¼Ÿ\n\né–¢å¿ƒã®ã‚ã‚‹ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ä»¥å¤–ã®è«–ç‚¹ã®ä¾‹\n\n * ã‚¨ãƒ©ã‚¹ãƒ ã‚¹ãƒ»ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‹ã‚‰ã®é™¤å¤–ã«ã‚ˆã‚Šã€æ•™è‚²ãƒ»æ–‡åŒ–äº¤æµã®æ©Ÿä¼šãŒåˆ¶é™ã•ã‚ŒãŸã€‚\n * è‹±å›½ã¯ã€å›½å¢ƒæ¤œå•ã®å¼·åŒ–ã«ã‚ˆã‚‹æ—…è¡Œæ™‚é–“ã®å»¶é•·ã«å¯¾å‡¦ã—ã€é€šå‹¤å®¢ã‚„æ—…è¡Œå®¢ã«å½±éŸ¿ã‚’ä¸ãˆãŸã€‚\n * ç’°å¢ƒåŸºæº–ã«ãŠã‘ã‚‹å”åŠ›ãŒæ¸›å°‘ã—ã€æ°—å€™å¤‰å‹•ã¨é—˜ã†åŠªåŠ›ãŒå¦¨ã’ã‚‰ã‚ŒãŸã€‚\n * ç›¸äº’åŒ»ç™‚å”å®šã®ä¸­æ–­ã«ã‚ˆã‚Šã€æ‚£è€…ã‚±ã‚¢ã«èª²é¡Œã‚’æ„Ÿã˜ãŸã€‚\n * Brexité–¢é€£ã®å¤‰æ›´ã«ã‚ˆã‚Šã€å®¶æ—ã®å±…ä½æ¨©ã‚„å¸‚æ°‘æ¨©ã®ç”³è«‹ãŒè¤‡é›‘ã«ãªã£ãŸã€‚\n * è‹±å›½ã¯ã€å…±åŒç ”ç©¶æ©Ÿä¼šã®æ¸›å°‘ã«ã‚ˆã‚Šã€ç ”ç©¶ã®èª²é¡Œã«å–ã‚Šçµ„ã‚€ä¸–ç•Œçš„ãªå–ã‚Šçµ„ã¿ã«æ”¯éšœã‚’ããŸã™ã“ã¨ã‚’ç›®ã®å½“ãŸã‚Šã«ã—ãŸã€‚\n * EUã®æ–‡åŒ–åŠ©æˆãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‹ã‚‰ã®é™¤å¤–ã«ã‚ˆã‚Šã€å‰µé€ çš„ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®åˆ¶é™ã«ç›´é¢ã—ãŸã€‚\n * è‹±å›½ã¯ã€EUã®è³‡é‡‘æä¾›ã®å–ªå¤±ã«ã‚ˆã‚Šã€æ…ˆå–„æ´»å‹•ã‚„ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æ”¯æ´ã®å¾Œé€€ã‚’ç›®ã®å½“ãŸã‚Šã«ã—ãŸã€‚\n * æ¶ˆè²»è€…ä¿è­·ã®å¼±ä½“åŒ–ã«ã‚ˆã‚Šã€å›½å¢ƒã‚’è¶ŠãˆãŸç´›äº‰è§£æ±ºã«èª²é¡ŒãŒç”Ÿã˜ãŸã€‚\n * è‹±å›½ã¯ãƒ—ãƒ­ã®éŸ³æ¥½å®¶ã¨ã—ã¦EUè«¸å›½ã‚’ãƒ„ã‚¢ãƒ¼ã™ã‚‹éš›ã®åˆ¶é™ã«ç›´é¢ã—ã€ã‚­ãƒ£ãƒªã‚¢ã«å½±éŸ¿ã‚’ä¸ãˆãŸã€‚\n\nã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼å†…éƒ¨ã§ã®è­°è«–ã®ä¾‹\n\n * Brexitã«ã‚ˆã‚Šã‚µãƒ—ãƒ©ã‚¤ãƒã‚§ãƒ¼ãƒ³ãŒæ··ä¹±ã—ã€ä¼æ¥­ã«ã¨ã£ã¦ã‚³ã‚¹ãƒˆå¢—ã¨ç´æœŸé…å»¶ã«ã¤ãªãŒã£ãŸã€‚\n * ãƒ–ãƒ¬ã‚°ã‚¸ãƒƒãƒˆã®ãŸã‚ã€å¸‚å ´ã®å¤‰å‹•ã‚„æŠ•è³‡ãƒ»é€€è·é‡‘ã®ä¸ç¢ºå®Ÿæ€§ã«ç›´é¢ã—ãŸã€‚\n * æ–°ãŸãªé–¢ç¨ã‚„é€šé–¢æ‰‹ç¶šãã«ã‚ˆã‚Šã€è‹±å›½ã¯è¼¸å‡ºæ¥­è€…ã¨ã—ã¦åˆ©ç›Šç‡ã®ä½ä¸‹ã«å¯¾å‡¦ã—ãŸã€‚\n * ãƒ–ãƒ¬ã‚°ã‚¸ãƒƒãƒˆå¾Œã€ä¼æ¥­ãŒEUå¸‚å ´å†…ã«ã¨ã©ã¾ã‚‹ãŸã‚ã«äº‹æ¥­ã‚’ç§»è»¢ã—ãŸãŸã‚ã€é›‡ç”¨ã‚’å¤±ã£ãŸã€‚\n * è‹±å›½ã¯è¼¸å…¥å“ä¾¡æ ¼ã®é«˜é¨°ã«ã‚ˆã‚‹ç”Ÿæ´»è²»ã®å¢—åŠ ã«è‹¦ã—ã‚“ã ã€‚\n * è‹±å›½ã®ãƒã‚¤ãƒ†ã‚¯ç”£æ¥­ã¸ã®æŠ•è³‡ãŒæ¸›å°‘ã—ã€æŠ€è¡“é©æ–°ã¨é›‡ç”¨æ©Ÿä¼šã«å½±éŸ¿ã‚’ä¸ãˆãŸã€‚\n * æ–°ãŸãªãƒ“ã‚¶è¦åˆ¶ã«ã‚ˆã‚‹è¦³å…‰å®¢ã®æ¸›å°‘ã‚’ç›®ã®å½“ãŸã‚Šã«ã—ã€æ¥å®¢æ¥­ã«å½±éŸ¿ã€‚\n * ãƒãƒ³ãƒ‰ä¾¡å€¤ã®ä¸‹è½ã«ã‚ˆã‚Šè³¼è²·åŠ›ãŒä½ä¸‹ã—ã€æ—…è²»ãŒå¢—åŠ ã—ãŸã€‚\n\n\n/ai \n\nè²¡å‹™ä¸Šã®ãƒã‚¤ãƒŠã‚¹å½±éŸ¿","model":"gpt-4o-mini"},"takeaways":{"sample_size":30,"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain_community.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef takeaways(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/takeaways.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['takeaways']['sample_size']\n    prompt = config['takeaways']['prompt']\n    model = config['takeaways']['model']\n\n    model = config.get('model_takeaways', config.get('model', 'gpt3.5-turbo'))\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n        label = generate_takeaways(args_sample, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'takeaways': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_takeaways(args_sample, prompt, model):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    input = \"\\n\".join(args_sample)\n    response = llm.invoke(input=messages(prompt, input)).content.strip()\n    return response","prompt":"/system \n\nã‚ãªãŸã¯ã‚·ãƒ³ã‚¯ã‚¿ãƒ³ã‚¯ã§åƒããƒªã‚µãƒ¼ãƒã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚Creative MTGã«å‚åŠ ã—ãŸäººã®ã‚³ãƒ¡ãƒ³ãƒˆã®ãƒªã‚¹ãƒˆãŒæ¸¡ã•ã‚Œã¾ã™ã€‚\nCreative MTGã§ã¯ã€ã€ŒAkeruEã€ã€ã€Œãƒã‚¯ã‚»ãƒ«Ã—SHIOMERã€ã¨ã„ã†2ã¤ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãŒã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’é€²ã‚ã‚‹ä¸Šã§ä½¿ã£ãŸã€ŒæŠ€ã€ã«ã¤ã„ã¦ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¡Œã„ã¾ã—ãŸã€‚\nã‚ãªãŸã¯ã€ã©ã‚“ãªè©±ã«æ³¨ç›®ãŒé›†ã¾ã£ãŸã‹ã€ä¸»ãªè¦ç‚¹ã‚’1~2æ®µè½ã«ã¾ã¨ã‚ã¦å›ç­”ã—ã¾ã™ã€‚ã‚ãªãŸã¯ç°¡æ½”ã§èª­ã¿ã‚„ã™ã„çŸ­ã„æ–‡ç« ã‚’æ›¸ãã“ã¨ãŒã§ãã¾ã™ã€‚ \n \n/human\n\n[\n  \"éŠƒã«ã‚ˆã‚‹æš´åŠ›ã¯ã€ç§ãŸã¡ã®ç¤¾ä¼šã«ãŠã‘ã‚‹æ·±åˆ»ãªå…¬è¡†è¡›ç”Ÿã®å±æ©Ÿã‚’æ§‹æˆã—ã¦ã„ã‚‹ã¨å›ºãä¿¡ã˜ã¦ã„ã¾ã™ã€‚\",\n  \"åŒ…æ‹¬çš„ãªéŠƒè¦åˆ¶ç­–ã‚’é€šã˜ã¦ã€ã“ã®å•é¡Œã«æ—©æ€¥ã«å–ã‚Šçµ„ã‚€å¿…è¦ãŒã‚ã‚‹ã€‚\",\n  \"ã™ã¹ã¦ã®éŠƒè³¼å…¥è€…ã«å¯¾ã™ã‚‹èº«å…ƒèª¿æŸ»ã®å®Ÿæ–½ã‚’æ”¯æŒã—ã¾ã™ã€‚\",\n  \"ã‚¢ã‚µãƒ«ãƒˆãƒ»ã‚¦ã‚§ãƒãƒ³ã¨å¤§å®¹é‡å¼¾å€‰ã®ç¦æ­¢ã«è³›æˆã—ã¾ã™ã€‚\",\n  \"é•æ³•ãªéŠƒã®å£²è²·ã‚’é˜²ããŸã‚ã€ã‚ˆã‚Šå³ã—ã„è¦åˆ¶ã‚’æå”±ã—ã¾ã™ã€‚\",\n  \"éŠƒã®è³¼å…¥ãƒ—ãƒ­ã‚»ã‚¹ã«ãŠã„ã¦ã€ç²¾ç¥é‘‘å®šã‚’ç¾©å‹™ä»˜ã‘ã‚‹ã¹ãã§ã‚ã‚‹ã€‚\"\n]\n\n/ai \n\nå‚åŠ è€…ã¯ã€åŒ…æ‹¬çš„ãªéŠƒè¦åˆ¶ã‚’æ±‚ã‚ã€æ™®éçš„ãªèº«å…ƒèª¿æŸ»ã€çªæ’ƒå…µå™¨ã®ç¦æ­¢ã€é•æ³•ãªéŠƒå£²è²·ã®æŠ‘åˆ¶ã€ç²¾ç¥è¡›ç”Ÿè©•ä¾¡ã®å„ªå…ˆãªã©ã‚’å¼·èª¿ã—ãŸã€‚","model":"gpt-4o-mini"},"overview":{"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain_community.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef overview(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/overview.txt\"\n\n    takeaways = pd.read_csv(f\"outputs/{dataset}/takeaways.csv\")\n    labels = pd.read_csv(f\"outputs/{dataset}/labels.csv\")\n\n    prompt = config['overview']['prompt']\n    model = config['overview']['model']\n\n    ids = labels['cluster-id'].to_list()\n    takeaways.set_index('cluster-id', inplace=True)\n    labels.set_index('cluster-id', inplace=True)\n\n    input = ''\n    for i, id in enumerate(ids):\n        input += f\"# Cluster {i}/{len(ids)}: {labels.loc[id]['label']}\\n\\n\"\n        input += takeaways.loc[id]['takeaways'] + '\\n\\n'\n\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    response = llm(messages=messages(prompt, input)).content.strip()\n\n    with open(path, 'w') as file:\n        file.write(response)","prompt":"/system \nã‚ãªãŸã¯ã‚·ãƒ³ã‚¯ã‚¿ãƒ³ã‚¯ã§åƒãå°‚é–€å®¶ãƒªã‚µãƒ¼ãƒã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ã‚ãªãŸã®ãƒãƒ¼ãƒ ã¯ã€ã‚ã‚‹ãƒˆãƒ”ãƒƒã‚¯ã«é–¢ã™ã‚‹å…¬é–‹ã‚³ãƒ³ã‚µãƒ«ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿæ–½ã—ã€ã•ã¾ã–ã¾ãªé¸æŠè‚¢ã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã‚’åˆ†æã—å§‹ã‚ã¾ã—ãŸã€‚ã‚ãªãŸã¯ä»Šã€ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®ãƒªã‚¹ãƒˆã¨å„ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®ç°¡å˜ãªåˆ†æã‚’å—ã‘å–ã‚Šã¾ã™ã€‚ã‚ãªãŸã®ä»•äº‹ã¯ã€CreativeMTGã§ã©ã‚“ãªè©±ã«æ³¨ç›®ãŒé›†ã¾ã£ãŸã‹ã‚’ç°¡æ½”ã«ã¾ã¨ã‚ã‚‹ã“ã¨ã§ã™ã€‚ã‚ãªãŸã®è¦ç´„ã¯éå¸¸ã«ç°¡æ½”ã§ãªã‘ã‚Œã°ãªã‚‰ãšï¼ˆã›ã„ãœã„1æ®µè½ã€ã›ã„ãœã„4æ–‡ï¼‰ã€å¹³å‡¡ãªè¡¨ç¾ã¯é¿ã‘ãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚\nè£œè¶³ã¨ã—ã¦ã€Creative MTGã§ã¯ã€ã€ŒAkeruEã€ã€ã€Œãƒã‚¯ã‚»ãƒ«Ã—SHIOMERã€ã¨ã„ã†2ã¤ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãŒã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’é€²ã‚ã‚‹ä¸Šã§ä½¿ã£ãŸã€ŒæŠ€ã€ã«ã¤ã„ã¦ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¡Œã„ã¾ã—ãŸã€‚","model":"gpt-4o-mini"},"aggregation":{"source_code":"\"\"\"Generate a convenient JSON output file.\"\"\"\n\nfrom tqdm import tqdm\nfrom typing import List\nimport pandas as pd\nfrom langchain_community.chat_models import ChatOpenAI\nimport json\n\n\ndef aggregation(config):\n\n    path = f\"outputs/{config['output_dir']}/result.json\"\n\n    results = {\n        \"clusters\": [],\n        \"comments\": {},\n        \"overview\": \"\",\n        \"config\": config,\n    }\n\n    arguments = pd.read_csv(f\"outputs/{config['output_dir']}/args.csv\")\n    arguments.set_index('arg-id', inplace=True)\n\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n    useful_comment_ids = set(arguments['comment-id'].values)\n    for _, row in comments.iterrows():\n        id = row['comment-id']\n        if id in useful_comment_ids:\n            res = {'comment': row['comment-body']}\n            numeric_cols = ['agrees', 'disagrees']\n            string_cols = ['video', 'interview', 'timestamp']\n            for col in numeric_cols:\n                if col in row:\n                    res[col] = float(row[col])\n            for col in string_cols:\n                if col in row:\n                    res[col] = row[col]\n            results['comments'][str(id)] = res\n\n    languages = list(config.get('translation', {}).get('languages', []))\n    if len(languages) \u003e 0:\n        with open(f\"outputs/{config['output_dir']}/translations.json\") as f:\n            translations = f.read()\n        results['translations'] = json.loads(translations)\n\n    clusters = pd.read_csv(f\"outputs/{config['output_dir']}/clusters.csv\")\n    labels = pd.read_csv(f\"outputs/{config['output_dir']}/labels.csv\")\n    takeaways = pd.read_csv(f\"outputs/{config['output_dir']}/takeaways.csv\")\n    takeaways.set_index('cluster-id', inplace=True)\n\n    with open(f\"outputs/{config['output_dir']}/overview.txt\") as f:\n        overview = f.read()\n    results['overview'] = overview\n\n    for _, row in labels.iterrows():\n        cid = row['cluster-id']\n        label = row['label']\n        arg_rows = clusters[clusters['cluster-id'] == cid]\n        arguments_in_cluster = []\n        for _, arg_row in arg_rows.iterrows():\n            arg_id = arg_row['arg-id']\n            argument = arguments.loc[arg_id]['argument']\n            comment_id = arguments.loc[arg_id]['comment-id']\n            x = float(arg_row['x'])\n            y = float(arg_row['y'])\n            p = float(arg_row['probability'])\n            obj = {\n                'arg_id': arg_id,\n                'argument': argument,\n                'comment_id': str(comment_id),\n                'x': x,\n                'y': y,\n                'p': p,\n            }\n            arguments_in_cluster.append(obj)\n        results['clusters'].append({\n            'cluster': label,\n            'cluster_id': str(cid),\n            'takeaways': takeaways.loc[cid]['takeaways'],\n            'arguments': arguments_in_cluster\n        })\n\n    with open(path, 'w') as file:\n        json.dump(results, file, indent=2)\n"},"visualization":{"replacements":[],"source_code":"\nimport subprocess\n\n\ndef visualization(config):\n    output_dir = config['output_dir']\n    with open(f\"outputs/{output_dir}/result.json\") as f:\n        result = f.read()\n\n    cwd = \"../next-app\"\n    command = f\"REPORT={output_dir} npm run build\"\n\n    try:\n        process = subprocess.Popen(command, shell=True, cwd=cwd, stdout=subprocess.PIPE,\n                                   stderr=subprocess.PIPE, universal_newlines=True)\n        while True:\n            output_line = process.stdout.readline()\n            if output_line == '' and process.poll() is not None:\n                break\n            if output_line:\n                print(output_line.strip())\n        process.wait()\n        errors = process.stderr.read()\n        if errors:\n            print(\"Errors:\")\n            print(errors)\n    except subprocess.CalledProcessError as e:\n        print(\"Error: \", e)\n"},"plan":[{"step":"extraction","run":true,"reason":"some parameters changed: prompt"},{"step":"embedding","run":true,"reason":"some dependent steps will re-run: extraction"},{"step":"clustering","run":true,"reason":"some dependent steps will re-run: embedding"},{"step":"labelling","run":true,"reason":"some dependent steps will re-run: clustering"},{"step":"takeaways","run":true,"reason":"some dependent steps will re-run: clustering"},{"step":"overview","run":true,"reason":"some dependent steps will re-run: labelling, takeaways"},{"step":"aggregation","run":true,"reason":"some dependent steps will re-run: extraction, clustering, labelling, takeaways, overview"},{"step":"visualization","run":true,"reason":"some dependent steps will re-run: aggregation"}],"status":"completed","start_time":"2025-01-24T18:34:47.570221","completed_jobs":[{"step":"extraction","completed":"2025-01-24T18:36:14.152792","duration":86.575595,"params":{"workers":3,"limit":80,"source_code":"import os\nimport json\nfrom tqdm import tqdm\nimport pandas as pd\nfrom langchain_openai import ChatOpenAI\nfrom utils import messages, update_progress\nimport concurrent.futures\n\n\ndef extraction(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/args.csv\"\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n\n    model = config['extraction']['model']\n    prompt = config['extraction']['prompt']\n    workers = config['extraction']['workers']\n    limit = config['extraction']['limit']\n\n    comment_ids = (comments['comment-id'].values)[:limit]\n    comments.set_index('comment-id', inplace=True)\n    results = pd.DataFrame()\n    update_progress(config, total=len(comment_ids))\n    for i in tqdm(range(0, len(comment_ids), workers)):\n        batch = comment_ids[i: i + workers]\n        batch_inputs = [comments.loc[id]['comment-body'] for id in batch]\n        batch_results = extract_batch(batch_inputs, prompt, model, workers)\n        for comment_id, extracted_args in zip(batch, batch_results):\n            for j, arg in enumerate(extracted_args):\n                new_row = {\"arg-id\": f\"A{comment_id}_{j}\",\n                           \"comment-id\": int(comment_id), \"argument\": arg}\n                results = pd.concat(\n                    [results, pd.DataFrame([new_row])], ignore_index=True)\n        update_progress(config, incr=len(batch))\n    results.to_csv(path, index=False)\n\n\ndef extract_batch(batch, prompt, model, workers):\n    with concurrent.futures.ThreadPoolExecutor(max_workers=workers) as executor:\n        futures = [executor.submit(\n            extract_arguments, input, prompt, model) for input in list(batch)]\n        concurrent.futures.wait(futures)\n        return [future.result() for future in futures]\n\n\ndef extract_arguments(input, prompt, model, retries=3):\n    llm = ChatOpenAI(model=model, temperature=0.0)\n    messages_list = messages(prompt, input)\n    response = llm.invoke(messages_list).content.strip()\n    try:\n        obj = json.loads(response)\n        # LLM sometimes returns valid JSON string\n        if isinstance(obj, str):\n            obj = [obj]\n        items = [a.strip() for a in obj]\n        items = filter(None, items)  # omit empty strings\n        return items\n    except json.decoder.JSONDecodeError as e:\n        print(\"JSON error:\", e)\n        print(\"Input was:\", input)\n        print(\"Response was:\", response)\n        if retries \u003e 0:\n            print(\"Retrying...\")\n            return extract_arguments(input, prompt, model, retries - 1)\n        else:\n            print(\"Silently giving up on trying to generate valid list.\")\n            return []","prompt":"/system\n\nã‚ãªãŸã¯ãƒ—ãƒ­ã®ãƒªã‚µãƒ¼ãƒã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã‚ã‚Šã€ç§ã®ä»•äº‹ã¯è«–æ‹ ã®ãã‚Œã„ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æº–å‚™ã™ã‚‹ã“ã¨ã§ã™ã€‚\n\nèƒŒæ™¯ã¨ã—ã¦ã€ç§ã¯Creative MTGã«å‚åŠ ã—ãŸäººã®ã‚³ãƒ¡ãƒ³ãƒˆã‚’é›†ã‚ã¦ã„ã¾ã™ã€‚\nCreative MTGã§ã¯ã€ã€ŒAkeruEã€ã€ã€Œãƒã‚¯ã‚»ãƒ«Ã—SHIOMERã€ã¨ã„ã†2ã¤ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãŒã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’é€²ã‚ã‚‹ä¸Šã§ä½¿ã£ãŸã€ŒæŠ€ã€ã«ã¤ã„ã¦ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¡Œã„ã¾ã—ãŸã€‚\nCreative MTGã§ã©ã®ã‚ˆã†ãªåå¿œãŒã‚ã£ãŸã®ã‹ã‚’åˆ†é¡ã™ã‚‹ãŠæ‰‹ä¼ã„ã‚’ã—ã¦ã„ãŸã ããŸã„ã§ã™ã€‚\nã“ã‚Œã‹ã‚‰ä¸ãˆã‚‹ã®ã¯Creative MTGã«å‚åŠ ã—ãŸäººã®ã‚³ãƒ¡ãƒ³ãƒˆã®ãƒªã‚¹ãƒˆã§ã™ã€‚\nã“ã‚Œã‹ã‚‰ä¸ãˆã‚‹æŠ•ç¨¿ã‚’JSONãƒªã‚¹ãƒˆã¨ã—ã¦è¿”ã—ã¦ãã ã•ã„ã€‚\næœ¬å½“ã«å¿…è¦ãªå ´åˆã¯ã€2ã¤ä»¥ä¸Šã®åˆ¥ã€…ã®æ„è¦‹ã«åˆ†ã‘ã‚‹ã“ã¨ã‚‚ã§ãã‚‹ãŒã€1ã¤ã®ãƒˆãƒ”ãƒƒã‚¯ã‚’è¿”ã™ã®ãŒæœ€å–„ã§ã‚ã‚‹ã“ã¨ãŒå¤šã„ã§ã—ã‚‡ã†ã€‚\nä»¥ä¸‹ã«ãƒã‚¹ãƒˆã‚’è¦ç´„ã™ã‚‹éš›ã®äº‹ä¾‹ã‚’æŒ™ã’ã¾ã™ã€‚\nã“ã‚Œã‚‰ã¯ã‚ãã¾ã§æ–‡è„ˆã®åˆ‡ã‚Šé›¢ã•ã‚ŒãŸä¾‹ã§ã‚ã‚Šã€ã“ã®ä¾‹ã§ä¸ãˆãŸæ–‡ç« ã‚’è¿”ã™ã“ã¨ã¯ã—ãªã„ã§ãã ã•ã„ã€‚\n\nçµæœã¯ã€ãã¡ã‚“ã¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã•ã‚ŒãŸæ–‡å­—åˆ—å½¢å¼ï¼ˆstringsï¼‰ã®JSONãƒªã‚¹ãƒˆã¨ã—ã¦è¿”ã—ã¦ãã ã•ã„ã€‚\n\n\n/human\n\næ°—å€™å¤‰å‹•ã‚’è€ƒæ…®ã—ãŸã•ã‚‰ãªã‚‹é¢¨æ°´å®³å¯¾ç­–ã®å¼·åŒ–ã«ã¤ã„ã¦ã€éƒ½ã®å…·ä½“çš„ãªè¨ˆç”»ã‚’ãŠä¼ºã„ã—ã¾ã™ã€‚\n\n/ai \n\n[\n  \"æ°—å€™å¤‰å‹•ã‚’è€ƒæ…®ã—ãŸã•ã‚‰ãªã‚‹é¢¨æ°´å®³å¯¾ç­–ã®å¼·åŒ–ã«ã¤ã„ã¦ã€éƒ½ã®å…·ä½“çš„ãªè¨ˆç”»ã‚’ãŠä¼ºã„ã—ã¾ã™ã€‚\"\n]\n\n/human \n\nè±ªé›¨å¯¾ç­–å…¨èˆ¬ã®åŸºæœ¬æ–¹é‡ã®æ¤œè¨ã‚’é€²ã‚ã‚‹ä¸­ã€å…·ä½“çš„ã«ã©ã®ã‚ˆã†ãªæ–½ç­–ã‚’ä½œã£ã¦ã»ã—ã„ã€‚\n\n/ai \n\n[\n  \"è±ªé›¨å¯¾ç­–å…¨èˆ¬ã®åŸºæœ¬æ–¹é‡ã®æ¤œè¨ã‚’é€²ã‚ã‚‹ä¸­ã€å…·ä½“çš„ã«ã©ã®ã‚ˆã†ãªæ–½ç­–ã‚’ä½œã£ã¦ã»ã—ã„ã€‚\",\n]\n\n/human\n\nAIæŠ€è¡“ã¯ã€ãã®ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ã«ãŠã‘ã‚‹ç’°å¢ƒè² è·ã®ä½æ¸›ã«é‡ç‚¹ã‚’ç½®ã„ã¦é–‹ç™ºã•ã‚Œã‚‹ã¹ãã§ã‚ã‚‹ã€‚\n\n/ai\n\n[\n  \"AIæŠ€è¡“ã¯ã€ãã®ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ã«ãŠã‘ã‚‹ç’°å¢ƒè² è·ã®ä½æ¸›ã«é‡ç‚¹ã‚’ç½®ã„ã¦é–‹ç™ºã•ã‚Œã‚‹ã¹ãã§ã‚ã‚‹ã€‚\"\n]\n\n\n/human\n\nã„ã„\n\n/ai\n\n[\n  \"ã„ã„\"\n]\n\n/human\n\nã‚ã¨ã§èª­ã‚€\n\n/ai\n\n[\n  \"ã‚ã¨ã§èª­ã‚€\"\n]\n\n/human\n\nèª­ã‚“ã \n\n/ai\n\n[\n  \"èª­ã‚“ã \"\n]\n\n/human\n\næœŸå¾…\n\n/ai\n\n[\n  \"æœŸå¾…\"\n]","model":"gpt-4o-mini"}},{"step":"embedding","completed":"2025-01-24T18:36:16.303376","duration":2.147389,"params":{"source_code":"from langchain_openai import OpenAIEmbeddings\nfrom langchain_community.chat_models import ChatOpenAI\nimport pandas as pd\nfrom tqdm import tqdm\n\n\ndef embedding(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/embeddings.pkl\"\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    embeddings = []\n    for i in tqdm(range(0, len(arguments), 1000)):\n        args = arguments[\"argument\"].tolist()[i: i + 1000]\n        embeddings_model = OpenAIEmbeddings()\n        embeds = embeddings_model.embed_documents(args)\n\n        embeddings.extend(embeds)\n    df = pd.DataFrame(\n        [\n            {\"arg-id\": arguments.iloc[i][\"arg-id\"], \"embedding\": e}\n            for i, e in enumerate(embeddings)\n        ]\n    )\n    df.to_pickle(path)"}},{"step":"clustering","completed":"2025-01-24T18:36:49.118022","duration":32.813041,"params":{"clusters":5,"source_code":"import pandas as pd\nimport numpy as np\nfrom importlib import import_module\nimport MeCab\n\ndef clustering(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/clusters.csv\"\n    arguments_df = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    arguments_array = arguments_df[\"argument\"].values\n\n    embeddings_df = pd.read_pickle(f\"outputs/{dataset}/embeddings.pkl\")\n    embeddings_array = np.asarray(embeddings_df[\"embedding\"].values.tolist())\n    clusters = config['clustering']['clusters']\n\n    result = cluster_embeddings(\n        docs=arguments_array,\n        embeddings=embeddings_array,\n        metadatas={\n            \"arg-id\": arguments_df[\"arg-id\"].values,\n            \"comment-id\": arguments_df[\"comment-id\"].values,\n        },\n        n_topics=clusters,\n    )\n    result.to_csv(path, index=False)\n\n\ndef cluster_embeddings(\n    docs,\n    embeddings,\n    metadatas,\n    min_cluster_size=2,\n    n_components=2,\n    n_topics=6,\n):\n    # å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n    SpectralClustering = import_module('sklearn.cluster').SpectralClustering\n    HDBSCAN = import_module('hdbscan').HDBSCAN\n    UMAP = import_module('umap').UMAP\n    CountVectorizer = import_module('sklearn.feature_extraction.text').CountVectorizer\n    BERTopic = import_module('bertopic').BERTopic\n\n    # NEologdã®è¾æ›¸ãƒ‘ã‚¹ã‚’æŒ‡å®š\n    neologd_path = '/usr/local/lib/mecab/dic/mecab-ipadic-neologd'\n    mecab = MeCab.Tagger(f\"-d {neologd_path} -Ochasen\")\n\n    # å“è©ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’è¡Œã†ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼\n    def tokenizer_mecab(text):\n        node = mecab.parseToNode(text)\n        words = []\n        while node:\n            # åè©ã€å‹•è©ã€å½¢å®¹è©ã ã‘ã‚’æŠ½å‡ºã™ã‚‹\n            if node.feature.startswith('åè©') or node.feature.startswith('å‹•è©') or node.feature.startswith('å½¢å®¹è©'):\n                words.append(node.surface)\n            node = node.next\n        return words\n\n    umap_model = UMAP(\n        random_state=42,\n        n_components=n_components,\n    )\n    hdbscan_model = HDBSCAN(min_cluster_size=min_cluster_size)\n\n    # æ—¥æœ¬èªã®ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆã‚’ä½œæˆï¼ˆå¿…è¦ã«å¿œã˜ã¦æ‹¡å¼µå¯èƒ½ï¼‰\n    japanese_stopwords = [\"ã“ã‚Œ\", \"ãã‚Œ\", \"ã‚ã‚Œ\", \"ã“ã¨\", \"ã‚‚ã®\", \"ãŸã‚\", \"ã‚ˆã†\", \"ã•ã‚“\", \"ã™ã‚‹\", \"ãªã‚‹\", \"ã‚ã‚‹\", \"ã„ã‚‹\"]\n\n    # æ—¥æœ¬èªãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã¨ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ã‚’ä½¿ç”¨ã™ã‚‹\n    vectorizer_model = CountVectorizer(tokenizer=tokenizer_mecab, stop_words=japanese_stopwords)\n\n    topic_model = BERTopic(\n        umap_model=umap_model,\n        hdbscan_model=hdbscan_model,\n        vectorizer_model=vectorizer_model,\n        verbose=True,\n    )\n\n    # ãƒˆãƒ”ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°\n    _, __ = topic_model.fit_transform(docs, embeddings=embeddings)\n\n    n_samples = len(embeddings)\n    n_neighbors = min(n_samples - 1, 10)\n    spectral_model = SpectralClustering(\n        n_clusters=n_topics,\n        affinity=\"nearest_neighbors\",\n        n_neighbors=n_neighbors,\n        random_state=42\n    )\n    umap_embeds = umap_model.fit_transform(embeddings)\n    cluster_labels = spectral_model.fit_predict(umap_embeds)\n\n    result = topic_model.get_document_info(\n        docs=docs,\n        metadata={\n            **metadatas,\n            \"x\": umap_embeds[:, 0],\n            \"y\": umap_embeds[:, 1],\n        },\n    )\n\n    result.columns = [c.lower() for c in result.columns]\n    result = result[['arg-id', 'x', 'y', 'probability']]\n    result['cluster-id'] = cluster_labels\n\n    return result"}},{"step":"labelling","completed":"2025-01-24T18:36:54.548469","duration":5.426989,"params":{"sample_size":30,"source_code":"\"\"\"Create labels for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain_openai import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef labelling(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/labels.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['labelling']['sample_size']\n    prompt = config['labelling']['prompt']\n    model = config['labelling']['model']\n\n    question = config['question']\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n\n        args_ids_outside = clusters[clusters['cluster-id']\n                                    != cluster_id]['arg-id'].values\n        args_ids_outside = np.random.choice(args_ids_outside, size=min(\n            len(args_ids_outside), sample_size), replace=False)\n        args_sample_outside = arguments[arguments['arg-id']\n                                        .isin(args_ids_outside)]['argument'].values\n\n        label = generate_label(question, args_sample,\n                               args_sample_outside, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'label': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_label(question, args_sample, args_sample_outside, prompt, model):\n    llm = ChatOpenAI(model=model, temperature=0.0)\n    outside = '\\n * ' + '\\n * '.join(args_sample_outside)\n    inside = '\\n * ' + '\\n * '.join(args_sample)\n    input = f\"Question of the consultation:{question}\\n\\n\" + \\\n        f\"Examples of arguments OUTSIDE the cluster:\\n {outside}\" + \\\n        f\"Examples of arguments INSIDE the cluster:\\n {inside}\"\n    response = llm.invoke(input=messages(prompt, input)).content.strip()\n\n    return response","prompt":"/system \n\nã‚ãªãŸã¯ã€Creative MTGã«é–¢ã™ã‚‹ä¸€é€£ã®ã‚³ãƒ¡ãƒ³ãƒˆã«å¯¾ã™ã‚‹ã‚«ãƒ†ã‚´ãƒªãƒ©ãƒ™ãƒ«ã‚’ç”Ÿæˆã™ã‚‹ã‚«ãƒ†ã‚´ãƒªãƒ©ãƒ™ãƒªãƒ³ã‚°ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚\nCreative MTGã§ã¯ã€ã€ŒAkeruEã€ã€ã€Œãƒã‚¯ã‚»ãƒ«Ã—SHIOMERã€ã¨ã„ã†2ã¤ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãŒã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’é€²ã‚ã‚‹ä¸Šã§ä½¿ã£ãŸã€ŒæŠ€ã€ã«ã¤ã„ã¦ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¡Œã„ã¾ã—ãŸã€‚\nã‚ãªãŸã«ã¯ã€ç›¸è«‡ã®ä¸»ãªè³ªå•ã€ã‚¯ãƒ©ã‚¹ã‚¿å†…ã®è­°è«–ã®ãƒªã‚¹ãƒˆã€ãŠã‚ˆã³ã“ã®ã‚¯ãƒ©ã‚¹ã‚¿å¤–ã®è­°è«–ã®ãƒªã‚¹ãƒˆãŒä¸ãˆã‚‰ã‚Œã¾ã™ã€‚ã‚ãªãŸã¯ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã‚’è¦ç´„ã™ã‚‹1ã¤ã®ã‚«ãƒ†ã‚´ãƒªãƒ¼ãƒ©ãƒ™ãƒ«ã§å›ç­”ã—ã¾ã™ã€‚\n\nè³ªå•ã‹ã‚‰ã™ã§ã«æ˜ã‚‰ã‹ãªæ–‡è„ˆã¯å«ã‚ãªã„ï¼ˆã€ŒCreative MTGã®å‚åŠ è€…ã®åå¿œã«ã¯ã©ã†ã„ã†å‚¾å‘ãŒã‚ã£ãŸã®ã‹ã€ã®ã‚ˆã†ãªã‚‚ã®ã§ã‚ã‚Œã°ã€ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®ãƒ©ãƒ™ãƒ«ã«ã€ŒCreative MTGã®å‚åŠ è€…ã®åå¿œã€ã¨ç¹°ã‚Šè¿”ã™å¿…è¦ã¯ãªã„ï¼‰ã€‚\n\nãƒ©ãƒ™ãƒ«ã¯éå¸¸ã«ç°¡æ½”ã§ãªã‘ã‚Œã°ãªã‚‰ãšã€ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã¨ãã®å¤–å´ã«ã‚ã‚‹è«–ç‚¹ã‚’åŒºåˆ¥ã™ã‚‹ã®ã«ååˆ†ãªæ­£ç¢ºã•ã§ãªã‘ã‚Œã°ãªã‚‰ãªã„ã€‚\nãƒ©ãƒ™ãƒ«ã¯å…¨ã¦é‡è¤‡ã—ã¦ã¯ãªã‚‰ãªã„ã€‚\nã€Œå‚åŠ è€…ã®åå¿œã®å‚¾å‘ã€ã€Œå‚åŠ è€…ã®å…·ä½“çš„ãªåå¿œã€ã®ã‚ˆã†ãªã‚‚ã®ã¯ã‚„ã‚ã¦ãã ã•ã„ã€‚\nå…·ä½“çš„ã«ã©ã‚“ãªè©±ã«æ³¨ç›®ãŒé›†ã¾ã£ãŸã‹ã‚’çŸ¥ã‚ŠãŸã„ã§ã™ã€‚\nã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼å¤–ã®è«–ç‚¹ã¨æ˜ç¢ºã«åŒºåˆ¥ã•ã‚Œã‚‹ã‚ˆã†ãªãƒ©ãƒ™ãƒ«ã‚’å›ç­”ã—ã¦ãã ã•ã„ã€‚\n\n/human\n\nã‚³ãƒ³ã‚µãƒ«ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®è³ªå• ã€Œè‹±å›½ã®EUé›¢è„±æ±ºå®šã®å½±éŸ¿ã¯ä½•ã ã¨æ€ã„ã¾ã™ã‹ï¼Ÿ\n\né–¢å¿ƒã®ã‚ã‚‹ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ä»¥å¤–ã®è«–ç‚¹ã®ä¾‹\n\n * ã‚¨ãƒ©ã‚¹ãƒ ã‚¹ãƒ»ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‹ã‚‰ã®é™¤å¤–ã«ã‚ˆã‚Šã€æ•™è‚²ãƒ»æ–‡åŒ–äº¤æµã®æ©Ÿä¼šãŒåˆ¶é™ã•ã‚ŒãŸã€‚\n * è‹±å›½ã¯ã€å›½å¢ƒæ¤œå•ã®å¼·åŒ–ã«ã‚ˆã‚‹æ—…è¡Œæ™‚é–“ã®å»¶é•·ã«å¯¾å‡¦ã—ã€é€šå‹¤å®¢ã‚„æ—…è¡Œå®¢ã«å½±éŸ¿ã‚’ä¸ãˆãŸã€‚\n * ç’°å¢ƒåŸºæº–ã«ãŠã‘ã‚‹å”åŠ›ãŒæ¸›å°‘ã—ã€æ°—å€™å¤‰å‹•ã¨é—˜ã†åŠªåŠ›ãŒå¦¨ã’ã‚‰ã‚ŒãŸã€‚\n * ç›¸äº’åŒ»ç™‚å”å®šã®ä¸­æ–­ã«ã‚ˆã‚Šã€æ‚£è€…ã‚±ã‚¢ã«èª²é¡Œã‚’æ„Ÿã˜ãŸã€‚\n * Brexité–¢é€£ã®å¤‰æ›´ã«ã‚ˆã‚Šã€å®¶æ—ã®å±…ä½æ¨©ã‚„å¸‚æ°‘æ¨©ã®ç”³è«‹ãŒè¤‡é›‘ã«ãªã£ãŸã€‚\n * è‹±å›½ã¯ã€å…±åŒç ”ç©¶æ©Ÿä¼šã®æ¸›å°‘ã«ã‚ˆã‚Šã€ç ”ç©¶ã®èª²é¡Œã«å–ã‚Šçµ„ã‚€ä¸–ç•Œçš„ãªå–ã‚Šçµ„ã¿ã«æ”¯éšœã‚’ããŸã™ã“ã¨ã‚’ç›®ã®å½“ãŸã‚Šã«ã—ãŸã€‚\n * EUã®æ–‡åŒ–åŠ©æˆãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‹ã‚‰ã®é™¤å¤–ã«ã‚ˆã‚Šã€å‰µé€ çš„ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®åˆ¶é™ã«ç›´é¢ã—ãŸã€‚\n * è‹±å›½ã¯ã€EUã®è³‡é‡‘æä¾›ã®å–ªå¤±ã«ã‚ˆã‚Šã€æ…ˆå–„æ´»å‹•ã‚„ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æ”¯æ´ã®å¾Œé€€ã‚’ç›®ã®å½“ãŸã‚Šã«ã—ãŸã€‚\n * æ¶ˆè²»è€…ä¿è­·ã®å¼±ä½“åŒ–ã«ã‚ˆã‚Šã€å›½å¢ƒã‚’è¶ŠãˆãŸç´›äº‰è§£æ±ºã«èª²é¡ŒãŒç”Ÿã˜ãŸã€‚\n * è‹±å›½ã¯ãƒ—ãƒ­ã®éŸ³æ¥½å®¶ã¨ã—ã¦EUè«¸å›½ã‚’ãƒ„ã‚¢ãƒ¼ã™ã‚‹éš›ã®åˆ¶é™ã«ç›´é¢ã—ã€ã‚­ãƒ£ãƒªã‚¢ã«å½±éŸ¿ã‚’ä¸ãˆãŸã€‚\n\nã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼å†…éƒ¨ã§ã®è­°è«–ã®ä¾‹\n\n * Brexitã«ã‚ˆã‚Šã‚µãƒ—ãƒ©ã‚¤ãƒã‚§ãƒ¼ãƒ³ãŒæ··ä¹±ã—ã€ä¼æ¥­ã«ã¨ã£ã¦ã‚³ã‚¹ãƒˆå¢—ã¨ç´æœŸé…å»¶ã«ã¤ãªãŒã£ãŸã€‚\n * ãƒ–ãƒ¬ã‚°ã‚¸ãƒƒãƒˆã®ãŸã‚ã€å¸‚å ´ã®å¤‰å‹•ã‚„æŠ•è³‡ãƒ»é€€è·é‡‘ã®ä¸ç¢ºå®Ÿæ€§ã«ç›´é¢ã—ãŸã€‚\n * æ–°ãŸãªé–¢ç¨ã‚„é€šé–¢æ‰‹ç¶šãã«ã‚ˆã‚Šã€è‹±å›½ã¯è¼¸å‡ºæ¥­è€…ã¨ã—ã¦åˆ©ç›Šç‡ã®ä½ä¸‹ã«å¯¾å‡¦ã—ãŸã€‚\n * ãƒ–ãƒ¬ã‚°ã‚¸ãƒƒãƒˆå¾Œã€ä¼æ¥­ãŒEUå¸‚å ´å†…ã«ã¨ã©ã¾ã‚‹ãŸã‚ã«äº‹æ¥­ã‚’ç§»è»¢ã—ãŸãŸã‚ã€é›‡ç”¨ã‚’å¤±ã£ãŸã€‚\n * è‹±å›½ã¯è¼¸å…¥å“ä¾¡æ ¼ã®é«˜é¨°ã«ã‚ˆã‚‹ç”Ÿæ´»è²»ã®å¢—åŠ ã«è‹¦ã—ã‚“ã ã€‚\n * è‹±å›½ã®ãƒã‚¤ãƒ†ã‚¯ç”£æ¥­ã¸ã®æŠ•è³‡ãŒæ¸›å°‘ã—ã€æŠ€è¡“é©æ–°ã¨é›‡ç”¨æ©Ÿä¼šã«å½±éŸ¿ã‚’ä¸ãˆãŸã€‚\n * æ–°ãŸãªãƒ“ã‚¶è¦åˆ¶ã«ã‚ˆã‚‹è¦³å…‰å®¢ã®æ¸›å°‘ã‚’ç›®ã®å½“ãŸã‚Šã«ã—ã€æ¥å®¢æ¥­ã«å½±éŸ¿ã€‚\n * ãƒãƒ³ãƒ‰ä¾¡å€¤ã®ä¸‹è½ã«ã‚ˆã‚Šè³¼è²·åŠ›ãŒä½ä¸‹ã—ã€æ—…è²»ãŒå¢—åŠ ã—ãŸã€‚\n\n\n/ai \n\nè²¡å‹™ä¸Šã®ãƒã‚¤ãƒŠã‚¹å½±éŸ¿","model":"gpt-4o-mini"}},{"step":"takeaways","completed":"2025-01-24T18:37:15.085204","duration":20.534217,"params":{"sample_size":30,"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain_community.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef takeaways(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/takeaways.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['takeaways']['sample_size']\n    prompt = config['takeaways']['prompt']\n    model = config['takeaways']['model']\n\n    model = config.get('model_takeaways', config.get('model', 'gpt3.5-turbo'))\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n        label = generate_takeaways(args_sample, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'takeaways': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_takeaways(args_sample, prompt, model):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    input = \"\\n\".join(args_sample)\n    response = llm.invoke(input=messages(prompt, input)).content.strip()\n    return response","prompt":"/system \n\nã‚ãªãŸã¯ã‚·ãƒ³ã‚¯ã‚¿ãƒ³ã‚¯ã§åƒããƒªã‚µãƒ¼ãƒã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚Creative MTGã«å‚åŠ ã—ãŸäººã®ã‚³ãƒ¡ãƒ³ãƒˆã®ãƒªã‚¹ãƒˆãŒæ¸¡ã•ã‚Œã¾ã™ã€‚\nCreative MTGã§ã¯ã€ã€ŒAkeruEã€ã€ã€Œãƒã‚¯ã‚»ãƒ«Ã—SHIOMERã€ã¨ã„ã†2ã¤ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãŒã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’é€²ã‚ã‚‹ä¸Šã§ä½¿ã£ãŸã€ŒæŠ€ã€ã«ã¤ã„ã¦ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¡Œã„ã¾ã—ãŸã€‚\nã‚ãªãŸã¯ã€ã©ã‚“ãªè©±ã«æ³¨ç›®ãŒé›†ã¾ã£ãŸã‹ã€ä¸»ãªè¦ç‚¹ã‚’1~2æ®µè½ã«ã¾ã¨ã‚ã¦å›ç­”ã—ã¾ã™ã€‚ã‚ãªãŸã¯ç°¡æ½”ã§èª­ã¿ã‚„ã™ã„çŸ­ã„æ–‡ç« ã‚’æ›¸ãã“ã¨ãŒã§ãã¾ã™ã€‚ \n \n/human\n\n[\n  \"éŠƒã«ã‚ˆã‚‹æš´åŠ›ã¯ã€ç§ãŸã¡ã®ç¤¾ä¼šã«ãŠã‘ã‚‹æ·±åˆ»ãªå…¬è¡†è¡›ç”Ÿã®å±æ©Ÿã‚’æ§‹æˆã—ã¦ã„ã‚‹ã¨å›ºãä¿¡ã˜ã¦ã„ã¾ã™ã€‚\",\n  \"åŒ…æ‹¬çš„ãªéŠƒè¦åˆ¶ç­–ã‚’é€šã˜ã¦ã€ã“ã®å•é¡Œã«æ—©æ€¥ã«å–ã‚Šçµ„ã‚€å¿…è¦ãŒã‚ã‚‹ã€‚\",\n  \"ã™ã¹ã¦ã®éŠƒè³¼å…¥è€…ã«å¯¾ã™ã‚‹èº«å…ƒèª¿æŸ»ã®å®Ÿæ–½ã‚’æ”¯æŒã—ã¾ã™ã€‚\",\n  \"ã‚¢ã‚µãƒ«ãƒˆãƒ»ã‚¦ã‚§ãƒãƒ³ã¨å¤§å®¹é‡å¼¾å€‰ã®ç¦æ­¢ã«è³›æˆã—ã¾ã™ã€‚\",\n  \"é•æ³•ãªéŠƒã®å£²è²·ã‚’é˜²ããŸã‚ã€ã‚ˆã‚Šå³ã—ã„è¦åˆ¶ã‚’æå”±ã—ã¾ã™ã€‚\",\n  \"éŠƒã®è³¼å…¥ãƒ—ãƒ­ã‚»ã‚¹ã«ãŠã„ã¦ã€ç²¾ç¥é‘‘å®šã‚’ç¾©å‹™ä»˜ã‘ã‚‹ã¹ãã§ã‚ã‚‹ã€‚\"\n]\n\n/ai \n\nå‚åŠ è€…ã¯ã€åŒ…æ‹¬çš„ãªéŠƒè¦åˆ¶ã‚’æ±‚ã‚ã€æ™®éçš„ãªèº«å…ƒèª¿æŸ»ã€çªæ’ƒå…µå™¨ã®ç¦æ­¢ã€é•æ³•ãªéŠƒå£²è²·ã®æŠ‘åˆ¶ã€ç²¾ç¥è¡›ç”Ÿè©•ä¾¡ã®å„ªå…ˆãªã©ã‚’å¼·èª¿ã—ãŸã€‚","model":"gpt-4o-mini"}},{"step":"overview","completed":"2025-01-24T18:37:19.235863","duration":4.147972,"params":{"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain_community.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef overview(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/overview.txt\"\n\n    takeaways = pd.read_csv(f\"outputs/{dataset}/takeaways.csv\")\n    labels = pd.read_csv(f\"outputs/{dataset}/labels.csv\")\n\n    prompt = config['overview']['prompt']\n    model = config['overview']['model']\n\n    ids = labels['cluster-id'].to_list()\n    takeaways.set_index('cluster-id', inplace=True)\n    labels.set_index('cluster-id', inplace=True)\n\n    input = ''\n    for i, id in enumerate(ids):\n        input += f\"# Cluster {i}/{len(ids)}: {labels.loc[id]['label']}\\n\\n\"\n        input += takeaways.loc[id]['takeaways'] + '\\n\\n'\n\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    response = llm(messages=messages(prompt, input)).content.strip()\n\n    with open(path, 'w') as file:\n        file.write(response)","prompt":"/system \nã‚ãªãŸã¯ã‚·ãƒ³ã‚¯ã‚¿ãƒ³ã‚¯ã§åƒãå°‚é–€å®¶ãƒªã‚µãƒ¼ãƒã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ã‚ãªãŸã®ãƒãƒ¼ãƒ ã¯ã€ã‚ã‚‹ãƒˆãƒ”ãƒƒã‚¯ã«é–¢ã™ã‚‹å…¬é–‹ã‚³ãƒ³ã‚µãƒ«ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿæ–½ã—ã€ã•ã¾ã–ã¾ãªé¸æŠè‚¢ã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã‚’åˆ†æã—å§‹ã‚ã¾ã—ãŸã€‚ã‚ãªãŸã¯ä»Šã€ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®ãƒªã‚¹ãƒˆã¨å„ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®ç°¡å˜ãªåˆ†æã‚’å—ã‘å–ã‚Šã¾ã™ã€‚ã‚ãªãŸã®ä»•äº‹ã¯ã€CreativeMTGã§ã©ã‚“ãªè©±ã«æ³¨ç›®ãŒé›†ã¾ã£ãŸã‹ã‚’ç°¡æ½”ã«ã¾ã¨ã‚ã‚‹ã“ã¨ã§ã™ã€‚ã‚ãªãŸã®è¦ç´„ã¯éå¸¸ã«ç°¡æ½”ã§ãªã‘ã‚Œã°ãªã‚‰ãšï¼ˆã›ã„ãœã„1æ®µè½ã€ã›ã„ãœã„4æ–‡ï¼‰ã€å¹³å‡¡ãªè¡¨ç¾ã¯é¿ã‘ãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚\nè£œè¶³ã¨ã—ã¦ã€Creative MTGã§ã¯ã€ã€ŒAkeruEã€ã€ã€Œãƒã‚¯ã‚»ãƒ«Ã—SHIOMERã€ã¨ã„ã†2ã¤ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãŒã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’é€²ã‚ã‚‹ä¸Šã§ä½¿ã£ãŸã€ŒæŠ€ã€ã«ã¤ã„ã¦ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¡Œã„ã¾ã—ãŸã€‚","model":"gpt-4o-mini"}},{"step":"aggregation","completed":"2025-01-24T18:37:19.359094","duration":0.119161,"params":{"source_code":"\"\"\"Generate a convenient JSON output file.\"\"\"\n\nfrom tqdm import tqdm\nfrom typing import List\nimport pandas as pd\nfrom langchain_community.chat_models import ChatOpenAI\nimport json\n\n\ndef aggregation(config):\n\n    path = f\"outputs/{config['output_dir']}/result.json\"\n\n    results = {\n        \"clusters\": [],\n        \"comments\": {},\n        \"overview\": \"\",\n        \"config\": config,\n    }\n\n    arguments = pd.read_csv(f\"outputs/{config['output_dir']}/args.csv\")\n    arguments.set_index('arg-id', inplace=True)\n\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n    useful_comment_ids = set(arguments['comment-id'].values)\n    for _, row in comments.iterrows():\n        id = row['comment-id']\n        if id in useful_comment_ids:\n            res = {'comment': row['comment-body']}\n            numeric_cols = ['agrees', 'disagrees']\n            string_cols = ['video', 'interview', 'timestamp']\n            for col in numeric_cols:\n                if col in row:\n                    res[col] = float(row[col])\n            for col in string_cols:\n                if col in row:\n                    res[col] = row[col]\n            results['comments'][str(id)] = res\n\n    languages = list(config.get('translation', {}).get('languages', []))\n    if len(languages) \u003e 0:\n        with open(f\"outputs/{config['output_dir']}/translations.json\") as f:\n            translations = f.read()\n        results['translations'] = json.loads(translations)\n\n    clusters = pd.read_csv(f\"outputs/{config['output_dir']}/clusters.csv\")\n    labels = pd.read_csv(f\"outputs/{config['output_dir']}/labels.csv\")\n    takeaways = pd.read_csv(f\"outputs/{config['output_dir']}/takeaways.csv\")\n    takeaways.set_index('cluster-id', inplace=True)\n\n    with open(f\"outputs/{config['output_dir']}/overview.txt\") as f:\n        overview = f.read()\n    results['overview'] = overview\n\n    for _, row in labels.iterrows():\n        cid = row['cluster-id']\n        label = row['label']\n        arg_rows = clusters[clusters['cluster-id'] == cid]\n        arguments_in_cluster = []\n        for _, arg_row in arg_rows.iterrows():\n            arg_id = arg_row['arg-id']\n            argument = arguments.loc[arg_id]['argument']\n            comment_id = arguments.loc[arg_id]['comment-id']\n            x = float(arg_row['x'])\n            y = float(arg_row['y'])\n            p = float(arg_row['probability'])\n            obj = {\n                'arg_id': arg_id,\n                'argument': argument,\n                'comment_id': str(comment_id),\n                'x': x,\n                'y': y,\n                'p': p,\n            }\n            arguments_in_cluster.append(obj)\n        results['clusters'].append({\n            'cluster': label,\n            'cluster_id': str(cid),\n            'takeaways': takeaways.loc[cid]['takeaways'],\n            'arguments': arguments_in_cluster\n        })\n\n    with open(path, 'w') as file:\n        json.dump(results, file, indent=2)\n"}},{"step":"visualization","completed":"2025-01-24T18:37:52.952930","duration":33.591244,"params":{"replacements":[],"source_code":"\nimport subprocess\n\n\ndef visualization(config):\n    output_dir = config['output_dir']\n    with open(f\"outputs/{output_dir}/result.json\") as f:\n        result = f.read()\n\n    cwd = \"../next-app\"\n    command = f\"REPORT={output_dir} npm run build\"\n\n    try:\n        process = subprocess.Popen(command, shell=True, cwd=cwd, stdout=subprocess.PIPE,\n                                   stderr=subprocess.PIPE, universal_newlines=True)\n        while True:\n            output_line = process.stdout.readline()\n            if output_line == '' and process.poll() is not None:\n                break\n            if output_line:\n                print(output_line.strip())\n        process.wait()\n        errors = process.stderr.read()\n        if errors:\n            print(\"Errors:\")\n            print(errors)\n    except subprocess.CalledProcessError as e:\n        print(\"Error: \", e)\n"}}],"lock_until":"2025-01-24T18:42:52.958857","current_job":"visualization","current_job_started":"2025-01-24T18:37:19.361761","current_job_progress":null,"current_jop_tasks":null,"previously_completed_jobs":[],"end_time":"2025-01-24T18:37:52.958828"},"embedding":{"source_code":"from langchain_openai import OpenAIEmbeddings\nfrom langchain_community.chat_models import ChatOpenAI\nimport pandas as pd\nfrom tqdm import tqdm\n\n\ndef embedding(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/embeddings.pkl\"\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    embeddings = []\n    for i in tqdm(range(0, len(arguments), 1000)):\n        args = arguments[\"argument\"].tolist()[i: i + 1000]\n        embeddings_model = OpenAIEmbeddings()\n        embeds = embeddings_model.embed_documents(args)\n\n        embeddings.extend(embeds)\n    df = pd.DataFrame(\n        [\n            {\"arg-id\": arguments.iloc[i][\"arg-id\"], \"embedding\": e}\n            for i, e in enumerate(embeddings)\n        ]\n    )\n    df.to_pickle(path)"},"labelling":{"sample_size":30,"source_code":"\"\"\"Create labels for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain_openai import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef labelling(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/labels.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['labelling']['sample_size']\n    prompt = config['labelling']['prompt']\n    model = config['labelling']['model']\n\n    question = config['question']\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n\n        args_ids_outside = clusters[clusters['cluster-id']\n                                    != cluster_id]['arg-id'].values\n        args_ids_outside = np.random.choice(args_ids_outside, size=min(\n            len(args_ids_outside), sample_size), replace=False)\n        args_sample_outside = arguments[arguments['arg-id']\n                                        .isin(args_ids_outside)]['argument'].values\n\n        label = generate_label(question, args_sample,\n                               args_sample_outside, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'label': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_label(question, args_sample, args_sample_outside, prompt, model):\n    llm = ChatOpenAI(model=model, temperature=0.0)\n    outside = '\\n * ' + '\\n * '.join(args_sample_outside)\n    inside = '\\n * ' + '\\n * '.join(args_sample)\n    input = f\"Question of the consultation:{question}\\n\\n\" + \\\n        f\"Examples of arguments OUTSIDE the cluster:\\n {outside}\" + \\\n        f\"Examples of arguments INSIDE the cluster:\\n {inside}\"\n    response = llm.invoke(input=messages(prompt, input)).content.strip()\n\n    return response","prompt":"/system \n\nã‚ãªãŸã¯ã€Creative MTGã«é–¢ã™ã‚‹ä¸€é€£ã®ã‚³ãƒ¡ãƒ³ãƒˆã«å¯¾ã™ã‚‹ã‚«ãƒ†ã‚´ãƒªãƒ©ãƒ™ãƒ«ã‚’ç”Ÿæˆã™ã‚‹ã‚«ãƒ†ã‚´ãƒªãƒ©ãƒ™ãƒªãƒ³ã‚°ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚\nCreative MTGã§ã¯ã€ã€ŒAkeruEã€ã€ã€Œãƒã‚¯ã‚»ãƒ«Ã—SHIOMERã€ã¨ã„ã†2ã¤ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãŒã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’é€²ã‚ã‚‹ä¸Šã§ä½¿ã£ãŸã€ŒæŠ€ã€ã«ã¤ã„ã¦ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¡Œã„ã¾ã—ãŸã€‚\nã‚ãªãŸã«ã¯ã€ç›¸è«‡ã®ä¸»ãªè³ªå•ã€ã‚¯ãƒ©ã‚¹ã‚¿å†…ã®è­°è«–ã®ãƒªã‚¹ãƒˆã€ãŠã‚ˆã³ã“ã®ã‚¯ãƒ©ã‚¹ã‚¿å¤–ã®è­°è«–ã®ãƒªã‚¹ãƒˆãŒä¸ãˆã‚‰ã‚Œã¾ã™ã€‚ã‚ãªãŸã¯ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã‚’è¦ç´„ã™ã‚‹1ã¤ã®ã‚«ãƒ†ã‚´ãƒªãƒ¼ãƒ©ãƒ™ãƒ«ã§å›ç­”ã—ã¾ã™ã€‚\n\nè³ªå•ã‹ã‚‰ã™ã§ã«æ˜ã‚‰ã‹ãªæ–‡è„ˆã¯å«ã‚ãªã„ï¼ˆã€ŒCreative MTGã®å‚åŠ è€…ã®åå¿œã«ã¯ã©ã†ã„ã†å‚¾å‘ãŒã‚ã£ãŸã®ã‹ã€ã®ã‚ˆã†ãªã‚‚ã®ã§ã‚ã‚Œã°ã€ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®ãƒ©ãƒ™ãƒ«ã«ã€ŒCreative MTGã®å‚åŠ è€…ã®åå¿œã€ã¨ç¹°ã‚Šè¿”ã™å¿…è¦ã¯ãªã„ï¼‰ã€‚\n\nãƒ©ãƒ™ãƒ«ã¯éå¸¸ã«ç°¡æ½”ã§ãªã‘ã‚Œã°ãªã‚‰ãšã€ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã¨ãã®å¤–å´ã«ã‚ã‚‹è«–ç‚¹ã‚’åŒºåˆ¥ã™ã‚‹ã®ã«ååˆ†ãªæ­£ç¢ºã•ã§ãªã‘ã‚Œã°ãªã‚‰ãªã„ã€‚\nãƒ©ãƒ™ãƒ«ã¯å…¨ã¦é‡è¤‡ã—ã¦ã¯ãªã‚‰ãªã„ã€‚\nã€Œå‚åŠ è€…ã®åå¿œã®å‚¾å‘ã€ã€Œå‚åŠ è€…ã®å…·ä½“çš„ãªåå¿œã€ã®ã‚ˆã†ãªã‚‚ã®ã¯ã‚„ã‚ã¦ãã ã•ã„ã€‚\nå…·ä½“çš„ã«ã©ã‚“ãªè©±ã«æ³¨ç›®ãŒé›†ã¾ã£ãŸã‹ã‚’çŸ¥ã‚ŠãŸã„ã§ã™ã€‚\nã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼å¤–ã®è«–ç‚¹ã¨æ˜ç¢ºã«åŒºåˆ¥ã•ã‚Œã‚‹ã‚ˆã†ãªãƒ©ãƒ™ãƒ«ã‚’å›ç­”ã—ã¦ãã ã•ã„ã€‚\n\n/human\n\nã‚³ãƒ³ã‚µãƒ«ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®è³ªå• ã€Œè‹±å›½ã®EUé›¢è„±æ±ºå®šã®å½±éŸ¿ã¯ä½•ã ã¨æ€ã„ã¾ã™ã‹ï¼Ÿ\n\né–¢å¿ƒã®ã‚ã‚‹ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ä»¥å¤–ã®è«–ç‚¹ã®ä¾‹\n\n * ã‚¨ãƒ©ã‚¹ãƒ ã‚¹ãƒ»ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‹ã‚‰ã®é™¤å¤–ã«ã‚ˆã‚Šã€æ•™è‚²ãƒ»æ–‡åŒ–äº¤æµã®æ©Ÿä¼šãŒåˆ¶é™ã•ã‚ŒãŸã€‚\n * è‹±å›½ã¯ã€å›½å¢ƒæ¤œå•ã®å¼·åŒ–ã«ã‚ˆã‚‹æ—…è¡Œæ™‚é–“ã®å»¶é•·ã«å¯¾å‡¦ã—ã€é€šå‹¤å®¢ã‚„æ—…è¡Œå®¢ã«å½±éŸ¿ã‚’ä¸ãˆãŸã€‚\n * ç’°å¢ƒåŸºæº–ã«ãŠã‘ã‚‹å”åŠ›ãŒæ¸›å°‘ã—ã€æ°—å€™å¤‰å‹•ã¨é—˜ã†åŠªåŠ›ãŒå¦¨ã’ã‚‰ã‚ŒãŸã€‚\n * ç›¸äº’åŒ»ç™‚å”å®šã®ä¸­æ–­ã«ã‚ˆã‚Šã€æ‚£è€…ã‚±ã‚¢ã«èª²é¡Œã‚’æ„Ÿã˜ãŸã€‚\n * Brexité–¢é€£ã®å¤‰æ›´ã«ã‚ˆã‚Šã€å®¶æ—ã®å±…ä½æ¨©ã‚„å¸‚æ°‘æ¨©ã®ç”³è«‹ãŒè¤‡é›‘ã«ãªã£ãŸã€‚\n * è‹±å›½ã¯ã€å…±åŒç ”ç©¶æ©Ÿä¼šã®æ¸›å°‘ã«ã‚ˆã‚Šã€ç ”ç©¶ã®èª²é¡Œã«å–ã‚Šçµ„ã‚€ä¸–ç•Œçš„ãªå–ã‚Šçµ„ã¿ã«æ”¯éšœã‚’ããŸã™ã“ã¨ã‚’ç›®ã®å½“ãŸã‚Šã«ã—ãŸã€‚\n * EUã®æ–‡åŒ–åŠ©æˆãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‹ã‚‰ã®é™¤å¤–ã«ã‚ˆã‚Šã€å‰µé€ çš„ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®åˆ¶é™ã«ç›´é¢ã—ãŸã€‚\n * è‹±å›½ã¯ã€EUã®è³‡é‡‘æä¾›ã®å–ªå¤±ã«ã‚ˆã‚Šã€æ…ˆå–„æ´»å‹•ã‚„ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æ”¯æ´ã®å¾Œé€€ã‚’ç›®ã®å½“ãŸã‚Šã«ã—ãŸã€‚\n * æ¶ˆè²»è€…ä¿è­·ã®å¼±ä½“åŒ–ã«ã‚ˆã‚Šã€å›½å¢ƒã‚’è¶ŠãˆãŸç´›äº‰è§£æ±ºã«èª²é¡ŒãŒç”Ÿã˜ãŸã€‚\n * è‹±å›½ã¯ãƒ—ãƒ­ã®éŸ³æ¥½å®¶ã¨ã—ã¦EUè«¸å›½ã‚’ãƒ„ã‚¢ãƒ¼ã™ã‚‹éš›ã®åˆ¶é™ã«ç›´é¢ã—ã€ã‚­ãƒ£ãƒªã‚¢ã«å½±éŸ¿ã‚’ä¸ãˆãŸã€‚\n\nã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼å†…éƒ¨ã§ã®è­°è«–ã®ä¾‹\n\n * Brexitã«ã‚ˆã‚Šã‚µãƒ—ãƒ©ã‚¤ãƒã‚§ãƒ¼ãƒ³ãŒæ··ä¹±ã—ã€ä¼æ¥­ã«ã¨ã£ã¦ã‚³ã‚¹ãƒˆå¢—ã¨ç´æœŸé…å»¶ã«ã¤ãªãŒã£ãŸã€‚\n * ãƒ–ãƒ¬ã‚°ã‚¸ãƒƒãƒˆã®ãŸã‚ã€å¸‚å ´ã®å¤‰å‹•ã‚„æŠ•è³‡ãƒ»é€€è·é‡‘ã®ä¸ç¢ºå®Ÿæ€§ã«ç›´é¢ã—ãŸã€‚\n * æ–°ãŸãªé–¢ç¨ã‚„é€šé–¢æ‰‹ç¶šãã«ã‚ˆã‚Šã€è‹±å›½ã¯è¼¸å‡ºæ¥­è€…ã¨ã—ã¦åˆ©ç›Šç‡ã®ä½ä¸‹ã«å¯¾å‡¦ã—ãŸã€‚\n * ãƒ–ãƒ¬ã‚°ã‚¸ãƒƒãƒˆå¾Œã€ä¼æ¥­ãŒEUå¸‚å ´å†…ã«ã¨ã©ã¾ã‚‹ãŸã‚ã«äº‹æ¥­ã‚’ç§»è»¢ã—ãŸãŸã‚ã€é›‡ç”¨ã‚’å¤±ã£ãŸã€‚\n * è‹±å›½ã¯è¼¸å…¥å“ä¾¡æ ¼ã®é«˜é¨°ã«ã‚ˆã‚‹ç”Ÿæ´»è²»ã®å¢—åŠ ã«è‹¦ã—ã‚“ã ã€‚\n * è‹±å›½ã®ãƒã‚¤ãƒ†ã‚¯ç”£æ¥­ã¸ã®æŠ•è³‡ãŒæ¸›å°‘ã—ã€æŠ€è¡“é©æ–°ã¨é›‡ç”¨æ©Ÿä¼šã«å½±éŸ¿ã‚’ä¸ãˆãŸã€‚\n * æ–°ãŸãªãƒ“ã‚¶è¦åˆ¶ã«ã‚ˆã‚‹è¦³å…‰å®¢ã®æ¸›å°‘ã‚’ç›®ã®å½“ãŸã‚Šã«ã—ã€æ¥å®¢æ¥­ã«å½±éŸ¿ã€‚\n * ãƒãƒ³ãƒ‰ä¾¡å€¤ã®ä¸‹è½ã«ã‚ˆã‚Šè³¼è²·åŠ›ãŒä½ä¸‹ã—ã€æ—…è²»ãŒå¢—åŠ ã—ãŸã€‚\n\n\n/ai \n\nè²¡å‹™ä¸Šã®ãƒã‚¤ãƒŠã‚¹å½±éŸ¿","model":"gpt-4o-mini"},"takeaways":{"sample_size":30,"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain_openai import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef takeaways(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/takeaways.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['takeaways']['sample_size']\n    prompt = config['takeaways']['prompt']\n    model = config['takeaways']['model']\n\n    model = config.get('model_takeaways', config.get('model', 'gpt3.5-turbo'))\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n        label = generate_takeaways(args_sample, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'takeaways': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_takeaways(args_sample, prompt, model):\n    llm = ChatOpenAI(model=model, temperature=0.0)\n    input = \"\\n\".join(args_sample)\n    response = llm.invoke(input=messages(prompt, input)).content.strip()\n    return response","prompt":"/system \n\nã‚ãªãŸã¯ã‚·ãƒ³ã‚¯ã‚¿ãƒ³ã‚¯ã§åƒããƒªã‚µãƒ¼ãƒã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚Creative MTGã«å‚åŠ ã—ãŸäººã®ã‚³ãƒ¡ãƒ³ãƒˆã®ãƒªã‚¹ãƒˆãŒæ¸¡ã•ã‚Œã¾ã™ã€‚\nCreative MTGã§ã¯ã€ã€ŒAkeruEã€ã€ã€Œãƒã‚¯ã‚»ãƒ«Ã—SHIOMERã€ã¨ã„ã†2ã¤ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãŒã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’é€²ã‚ã‚‹ä¸Šã§ä½¿ã£ãŸã€ŒæŠ€ã€ã«ã¤ã„ã¦ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¡Œã„ã¾ã—ãŸã€‚\nã‚ãªãŸã¯ã€ã©ã‚“ãªè©±ã«æ³¨ç›®ãŒé›†ã¾ã£ãŸã‹ã€ä¸»ãªè¦ç‚¹ã‚’1~2æ®µè½ã«ã¾ã¨ã‚ã¦å›ç­”ã—ã¾ã™ã€‚ã‚ãªãŸã¯ç°¡æ½”ã§èª­ã¿ã‚„ã™ã„çŸ­ã„æ–‡ç« ã‚’æ›¸ãã“ã¨ãŒã§ãã¾ã™ã€‚ \n \n/human\n\n[\n  \"éŠƒã«ã‚ˆã‚‹æš´åŠ›ã¯ã€ç§ãŸã¡ã®ç¤¾ä¼šã«ãŠã‘ã‚‹æ·±åˆ»ãªå…¬è¡†è¡›ç”Ÿã®å±æ©Ÿã‚’æ§‹æˆã—ã¦ã„ã‚‹ã¨å›ºãä¿¡ã˜ã¦ã„ã¾ã™ã€‚\",\n  \"åŒ…æ‹¬çš„ãªéŠƒè¦åˆ¶ç­–ã‚’é€šã˜ã¦ã€ã“ã®å•é¡Œã«æ—©æ€¥ã«å–ã‚Šçµ„ã‚€å¿…è¦ãŒã‚ã‚‹ã€‚\",\n  \"ã™ã¹ã¦ã®éŠƒè³¼å…¥è€…ã«å¯¾ã™ã‚‹èº«å…ƒèª¿æŸ»ã®å®Ÿæ–½ã‚’æ”¯æŒã—ã¾ã™ã€‚\",\n  \"ã‚¢ã‚µãƒ«ãƒˆãƒ»ã‚¦ã‚§ãƒãƒ³ã¨å¤§å®¹é‡å¼¾å€‰ã®ç¦æ­¢ã«è³›æˆã—ã¾ã™ã€‚\",\n  \"é•æ³•ãªéŠƒã®å£²è²·ã‚’é˜²ããŸã‚ã€ã‚ˆã‚Šå³ã—ã„è¦åˆ¶ã‚’æå”±ã—ã¾ã™ã€‚\",\n  \"éŠƒã®è³¼å…¥ãƒ—ãƒ­ã‚»ã‚¹ã«ãŠã„ã¦ã€ç²¾ç¥é‘‘å®šã‚’ç¾©å‹™ä»˜ã‘ã‚‹ã¹ãã§ã‚ã‚‹ã€‚\"\n]\n\n/ai \n\nå‚åŠ è€…ã¯ã€åŒ…æ‹¬çš„ãªéŠƒè¦åˆ¶ã‚’æ±‚ã‚ã€æ™®éçš„ãªèº«å…ƒèª¿æŸ»ã€çªæ’ƒå…µå™¨ã®ç¦æ­¢ã€é•æ³•ãªéŠƒå£²è²·ã®æŠ‘åˆ¶ã€ç²¾ç¥è¡›ç”Ÿè©•ä¾¡ã®å„ªå…ˆãªã©ã‚’å¼·èª¿ã—ãŸã€‚","model":"gpt-4o-mini"},"overview":{"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain_community.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef overview(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/overview.txt\"\n\n    takeaways = pd.read_csv(f\"outputs/{dataset}/takeaways.csv\")\n    labels = pd.read_csv(f\"outputs/{dataset}/labels.csv\")\n\n    prompt = config['overview']['prompt']\n    model = config['overview']['model']\n\n    ids = labels['cluster-id'].to_list()\n    takeaways.set_index('cluster-id', inplace=True)\n    labels.set_index('cluster-id', inplace=True)\n\n    input = ''\n    for i, id in enumerate(ids):\n        input += f\"# Cluster {i}/{len(ids)}: {labels.loc[id]['label']}\\n\\n\"\n        input += takeaways.loc[id]['takeaways'] + '\\n\\n'\n\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    messages_list = messages(prompt, input)  # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãƒªã‚¹ãƒˆã«å¤‰æ›\n    response = llm.invoke(messages_list).content.strip()  # invoke() ã‚’ä½¿ç”¨\n\n\n    with open(path, 'w') as file:\n        file.write(response)","prompt":"/system \nã‚ãªãŸã¯ã‚·ãƒ³ã‚¯ã‚¿ãƒ³ã‚¯ã§åƒãå°‚é–€å®¶ãƒªã‚µãƒ¼ãƒã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ã‚ãªãŸã®ãƒãƒ¼ãƒ ã¯ã€ã‚ã‚‹ãƒˆãƒ”ãƒƒã‚¯ã«é–¢ã™ã‚‹å…¬é–‹ã‚³ãƒ³ã‚µãƒ«ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿæ–½ã—ã€ã•ã¾ã–ã¾ãªé¸æŠè‚¢ã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã‚’åˆ†æã—å§‹ã‚ã¾ã—ãŸã€‚ã‚ãªãŸã¯ä»Šã€ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®ãƒªã‚¹ãƒˆã¨å„ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®ç°¡å˜ãªåˆ†æã‚’å—ã‘å–ã‚Šã¾ã™ã€‚ã‚ãªãŸã®ä»•äº‹ã¯ã€CreativeMTGã§ã©ã‚“ãªè©±ã«æ³¨ç›®ãŒé›†ã¾ã£ãŸã‹ã‚’ç°¡æ½”ã«ã¾ã¨ã‚ã‚‹ã“ã¨ã§ã™ã€‚ã‚ãªãŸã®è¦ç´„ã¯éå¸¸ã«ç°¡æ½”ã§ãªã‘ã‚Œã°ãªã‚‰ãšï¼ˆã›ã„ãœã„1æ®µè½ã€ã›ã„ãœã„4æ–‡ï¼‰ã€å¹³å‡¡ãªè¡¨ç¾ã¯é¿ã‘ãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚\nè£œè¶³ã¨ã—ã¦ã€Creative MTGã§ã¯ã€ã€ŒAkeruEã€ã€ã€Œãƒã‚¯ã‚»ãƒ«Ã—SHIOMERã€ã¨ã„ã†2ã¤ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãŒã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’é€²ã‚ã‚‹ä¸Šã§ä½¿ã£ãŸã€ŒæŠ€ã€ã«ã¤ã„ã¦ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¡Œã„ã¾ã—ãŸã€‚","model":"gpt-4o-mini"},"aggregation":{"source_code":"\"\"\"Generate a convenient JSON output file.\"\"\"\n\nfrom tqdm import tqdm\nfrom typing import List\nimport pandas as pd\nfrom langchain_community.chat_models import ChatOpenAI\nimport json\n\n\ndef aggregation(config):\n\n    path = f\"outputs/{config['output_dir']}/result.json\"\n\n    results = {\n        \"clusters\": [],\n        \"comments\": {},\n        \"overview\": \"\",\n        \"config\": config,\n    }\n\n    arguments = pd.read_csv(f\"outputs/{config['output_dir']}/args.csv\")\n    arguments.set_index('arg-id', inplace=True)\n\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n    useful_comment_ids = set(arguments['comment-id'].values)\n    for _, row in comments.iterrows():\n        id = row['comment-id']\n        if id in useful_comment_ids:\n            res = {'comment': row['comment-body']}\n            numeric_cols = ['agrees', 'disagrees']\n            string_cols = ['video', 'interview', 'timestamp']\n            for col in numeric_cols:\n                if col in row:\n                    res[col] = float(row[col])\n            for col in string_cols:\n                if col in row:\n                    res[col] = row[col]\n            results['comments'][str(id)] = res\n\n    languages = list(config.get('translation', {}).get('languages', []))\n    if len(languages) \u003e 0:\n        with open(f\"outputs/{config['output_dir']}/translations.json\") as f:\n            translations = f.read()\n        results['translations'] = json.loads(translations)\n\n    clusters = pd.read_csv(f\"outputs/{config['output_dir']}/clusters.csv\")\n    labels = pd.read_csv(f\"outputs/{config['output_dir']}/labels.csv\")\n    takeaways = pd.read_csv(f\"outputs/{config['output_dir']}/takeaways.csv\")\n    takeaways.set_index('cluster-id', inplace=True)\n\n    with open(f\"outputs/{config['output_dir']}/overview.txt\") as f:\n        overview = f.read()\n    results['overview'] = overview\n\n    for _, row in labels.iterrows():\n        cid = row['cluster-id']\n        label = row['label']\n        arg_rows = clusters[clusters['cluster-id'] == cid]\n        arguments_in_cluster = []\n        for _, arg_row in arg_rows.iterrows():\n            arg_id = arg_row['arg-id']\n            argument = arguments.loc[arg_id]['argument']\n            comment_id = arguments.loc[arg_id]['comment-id']\n            x = float(arg_row['x'])\n            y = float(arg_row['y'])\n            p = float(arg_row['probability'])\n            obj = {\n                'arg_id': arg_id,\n                'argument': argument,\n                'comment_id': str(comment_id),\n                'x': x,\n                'y': y,\n                'p': p,\n            }\n            arguments_in_cluster.append(obj)\n        results['clusters'].append({\n            'cluster': label,\n            'cluster_id': str(cid),\n            'takeaways': takeaways.loc[cid]['takeaways'],\n            'arguments': arguments_in_cluster\n        })\n\n    with open(path, 'w') as file:\n        json.dump(results, file, indent=2)\n"},"visualization":{"replacements":[],"source_code":"\nimport subprocess\n\n\ndef visualization(config):\n    output_dir = config['output_dir']\n    with open(f\"outputs/{output_dir}/result.json\") as f:\n        result = f.read()\n\n    cwd = \"../next-app\"\n    command = f\"REPORT={output_dir} npm run build\"\n\n    try:\n        process = subprocess.Popen(command, shell=True, cwd=cwd, stdout=subprocess.PIPE,\n                                   stderr=subprocess.PIPE, universal_newlines=True)\n        while True:\n            output_line = process.stdout.readline()\n            if output_line == '' and process.poll() is not None:\n                break\n            if output_line:\n                print(output_line.strip())\n        process.wait()\n        errors = process.stderr.read()\n        if errors:\n            print(\"Errors:\")\n            print(errors)\n    except subprocess.CalledProcessError as e:\n        print(\"Error: \", e)\n"},"plan":[{"step":"extraction","run":false,"reason":"nothing changed"},{"step":"embedding","run":false,"reason":"nothing changed"},{"step":"clustering","run":true,"reason":"some parameters changed: clusters"},{"step":"labelling","run":true,"reason":"some dependent steps will re-run: clustering"},{"step":"takeaways","run":true,"reason":"some dependent steps will re-run: clustering"},{"step":"overview","run":true,"reason":"some dependent steps will re-run: labelling, takeaways"},{"step":"aggregation","run":true,"reason":"some dependent steps will re-run: clustering, labelling, takeaways, overview"},{"step":"visualization","run":true,"reason":"some dependent steps will re-run: aggregation"}],"status":"running","start_time":"2025-01-24T18:41:48.189985","completed_jobs":[{"step":"clustering","completed":"2025-01-24T18:42:18.195419","duration":30.001477,"params":{"clusters":6,"source_code":"import pandas as pd\nimport numpy as np\nfrom importlib import import_module\nimport MeCab\n\ndef clustering(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/clusters.csv\"\n    arguments_df = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    arguments_array = arguments_df[\"argument\"].values\n\n    embeddings_df = pd.read_pickle(f\"outputs/{dataset}/embeddings.pkl\")\n    embeddings_array = np.asarray(embeddings_df[\"embedding\"].values.tolist())\n    clusters = config['clustering']['clusters']\n\n    result = cluster_embeddings(\n        docs=arguments_array,\n        embeddings=embeddings_array,\n        metadatas={\n            \"arg-id\": arguments_df[\"arg-id\"].values,\n            \"comment-id\": arguments_df[\"comment-id\"].values,\n        },\n        n_topics=clusters,\n    )\n    result.to_csv(path, index=False)\n\n\ndef cluster_embeddings(\n    docs,\n    embeddings,\n    metadatas,\n    min_cluster_size=2,\n    n_components=2,\n    n_topics=6,\n):\n    # å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n    SpectralClustering = import_module('sklearn.cluster').SpectralClustering\n    HDBSCAN = import_module('hdbscan').HDBSCAN\n    UMAP = import_module('umap').UMAP\n    CountVectorizer = import_module('sklearn.feature_extraction.text').CountVectorizer\n    BERTopic = import_module('bertopic').BERTopic\n\n    # NEologdã®è¾æ›¸ãƒ‘ã‚¹ã‚’æŒ‡å®š\n    neologd_path = '/usr/local/lib/mecab/dic/mecab-ipadic-neologd'\n    mecab = MeCab.Tagger(f\"-d {neologd_path} -Ochasen\")\n\n    # å“è©ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’è¡Œã†ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼\n    def tokenizer_mecab(text):\n        node = mecab.parseToNode(text)\n        words = []\n        while node:\n            # åè©ã€å‹•è©ã€å½¢å®¹è©ã ã‘ã‚’æŠ½å‡ºã™ã‚‹\n            if node.feature.startswith('åè©') or node.feature.startswith('å‹•è©') or node.feature.startswith('å½¢å®¹è©'):\n                words.append(node.surface)\n            node = node.next\n        return words\n\n    umap_model = UMAP(\n        random_state=42,\n        n_components=n_components,\n    )\n    hdbscan_model = HDBSCAN(min_cluster_size=min_cluster_size)\n\n    # æ—¥æœ¬èªã®ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆã‚’ä½œæˆï¼ˆå¿…è¦ã«å¿œã˜ã¦æ‹¡å¼µå¯èƒ½ï¼‰\n    japanese_stopwords = [\"ã“ã‚Œ\", \"ãã‚Œ\", \"ã‚ã‚Œ\", \"ã“ã¨\", \"ã‚‚ã®\", \"ãŸã‚\", \"ã‚ˆã†\", \"ã•ã‚“\", \"ã™ã‚‹\", \"ãªã‚‹\", \"ã‚ã‚‹\", \"ã„ã‚‹\"]\n\n    # æ—¥æœ¬èªãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã¨ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ã‚’ä½¿ç”¨ã™ã‚‹\n    vectorizer_model = CountVectorizer(tokenizer=tokenizer_mecab, stop_words=japanese_stopwords)\n\n    topic_model = BERTopic(\n        umap_model=umap_model,\n        hdbscan_model=hdbscan_model,\n        vectorizer_model=vectorizer_model,\n        verbose=True,\n    )\n\n    # ãƒˆãƒ”ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°\n    _, __ = topic_model.fit_transform(docs, embeddings=embeddings)\n\n    n_samples = len(embeddings)\n    n_neighbors = min(n_samples - 1, 10)\n    spectral_model = SpectralClustering(\n        n_clusters=n_topics,\n        affinity=\"nearest_neighbors\",\n        n_neighbors=n_neighbors,\n        random_state=42\n    )\n    umap_embeds = umap_model.fit_transform(embeddings)\n    cluster_labels = spectral_model.fit_predict(umap_embeds)\n\n    result = topic_model.get_document_info(\n        docs=docs,\n        metadata={\n            **metadatas,\n            \"x\": umap_embeds[:, 0],\n            \"y\": umap_embeds[:, 1],\n        },\n    )\n\n    result.columns = [c.lower() for c in result.columns]\n    result = result[['arg-id', 'x', 'y', 'probability']]\n    result['cluster-id'] = cluster_labels\n\n    return result"}},{"step":"labelling","completed":"2025-01-24T18:42:23.969932","duration":5.770414,"params":{"sample_size":30,"source_code":"\"\"\"Create labels for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain_openai import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef labelling(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/labels.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['labelling']['sample_size']\n    prompt = config['labelling']['prompt']\n    model = config['labelling']['model']\n\n    question = config['question']\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n\n        args_ids_outside = clusters[clusters['cluster-id']\n                                    != cluster_id]['arg-id'].values\n        args_ids_outside = np.random.choice(args_ids_outside, size=min(\n            len(args_ids_outside), sample_size), replace=False)\n        args_sample_outside = arguments[arguments['arg-id']\n                                        .isin(args_ids_outside)]['argument'].values\n\n        label = generate_label(question, args_sample,\n                               args_sample_outside, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'label': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_label(question, args_sample, args_sample_outside, prompt, model):\n    llm = ChatOpenAI(model=model, temperature=0.0)\n    outside = '\\n * ' + '\\n * '.join(args_sample_outside)\n    inside = '\\n * ' + '\\n * '.join(args_sample)\n    input = f\"Question of the consultation:{question}\\n\\n\" + \\\n        f\"Examples of arguments OUTSIDE the cluster:\\n {outside}\" + \\\n        f\"Examples of arguments INSIDE the cluster:\\n {inside}\"\n    response = llm.invoke(input=messages(prompt, input)).content.strip()\n\n    return response","prompt":"/system \n\nã‚ãªãŸã¯ã€Creative MTGã«é–¢ã™ã‚‹ä¸€é€£ã®ã‚³ãƒ¡ãƒ³ãƒˆã«å¯¾ã™ã‚‹ã‚«ãƒ†ã‚´ãƒªãƒ©ãƒ™ãƒ«ã‚’ç”Ÿæˆã™ã‚‹ã‚«ãƒ†ã‚´ãƒªãƒ©ãƒ™ãƒªãƒ³ã‚°ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚\nCreative MTGã§ã¯ã€ã€ŒAkeruEã€ã€ã€Œãƒã‚¯ã‚»ãƒ«Ã—SHIOMERã€ã¨ã„ã†2ã¤ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãŒã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’é€²ã‚ã‚‹ä¸Šã§ä½¿ã£ãŸã€ŒæŠ€ã€ã«ã¤ã„ã¦ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¡Œã„ã¾ã—ãŸã€‚\nã‚ãªãŸã«ã¯ã€ç›¸è«‡ã®ä¸»ãªè³ªå•ã€ã‚¯ãƒ©ã‚¹ã‚¿å†…ã®è­°è«–ã®ãƒªã‚¹ãƒˆã€ãŠã‚ˆã³ã“ã®ã‚¯ãƒ©ã‚¹ã‚¿å¤–ã®è­°è«–ã®ãƒªã‚¹ãƒˆãŒä¸ãˆã‚‰ã‚Œã¾ã™ã€‚ã‚ãªãŸã¯ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã‚’è¦ç´„ã™ã‚‹1ã¤ã®ã‚«ãƒ†ã‚´ãƒªãƒ¼ãƒ©ãƒ™ãƒ«ã§å›ç­”ã—ã¾ã™ã€‚\n\nè³ªå•ã‹ã‚‰ã™ã§ã«æ˜ã‚‰ã‹ãªæ–‡è„ˆã¯å«ã‚ãªã„ï¼ˆã€ŒCreative MTGã®å‚åŠ è€…ã®åå¿œã«ã¯ã©ã†ã„ã†å‚¾å‘ãŒã‚ã£ãŸã®ã‹ã€ã®ã‚ˆã†ãªã‚‚ã®ã§ã‚ã‚Œã°ã€ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®ãƒ©ãƒ™ãƒ«ã«ã€ŒCreative MTGã®å‚åŠ è€…ã®åå¿œã€ã¨ç¹°ã‚Šè¿”ã™å¿…è¦ã¯ãªã„ï¼‰ã€‚\n\nãƒ©ãƒ™ãƒ«ã¯éå¸¸ã«ç°¡æ½”ã§ãªã‘ã‚Œã°ãªã‚‰ãšã€ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã¨ãã®å¤–å´ã«ã‚ã‚‹è«–ç‚¹ã‚’åŒºåˆ¥ã™ã‚‹ã®ã«ååˆ†ãªæ­£ç¢ºã•ã§ãªã‘ã‚Œã°ãªã‚‰ãªã„ã€‚\nãƒ©ãƒ™ãƒ«ã¯å…¨ã¦é‡è¤‡ã—ã¦ã¯ãªã‚‰ãªã„ã€‚\nã€Œå‚åŠ è€…ã®åå¿œã®å‚¾å‘ã€ã€Œå‚åŠ è€…ã®å…·ä½“çš„ãªåå¿œã€ã®ã‚ˆã†ãªã‚‚ã®ã¯ã‚„ã‚ã¦ãã ã•ã„ã€‚\nå…·ä½“çš„ã«ã©ã‚“ãªè©±ã«æ³¨ç›®ãŒé›†ã¾ã£ãŸã‹ã‚’çŸ¥ã‚ŠãŸã„ã§ã™ã€‚\nã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼å¤–ã®è«–ç‚¹ã¨æ˜ç¢ºã«åŒºåˆ¥ã•ã‚Œã‚‹ã‚ˆã†ãªãƒ©ãƒ™ãƒ«ã‚’å›ç­”ã—ã¦ãã ã•ã„ã€‚\n\n/human\n\nã‚³ãƒ³ã‚µãƒ«ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®è³ªå• ã€Œè‹±å›½ã®EUé›¢è„±æ±ºå®šã®å½±éŸ¿ã¯ä½•ã ã¨æ€ã„ã¾ã™ã‹ï¼Ÿ\n\né–¢å¿ƒã®ã‚ã‚‹ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ä»¥å¤–ã®è«–ç‚¹ã®ä¾‹\n\n * ã‚¨ãƒ©ã‚¹ãƒ ã‚¹ãƒ»ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‹ã‚‰ã®é™¤å¤–ã«ã‚ˆã‚Šã€æ•™è‚²ãƒ»æ–‡åŒ–äº¤æµã®æ©Ÿä¼šãŒåˆ¶é™ã•ã‚ŒãŸã€‚\n * è‹±å›½ã¯ã€å›½å¢ƒæ¤œå•ã®å¼·åŒ–ã«ã‚ˆã‚‹æ—…è¡Œæ™‚é–“ã®å»¶é•·ã«å¯¾å‡¦ã—ã€é€šå‹¤å®¢ã‚„æ—…è¡Œå®¢ã«å½±éŸ¿ã‚’ä¸ãˆãŸã€‚\n * ç’°å¢ƒåŸºæº–ã«ãŠã‘ã‚‹å”åŠ›ãŒæ¸›å°‘ã—ã€æ°—å€™å¤‰å‹•ã¨é—˜ã†åŠªåŠ›ãŒå¦¨ã’ã‚‰ã‚ŒãŸã€‚\n * ç›¸äº’åŒ»ç™‚å”å®šã®ä¸­æ–­ã«ã‚ˆã‚Šã€æ‚£è€…ã‚±ã‚¢ã«èª²é¡Œã‚’æ„Ÿã˜ãŸã€‚\n * Brexité–¢é€£ã®å¤‰æ›´ã«ã‚ˆã‚Šã€å®¶æ—ã®å±…ä½æ¨©ã‚„å¸‚æ°‘æ¨©ã®ç”³è«‹ãŒè¤‡é›‘ã«ãªã£ãŸã€‚\n * è‹±å›½ã¯ã€å…±åŒç ”ç©¶æ©Ÿä¼šã®æ¸›å°‘ã«ã‚ˆã‚Šã€ç ”ç©¶ã®èª²é¡Œã«å–ã‚Šçµ„ã‚€ä¸–ç•Œçš„ãªå–ã‚Šçµ„ã¿ã«æ”¯éšœã‚’ããŸã™ã“ã¨ã‚’ç›®ã®å½“ãŸã‚Šã«ã—ãŸã€‚\n * EUã®æ–‡åŒ–åŠ©æˆãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‹ã‚‰ã®é™¤å¤–ã«ã‚ˆã‚Šã€å‰µé€ çš„ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®åˆ¶é™ã«ç›´é¢ã—ãŸã€‚\n * è‹±å›½ã¯ã€EUã®è³‡é‡‘æä¾›ã®å–ªå¤±ã«ã‚ˆã‚Šã€æ…ˆå–„æ´»å‹•ã‚„ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æ”¯æ´ã®å¾Œé€€ã‚’ç›®ã®å½“ãŸã‚Šã«ã—ãŸã€‚\n * æ¶ˆè²»è€…ä¿è­·ã®å¼±ä½“åŒ–ã«ã‚ˆã‚Šã€å›½å¢ƒã‚’è¶ŠãˆãŸç´›äº‰è§£æ±ºã«èª²é¡ŒãŒç”Ÿã˜ãŸã€‚\n * è‹±å›½ã¯ãƒ—ãƒ­ã®éŸ³æ¥½å®¶ã¨ã—ã¦EUè«¸å›½ã‚’ãƒ„ã‚¢ãƒ¼ã™ã‚‹éš›ã®åˆ¶é™ã«ç›´é¢ã—ã€ã‚­ãƒ£ãƒªã‚¢ã«å½±éŸ¿ã‚’ä¸ãˆãŸã€‚\n\nã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼å†…éƒ¨ã§ã®è­°è«–ã®ä¾‹\n\n * Brexitã«ã‚ˆã‚Šã‚µãƒ—ãƒ©ã‚¤ãƒã‚§ãƒ¼ãƒ³ãŒæ··ä¹±ã—ã€ä¼æ¥­ã«ã¨ã£ã¦ã‚³ã‚¹ãƒˆå¢—ã¨ç´æœŸé…å»¶ã«ã¤ãªãŒã£ãŸã€‚\n * ãƒ–ãƒ¬ã‚°ã‚¸ãƒƒãƒˆã®ãŸã‚ã€å¸‚å ´ã®å¤‰å‹•ã‚„æŠ•è³‡ãƒ»é€€è·é‡‘ã®ä¸ç¢ºå®Ÿæ€§ã«ç›´é¢ã—ãŸã€‚\n * æ–°ãŸãªé–¢ç¨ã‚„é€šé–¢æ‰‹ç¶šãã«ã‚ˆã‚Šã€è‹±å›½ã¯è¼¸å‡ºæ¥­è€…ã¨ã—ã¦åˆ©ç›Šç‡ã®ä½ä¸‹ã«å¯¾å‡¦ã—ãŸã€‚\n * ãƒ–ãƒ¬ã‚°ã‚¸ãƒƒãƒˆå¾Œã€ä¼æ¥­ãŒEUå¸‚å ´å†…ã«ã¨ã©ã¾ã‚‹ãŸã‚ã«äº‹æ¥­ã‚’ç§»è»¢ã—ãŸãŸã‚ã€é›‡ç”¨ã‚’å¤±ã£ãŸã€‚\n * è‹±å›½ã¯è¼¸å…¥å“ä¾¡æ ¼ã®é«˜é¨°ã«ã‚ˆã‚‹ç”Ÿæ´»è²»ã®å¢—åŠ ã«è‹¦ã—ã‚“ã ã€‚\n * è‹±å›½ã®ãƒã‚¤ãƒ†ã‚¯ç”£æ¥­ã¸ã®æŠ•è³‡ãŒæ¸›å°‘ã—ã€æŠ€è¡“é©æ–°ã¨é›‡ç”¨æ©Ÿä¼šã«å½±éŸ¿ã‚’ä¸ãˆãŸã€‚\n * æ–°ãŸãªãƒ“ã‚¶è¦åˆ¶ã«ã‚ˆã‚‹è¦³å…‰å®¢ã®æ¸›å°‘ã‚’ç›®ã®å½“ãŸã‚Šã«ã—ã€æ¥å®¢æ¥­ã«å½±éŸ¿ã€‚\n * ãƒãƒ³ãƒ‰ä¾¡å€¤ã®ä¸‹è½ã«ã‚ˆã‚Šè³¼è²·åŠ›ãŒä½ä¸‹ã—ã€æ—…è²»ãŒå¢—åŠ ã—ãŸã€‚\n\n\n/ai \n\nè²¡å‹™ä¸Šã®ãƒã‚¤ãƒŠã‚¹å½±éŸ¿","model":"gpt-4o-mini"}},{"step":"takeaways","completed":"2025-01-24T18:42:44.455530","duration":20.475404,"params":{"sample_size":30,"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain_openai import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef takeaways(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/takeaways.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['takeaways']['sample_size']\n    prompt = config['takeaways']['prompt']\n    model = config['takeaways']['model']\n\n    model = config.get('model_takeaways', config.get('model', 'gpt3.5-turbo'))\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n        label = generate_takeaways(args_sample, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'takeaways': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_takeaways(args_sample, prompt, model):\n    llm = ChatOpenAI(model=model, temperature=0.0)\n    input = \"\\n\".join(args_sample)\n    response = llm.invoke(input=messages(prompt, input)).content.strip()\n    return response","prompt":"/system \n\nã‚ãªãŸã¯ã‚·ãƒ³ã‚¯ã‚¿ãƒ³ã‚¯ã§åƒããƒªã‚µãƒ¼ãƒã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚Creative MTGã«å‚åŠ ã—ãŸäººã®ã‚³ãƒ¡ãƒ³ãƒˆã®ãƒªã‚¹ãƒˆãŒæ¸¡ã•ã‚Œã¾ã™ã€‚\nCreative MTGã§ã¯ã€ã€ŒAkeruEã€ã€ã€Œãƒã‚¯ã‚»ãƒ«Ã—SHIOMERã€ã¨ã„ã†2ã¤ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãŒã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’é€²ã‚ã‚‹ä¸Šã§ä½¿ã£ãŸã€ŒæŠ€ã€ã«ã¤ã„ã¦ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¡Œã„ã¾ã—ãŸã€‚\nã‚ãªãŸã¯ã€ã©ã‚“ãªè©±ã«æ³¨ç›®ãŒé›†ã¾ã£ãŸã‹ã€ä¸»ãªè¦ç‚¹ã‚’1~2æ®µè½ã«ã¾ã¨ã‚ã¦å›ç­”ã—ã¾ã™ã€‚ã‚ãªãŸã¯ç°¡æ½”ã§èª­ã¿ã‚„ã™ã„çŸ­ã„æ–‡ç« ã‚’æ›¸ãã“ã¨ãŒã§ãã¾ã™ã€‚ \n \n/human\n\n[\n  \"éŠƒã«ã‚ˆã‚‹æš´åŠ›ã¯ã€ç§ãŸã¡ã®ç¤¾ä¼šã«ãŠã‘ã‚‹æ·±åˆ»ãªå…¬è¡†è¡›ç”Ÿã®å±æ©Ÿã‚’æ§‹æˆã—ã¦ã„ã‚‹ã¨å›ºãä¿¡ã˜ã¦ã„ã¾ã™ã€‚\",\n  \"åŒ…æ‹¬çš„ãªéŠƒè¦åˆ¶ç­–ã‚’é€šã˜ã¦ã€ã“ã®å•é¡Œã«æ—©æ€¥ã«å–ã‚Šçµ„ã‚€å¿…è¦ãŒã‚ã‚‹ã€‚\",\n  \"ã™ã¹ã¦ã®éŠƒè³¼å…¥è€…ã«å¯¾ã™ã‚‹èº«å…ƒèª¿æŸ»ã®å®Ÿæ–½ã‚’æ”¯æŒã—ã¾ã™ã€‚\",\n  \"ã‚¢ã‚µãƒ«ãƒˆãƒ»ã‚¦ã‚§ãƒãƒ³ã¨å¤§å®¹é‡å¼¾å€‰ã®ç¦æ­¢ã«è³›æˆã—ã¾ã™ã€‚\",\n  \"é•æ³•ãªéŠƒã®å£²è²·ã‚’é˜²ããŸã‚ã€ã‚ˆã‚Šå³ã—ã„è¦åˆ¶ã‚’æå”±ã—ã¾ã™ã€‚\",\n  \"éŠƒã®è³¼å…¥ãƒ—ãƒ­ã‚»ã‚¹ã«ãŠã„ã¦ã€ç²¾ç¥é‘‘å®šã‚’ç¾©å‹™ä»˜ã‘ã‚‹ã¹ãã§ã‚ã‚‹ã€‚\"\n]\n\n/ai \n\nå‚åŠ è€…ã¯ã€åŒ…æ‹¬çš„ãªéŠƒè¦åˆ¶ã‚’æ±‚ã‚ã€æ™®éçš„ãªèº«å…ƒèª¿æŸ»ã€çªæ’ƒå…µå™¨ã®ç¦æ­¢ã€é•æ³•ãªéŠƒå£²è²·ã®æŠ‘åˆ¶ã€ç²¾ç¥è¡›ç”Ÿè©•ä¾¡ã®å„ªå…ˆãªã©ã‚’å¼·èª¿ã—ãŸã€‚","model":"gpt-4o-mini"}},{"step":"overview","completed":"2025-01-24T18:42:47.146221","duration":2.685419,"params":{"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain_community.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef overview(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/overview.txt\"\n\n    takeaways = pd.read_csv(f\"outputs/{dataset}/takeaways.csv\")\n    labels = pd.read_csv(f\"outputs/{dataset}/labels.csv\")\n\n    prompt = config['overview']['prompt']\n    model = config['overview']['model']\n\n    ids = labels['cluster-id'].to_list()\n    takeaways.set_index('cluster-id', inplace=True)\n    labels.set_index('cluster-id', inplace=True)\n\n    input = ''\n    for i, id in enumerate(ids):\n        input += f\"# Cluster {i}/{len(ids)}: {labels.loc[id]['label']}\\n\\n\"\n        input += takeaways.loc[id]['takeaways'] + '\\n\\n'\n\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    messages_list = messages(prompt, input)  # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãƒªã‚¹ãƒˆã«å¤‰æ›\n    response = llm.invoke(messages_list).content.strip()  # invoke() ã‚’ä½¿ç”¨\n\n\n    with open(path, 'w') as file:\n        file.write(response)","prompt":"/system \nã‚ãªãŸã¯ã‚·ãƒ³ã‚¯ã‚¿ãƒ³ã‚¯ã§åƒãå°‚é–€å®¶ãƒªã‚µãƒ¼ãƒã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ã‚ãªãŸã®ãƒãƒ¼ãƒ ã¯ã€ã‚ã‚‹ãƒˆãƒ”ãƒƒã‚¯ã«é–¢ã™ã‚‹å…¬é–‹ã‚³ãƒ³ã‚µãƒ«ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿæ–½ã—ã€ã•ã¾ã–ã¾ãªé¸æŠè‚¢ã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã‚’åˆ†æã—å§‹ã‚ã¾ã—ãŸã€‚ã‚ãªãŸã¯ä»Šã€ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®ãƒªã‚¹ãƒˆã¨å„ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®ç°¡å˜ãªåˆ†æã‚’å—ã‘å–ã‚Šã¾ã™ã€‚ã‚ãªãŸã®ä»•äº‹ã¯ã€CreativeMTGã§ã©ã‚“ãªè©±ã«æ³¨ç›®ãŒé›†ã¾ã£ãŸã‹ã‚’ç°¡æ½”ã«ã¾ã¨ã‚ã‚‹ã“ã¨ã§ã™ã€‚ã‚ãªãŸã®è¦ç´„ã¯éå¸¸ã«ç°¡æ½”ã§ãªã‘ã‚Œã°ãªã‚‰ãšï¼ˆã›ã„ãœã„1æ®µè½ã€ã›ã„ãœã„4æ–‡ï¼‰ã€å¹³å‡¡ãªè¡¨ç¾ã¯é¿ã‘ãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚\nè£œè¶³ã¨ã—ã¦ã€Creative MTGã§ã¯ã€ã€ŒAkeruEã€ã€ã€Œãƒã‚¯ã‚»ãƒ«Ã—SHIOMERã€ã¨ã„ã†2ã¤ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãŒã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’é€²ã‚ã‚‹ä¸Šã§ä½¿ã£ãŸã€ŒæŠ€ã€ã«ã¤ã„ã¦ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¡Œã„ã¾ã—ãŸã€‚","model":"gpt-4o-mini"}}],"lock_until":"2025-01-24T18:47:47.150255","current_job":"aggregation","current_job_started":"2025-01-24T18:42:47.150232","current_job_progress":null,"current_jop_tasks":null}}},"__N_SSG":true},"page":"/","query":{},"buildId":"CV6WqzivbkPeR90C6i50t","assetPrefix":".","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>